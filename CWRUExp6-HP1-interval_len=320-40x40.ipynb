{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5ab9cc-9d31-4bd8-9339-c80842c4c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32209d77-1aef-4ca4-81d7-ea6457e51333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 1\n",
    "random.seed(SEED)            # Python random module\n",
    "np.random.seed(SEED)         # NumPy\n",
    "tf.random.set_seed(SEED)     # TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71899bcf-951f-483f-9b14-081df6aa4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce deterministic behavior for GPU operations\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic execution\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Deterministic cuDNN algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd1cd7b-5ae6-45e4-9888-9da0cae55811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control GPU memory allocation (prevents TensorFlow from using all GPU memory)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # Enable memory growth\n",
    "\n",
    "# Restrict parallelism (ensures consistent execution order)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0842921e-69f2-4b98-a50d-a8cbf80872d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import scipy.io #to load matlab files \n",
    "# import numpy as np\n",
    "from sklearn.model_selection import train_test_split #for data splitting #, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras import layers, models #build and train CNN model\n",
    "import matplotlib.pyplot as plt #for plotting confusion matrices and accuracy metrics\n",
    "import seaborn as sns \n",
    "# import pandas as pd\n",
    "\n",
    "from scipy import signal #for computing spectograms\n",
    "from skimage.transform import resize #for resizing data\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9d9640-93e2-47e2-98d4-06a74ec1a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Read CWRU Bearing Data (Load - 2HP)\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "def ImportData():\n",
    "  folder_path = 'CWRU_BearingData_Load_1HP' \n",
    "  # X99_normal = scipy.io.loadmat('content/drive/MyDrive/BearingData_CaseWestern/99.mat')['X099_DE_time'] \n",
    "  file_path1 = os.path.join(folder_path, '98.mat')\n",
    "  X098_normal = scipy.io.loadmat(file_path1)['X098_DE_time'] #vibration data extracted from X099_DE_time key (drive-end accelerometer data)\n",
    "\n",
    " \n",
    "\n",
    "  file_path2 = os.path.join(folder_path, '110.mat')\n",
    "  X110_InnerRace_007  = scipy.io.loadmat(file_path2)['X110_DE_time']\n",
    "  # mat_data = scipy.io.loadmat(file_path2)\n",
    "  # print(mat_data.keys())\n",
    "\n",
    "  file_path2 = os.path.join(folder_path, '123.mat')\n",
    "  X123_Ball_007  = scipy.io.loadmat(file_path2)['X123_DE_time']\n",
    "\n",
    "  file_path3 = os.path.join(folder_path, '136.mat')\n",
    "  X136_Outer_007 = scipy.io.loadmat(file_path3)['X136_DE_time']\n",
    "\n",
    "  file_path6 = os.path.join(folder_path, '175.mat')\n",
    "  X175_InnerRace_014 = scipy.io.loadmat(file_path6)['X175_DE_time']\n",
    "    \n",
    "  file_path7 = os.path.join(folder_path, '190.mat')\n",
    "  X190_Ball_014 = scipy.io.loadmat(file_path7)['X190_DE_time']\n",
    "\n",
    "  file_path8 = os.path.join(folder_path, '202.mat')\n",
    "  X202_Outer_014  = scipy.io.loadmat(file_path8)['X202_DE_time']\n",
    "    \n",
    "  file_path9 = os.path.join(folder_path, '214.mat')\n",
    "  X214_InnerRace_021  = scipy.io.loadmat(file_path9)['X214_DE_time']\n",
    "\n",
    "  file_path10 = os.path.join(folder_path, '227.mat')\n",
    "  X227_Ball_021  = scipy.io.loadmat(file_path10)['X227_DE_time'] \n",
    "\n",
    "  file_path11 = os.path.join(folder_path, '239.mat')\n",
    "  X239_Outer_021  = scipy.io.loadmat(file_path11)['X239_DE_time'] \n",
    "    \n",
    "  return [X098_normal,X110_InnerRace_007,X123_Ball_007,X136_Outer_007,X175_InnerRace_014,X190_Ball_014,X202_Outer_014,X214_InnerRace_021,X227_Ball_021,X239_Outer_021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3827a-7567-422b-9d6a-08b5aa1ce7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6fbfd8-76a9-49e1-94e2-2924bd737533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data Processing and Feature Extraction\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "# def Sampling(Data, interval_length, samples_per_block):\n",
    "#     No_of_blocks = (round(len(Data)/interval_length) - round(samples_per_block/interval_length) - 1)\n",
    "#     SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "#     for i in range(No_of_blocks):\n",
    "#         SplitData[i,:] = Data[i*interval_length:(i*interval_length)+samples_per_block].T\n",
    "#     return SplitData\n",
    "\n",
    "#segments the time-series data into smaller blocks for processing\n",
    "#data: 1D numpy array of vibration data\n",
    "#interval length: step size (in samples) betweeen the start of consectuive blocks\n",
    "#samples_per_block: no. of samples in each block (fixed at 1600 in the code)\n",
    "#ignore_points: no. of points to skip at start and end of data(default is 0)\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    # Adjust data length to ignore the first and last 'ignore_points'\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    # Adjust the number of blocks\n",
    "    No_of_blocks = (round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1)\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block]) #splitdata matrix where each row is a block of samples_per_block samples\n",
    "    \n",
    "    for i in range(No_of_blocks):\n",
    "        # Skip the first 'ignore_points' and start sampling from that position\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx:(start_idx + samples_per_block)].T #.T transpose ensure the data is correctly oriented (since the input is a column vector)\n",
    "    \n",
    "    return SplitData #2D array of shape - no.ofblocks, samples_per_block)\n",
    "\n",
    "\n",
    "def DataPreparation(Data, interval_length, samples_per_block):\n",
    "  for count,i in enumerate(Data):\n",
    "    SplitData = Sampling(i, interval_length, samples_per_block) #for each dataset calls samplying to create blocks of 1600 samples\n",
    "    y = np.zeros([len(SplitData),10]) #y (one-hot encoded): Shape (No_of_blocks, 10), where the column corresponding to the class is set to 1 (e.g., for class 0, [1, 0, 0, ..., 0])\n",
    "    y[:,count] = 1\n",
    "    y1 = np.zeros([len(SplitData),1]) #y1 (integer labels): Shape (No_of_blocks, 1), where each element is the class index (0 to 9).\n",
    "    y1[:,0] = count \n",
    "    # Stack up and label the data   \n",
    "    if count==0:\n",
    "      X = SplitData\n",
    "      LabelPositional = y\n",
    "      Label = y1\n",
    "    else:\n",
    "      X = np.append(X, SplitData, axis=0)\n",
    "      LabelPositional = np.append(LabelPositional,y,axis=0)\n",
    "      Label = np.append(Label,y1,axis=0)\n",
    "  print(X)\n",
    "  return X, LabelPositional, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44975d7a-8b19-44e0-a88f-ca7bf2c4749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(ary):\n",
    "    ary = (ary - ary.min()) / np.abs(ary.max() - ary.min())\n",
    "    return ary\n",
    "\n",
    "def generate_spectrogram_image(data_y_vector, image_shape):\n",
    "    \"\"\"\n",
    "    Calculate the spectrogram of an array data_y_vector and resize it in \n",
    "    the image_shape resolution\n",
    "    \"\"\"\n",
    "    fs = 48000\n",
    "    # data_y_vector_len = np.shape(data_y_vector)[0]\n",
    "\n",
    "    f, t, sxx = signal.spectrogram(\n",
    "        data_y_vector,\n",
    "        fs)\n",
    "\n",
    "    sxx = min_max_norm(sxx)\n",
    "    sxx = resize(sxx, image_shape, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    return sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c91be0-79cd-438c-876c-9291efc88572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (483903, 1)\n",
      "Dataset 2 shape: (486224, 1)\n",
      "Dataset 3 shape: (487384, 1)\n",
      "Dataset 4 shape: (486804, 1)\n",
      "Dataset 5 shape: (381890, 1)\n",
      "Dataset 6 shape: (486224, 1)\n",
      "Dataset 7 shape: (484483, 1)\n",
      "Dataset 8 shape: (485063, 1)\n",
      "Dataset 9 shape: (486804, 1)\n",
      "Dataset 10 shape: (489125, 1)\n",
      "[[ 4.61040000e-02 -3.71335385e-02 -8.94960000e-02 ...  4.71470769e-02\n",
      "  -1.25169231e-03 -7.13464615e-02]\n",
      " [-9.05390769e-02 -8.11513846e-02 -5.65347692e-02 ... -3.21267692e-02\n",
      "  -6.25846154e-04 -1.58547692e-02]\n",
      " [ 3.54646154e-02  3.85938462e-02  6.13329231e-02 ...  6.04984615e-02\n",
      "   6.94689231e-02  8.61581538e-02]\n",
      " ...\n",
      " [-2.33706667e-02 -2.42053333e-02 -2.00320000e-02 ... -2.26194667e-01\n",
      "  -4.98296000e-01 -6.88600000e-01]\n",
      " [-2.25360000e-02  3.92293333e-02  8.17973333e-02 ...  1.29373333e-01\n",
      "   5.17493333e-02 -9.18133333e-03]\n",
      " [ 3.54733333e-01  2.68762667e-01  2.18682667e-01 ...  5.59226667e-02\n",
      "  -3.33866667e-03 -5.59226667e-02]]\n",
      "Shape of Input Data = (14807, 1600)\n",
      "Shape of Label Y_CNN = (14807, 10)\n",
      "Shape of Label Y = (14807, 1)\n"
     ]
    }
   ],
   "source": [
    "Data = ImportData()\n",
    "for i, d in enumerate(Data):\n",
    "    print(f\"Dataset {i+1} shape: {d.shape}\")\n",
    "interval_length = 320 #320 #290 #200  \n",
    "samples_per_block = 1600 #1650-25*2\n",
    "\n",
    "\n",
    "# Y_CNN is of shape (n, 10) representing 10 classes as 10 columns. In each sample, for the class to which it belongs, \n",
    "# the corresponding column value is marked 1 and the rest as 0, facilitating Softmax implementation in CNN \n",
    "# Y is of shape (m, 1) where column values are between 0 and 9 representing the classes directly. - 1-hot encoding\n",
    "X, Y_CNN, Y = DataPreparation(Data, interval_length, samples_per_block) \n",
    "\n",
    "\n",
    "print('Shape of Input Data =', X.shape)\n",
    "print('Shape of Label Y_CNN =', Y_CNN.shape)\n",
    "print('Shape of Label Y =', Y.shape)\n",
    "\n",
    "# XX = {'X':X}\n",
    "# scipy.io.savemat('Data.mat', XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaaee3ff-4250-4baf-bf15-23256e6d8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14807, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Training\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "## 2-Dimensional Convolutional Neural Network Classification\n",
    "\n",
    "# Reshape the data - 2 dimensional feed \n",
    "Input_2D = X.reshape([-1,40,40,1])\n",
    "\n",
    "# Input_2D = X_image.reshape([-1,96,96,1])\n",
    "print(Input_2D.shape)\n",
    "\n",
    "# Test-Train Split \n",
    "X_2D_train, X_2D_test, y_2D_train, y_2D_test, y_label_train, y_label_test = train_test_split(Input_2D, Y_CNN, Y, train_size=0.8, test_size=0.2, random_state=42, stratify=Y)\n",
    "#(ensuring class balance via stratify=Y)\n",
    "# X_2D_train, X_2D_test, y_2D_train, y_2D_test = train_test_split(Input_2D, Y_CNN, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define the CNN Classification model\n",
    "class CNN_2D():\n",
    "  def __init__(self):\n",
    "    self.model = self.CreateModel()\n",
    "\n",
    "  def CreateModel(self):\n",
    "    model = models.Sequential([\n",
    "        # layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding ='same',activation='relu'),\n",
    "        layers.Conv2D(filters=16, kernel_size=(3,3), padding='same',activation='relu', input_shape=(40,40,1)),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=32, kernel_size=(3,3), padding ='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=64, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100,activation='relu'),\n",
    "        layers.Dense(50,activation='relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Softmax()\n",
    "        ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf41e7c-a3e8-4875-ac08-918e90ad86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gayathri/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:25:28.113214: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:25:28.114242: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5014 - loss: 1.3045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:25:43.133604: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:25:43.134035: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85775, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.5028 - loss: 1.3009 - val_accuracy: 0.8577 - val_loss: 0.3503\n",
      "Epoch 2/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9113 - loss: 0.2632\n",
      "Epoch 2: val_accuracy improved from 0.85775 to 0.90756, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9114 - loss: 0.2629 - val_accuracy: 0.9076 - val_loss: 0.2261\n",
      "Epoch 3/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9390 - loss: 0.1569\n",
      "Epoch 3: val_accuracy improved from 0.90756 to 0.95526, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9390 - loss: 0.1568 - val_accuracy: 0.9553 - val_loss: 0.1188\n",
      "Epoch 4/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9613 - loss: 0.1130\n",
      "Epoch 4: val_accuracy did not improve from 0.95526\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9613 - loss: 0.1129 - val_accuracy: 0.9287 - val_loss: 0.3968\n",
      "Epoch 5/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9644 - loss: 0.1037\n",
      "Epoch 5: val_accuracy improved from 0.95526 to 0.97256, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 75ms/step - accuracy: 0.9645 - loss: 0.1035 - val_accuracy: 0.9726 - val_loss: 0.0899\n",
      "Epoch 6/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9663 - loss: 0.0925\n",
      "Epoch 6: val_accuracy improved from 0.97256 to 0.97932, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 0.9663 - loss: 0.0923 - val_accuracy: 0.9793 - val_loss: 0.0477\n",
      "Epoch 7/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9879 - loss: 0.0325\n",
      "Epoch 7: val_accuracy did not improve from 0.97932\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.9879 - loss: 0.0326 - val_accuracy: 0.9768 - val_loss: 0.0609\n",
      "Epoch 8/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9889 - loss: 0.0331\n",
      "Epoch 8: val_accuracy improved from 0.97932 to 0.99240, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - accuracy: 0.9889 - loss: 0.0331 - val_accuracy: 0.9924 - val_loss: 0.0249\n",
      "Epoch 9/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9873 - loss: 0.0388\n",
      "Epoch 9: val_accuracy improved from 0.99240 to 0.99325, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step - accuracy: 0.9873 - loss: 0.0388 - val_accuracy: 0.9932 - val_loss: 0.0225\n",
      "Epoch 10/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9862 - loss: 0.0408\n",
      "Epoch 10: val_accuracy improved from 0.99325 to 0.99578, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 0.9862 - loss: 0.0408 - val_accuracy: 0.9958 - val_loss: 0.0158\n",
      "Epoch 11/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9964 - loss: 0.0120\n",
      "Epoch 11: val_accuracy did not improve from 0.99578\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.9865 - val_loss: 0.0464\n",
      "Epoch 12/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9890 - loss: 0.0310\n",
      "Epoch 12: val_accuracy did not improve from 0.99578\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.9890 - loss: 0.0310 - val_accuracy: 0.9954 - val_loss: 0.0172\n",
      "Epoch 13/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9939 - loss: 0.0208\n",
      "Epoch 13: val_accuracy did not improve from 0.99578\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - accuracy: 0.9939 - loss: 0.0208 - val_accuracy: 0.9958 - val_loss: 0.0141\n",
      "Epoch 14/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9985 - loss: 0.0045\n",
      "Epoch 14: val_accuracy did not improve from 0.99578\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9890 - val_loss: 0.0299\n",
      "Epoch 15/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9903 - loss: 0.0315\n",
      "Epoch 15: val_accuracy improved from 0.99578 to 0.99662, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.9903 - loss: 0.0315 - val_accuracy: 0.9966 - val_loss: 0.0091\n",
      "Epoch 16/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9936 - loss: 0.0253\n",
      "Epoch 16: val_accuracy did not improve from 0.99662\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.9936 - loss: 0.0254 - val_accuracy: 0.9966 - val_loss: 0.0102\n",
      "Epoch 17/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9987 - loss: 0.0056\n",
      "Epoch 17: val_accuracy improved from 0.99662 to 0.99831, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 0.9983 - val_loss: 0.0062\n",
      "Epoch 18/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0026\n",
      "Epoch 18: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9962 - val_loss: 0.0137\n",
      "Epoch 19/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9991 - loss: 0.0035\n",
      "Epoch 19: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9966 - val_loss: 0.0081\n",
      "Epoch 20/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.2335e-04\n",
      "Epoch 20: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.2060e-04 - val_accuracy: 0.9975 - val_loss: 0.0055\n",
      "Epoch 21/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.0247e-05\n",
      "Epoch 21: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 9.0244e-05 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 22/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.2285e-05\n",
      "Epoch 22: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 4.2280e-05 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 23/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.9970e-05\n",
      "Epoch 23: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.9965e-05 - val_accuracy: 0.9975 - val_loss: 0.0055\n",
      "Epoch 24/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2282e-05\n",
      "Epoch 24: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.2281e-05 - val_accuracy: 0.9975 - val_loss: 0.0055\n",
      "Epoch 25/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.6672e-05\n",
      "Epoch 25: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.6672e-05 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 26/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.2727e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2728e-05 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 27/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.7438e-06\n",
      "Epoch 27: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.7445e-06 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 28/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.6833e-06\n",
      "Epoch 28: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.6839e-06 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 29/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.1458e-06\n",
      "Epoch 29: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 6.1462e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 30/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.9337e-06\n",
      "Epoch 30: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.9342e-06 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 31/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.0212e-06\n",
      "Epoch 31: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0214e-06 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 32/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.2771e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.2775e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 33/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.6910e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.6913e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 34/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.2316e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.2321e-06 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 35/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8605e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.8607e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 36/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5457e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5461e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 37/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.2924e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2927e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 38/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0744e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0747e-06 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 39/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.0215e-07\n",
      "Epoch 39: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.0239e-07 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 40/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.6021e-07\n",
      "Epoch 40: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.6031e-07 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 41/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.3815e-07\n",
      "Epoch 41: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.3828e-07 - val_accuracy: 0.9979 - val_loss: 0.0057\n",
      "Epoch 42/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.3334e-07\n",
      "Epoch 42: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.3345e-07 - val_accuracy: 0.9979 - val_loss: 0.0057\n",
      "Epoch 43/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.4345e-07\n",
      "Epoch 43: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.4355e-07 - val_accuracy: 0.9979 - val_loss: 0.0058\n",
      "Epoch 44/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.6690e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.6694e-07 - val_accuracy: 0.9979 - val_loss: 0.0058\n",
      "Epoch 45/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.0136e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.0140e-07 - val_accuracy: 0.9979 - val_loss: 0.0059\n",
      "Epoch 46/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.5195e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.5197e-07 - val_accuracy: 0.9979 - val_loss: 0.0059\n",
      "Epoch 47/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.1126e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.1132e-07 - val_accuracy: 0.9979 - val_loss: 0.0059\n",
      "Epoch 48/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.7740e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.7743e-07 - val_accuracy: 0.9979 - val_loss: 0.0059\n",
      "Epoch 49/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5026e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5027e-07 - val_accuracy: 0.9979 - val_loss: 0.0060\n",
      "Epoch 50/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.2481e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2482e-07 - val_accuracy: 0.9983 - val_loss: 0.0061\n",
      "Epoch 51/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.0519e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0520e-07 - val_accuracy: 0.9983 - val_loss: 0.0062\n",
      "Epoch 52/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.8691e-08\n",
      "Epoch 52: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.8696e-08 - val_accuracy: 0.9983 - val_loss: 0.0062\n",
      "Epoch 53/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.4831e-08\n",
      "Epoch 53: val_accuracy improved from 0.99831 to 0.99873, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.4834e-08 - val_accuracy: 0.9987 - val_loss: 0.0063\n",
      "Epoch 54/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3314e-08\n",
      "Epoch 54: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.3319e-08 - val_accuracy: 0.9987 - val_loss: 0.0064\n",
      "Epoch 55/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.3936e-08\n",
      "Epoch 55: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.3939e-08 - val_accuracy: 0.9987 - val_loss: 0.0064\n",
      "Epoch 56/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.6095e-08\n",
      "Epoch 56: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.6097e-08 - val_accuracy: 0.9987 - val_loss: 0.0065\n",
      "Epoch 57/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.9196e-08\n",
      "Epoch 57: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.9198e-08 - val_accuracy: 0.9987 - val_loss: 0.0065\n",
      "Epoch 58/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.3193e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.3194e-08 - val_accuracy: 0.9987 - val_loss: 0.0065\n",
      "Epoch 59/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.8229e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.8233e-08 - val_accuracy: 0.9987 - val_loss: 0.0065\n",
      "Epoch 60/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.4316e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.4317e-08 - val_accuracy: 0.9987 - val_loss: 0.0066\n",
      "Epoch 61/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0994e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.0994e-08 - val_accuracy: 0.9987 - val_loss: 0.0066\n",
      "Epoch 62/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7811e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7812e-08 - val_accuracy: 0.9987 - val_loss: 0.0066\n",
      "Epoch 63/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5263e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5264e-08 - val_accuracy: 0.9987 - val_loss: 0.0066\n",
      "Epoch 64/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.3197e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.3198e-08 - val_accuracy: 0.9987 - val_loss: 0.0066\n",
      "Epoch 65/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.1309e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.1310e-08 - val_accuracy: 0.9987 - val_loss: 0.0067\n",
      "Epoch 66/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 9.6914e-09\n",
      "Epoch 66: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 9.6916e-09 - val_accuracy: 0.9987 - val_loss: 0.0067\n",
      "Epoch 67/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.4035e-09\n",
      "Epoch 67: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.4040e-09 - val_accuracy: 0.9987 - val_loss: 0.0067\n",
      "Epoch 68/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.2480e-09\n",
      "Epoch 68: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 7.2483e-09 - val_accuracy: 0.9987 - val_loss: 0.0067\n",
      "Epoch 69/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.2519e-09\n",
      "Epoch 69: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.2517e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 70/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.3133e-09\n",
      "Epoch 70: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.3134e-09 - val_accuracy: 0.9987 - val_loss: 0.0067\n",
      "Epoch 71/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.6376e-09\n",
      "Epoch 71: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 4.6378e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 72/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.0037e-09\n",
      "Epoch 72: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.0041e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 73/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.5197e-09\n",
      "Epoch 73: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.5201e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 74/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.0923e-09\n",
      "Epoch 74: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.0922e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 75/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.5202e-09\n",
      "Epoch 75: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.5203e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 76/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.1615e-09\n",
      "Epoch 76: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.1616e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 77/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.8922e-09\n",
      "Epoch 77: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.8921e-09 - val_accuracy: 0.9987 - val_loss: 0.0068\n",
      "Epoch 78/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.7653e-09\n",
      "Epoch 78: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7651e-09 - val_accuracy: 0.9987 - val_loss: 0.0069\n",
      "Epoch 79/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5189e-09\n",
      "Epoch 79: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.5187e-09 - val_accuracy: 0.9987 - val_loss: 0.0069\n",
      "Epoch 80/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.3432e-09\n",
      "Epoch 80: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.3431e-09 - val_accuracy: 0.9987 - val_loss: 0.0070\n",
      "Epoch 81/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2485e-09\n",
      "Epoch 81: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.2481e-09 - val_accuracy: 0.9987 - val_loss: 0.0071\n",
      "Epoch 82/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.8425e-10\n",
      "Epoch 82: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.8431e-10 - val_accuracy: 0.9987 - val_loss: 0.0071\n",
      "Epoch 83/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.7902e-10\n",
      "Epoch 83: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.7936e-10 - val_accuracy: 0.9987 - val_loss: 0.0070\n",
      "Epoch 84/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.8350e-10\n",
      "Epoch 84: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.8389e-10 - val_accuracy: 0.9987 - val_loss: 0.0070\n",
      "Epoch 85/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 6.0522e-10\n",
      "Epoch 85: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 6.0572e-10 - val_accuracy: 0.9987 - val_loss: 0.0070\n",
      "Epoch 86/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.6453e-10\n",
      "Epoch 86: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 5.6505e-10 - val_accuracy: 0.9987 - val_loss: 0.0070\n",
      "Epoch 87/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.6789e-10\n",
      "Epoch 87: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.6779e-10 - val_accuracy: 0.9987 - val_loss: 0.0070\n",
      "Epoch 88/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.2376e-10\n",
      "Epoch 88: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.2373e-10 - val_accuracy: 0.9987 - val_loss: 0.0071\n",
      "Epoch 89/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.7993e-10\n",
      "Epoch 89: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.8001e-10 - val_accuracy: 0.9987 - val_loss: 0.0072\n",
      "Epoch 90/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.6577e-10\n",
      "Epoch 90: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.6577e-10 - val_accuracy: 0.9987 - val_loss: 0.0074\n",
      "Epoch 91/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.9374e-10\n",
      "Epoch 91: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.9371e-10 - val_accuracy: 0.9987 - val_loss: 0.0071\n",
      "Epoch 92/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.1456e-10\n",
      "Epoch 92: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.1485e-10 - val_accuracy: 0.9987 - val_loss: 0.0073\n",
      "Epoch 93/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.8870e-10\n",
      "Epoch 93: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.8870e-10 - val_accuracy: 0.9987 - val_loss: 0.0069\n",
      "Epoch 94/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7401e-10\n",
      "Epoch 94: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.7419e-10 - val_accuracy: 0.9987 - val_loss: 0.0069\n",
      "Epoch 95/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.6547e-10\n",
      "Epoch 95: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 1.6580e-10 - val_accuracy: 0.9987 - val_loss: 0.0074\n",
      "Epoch 96/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.1729e-10\n",
      "Epoch 96: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.1735e-10 - val_accuracy: 0.9987 - val_loss: 0.0073\n",
      "Epoch 97/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 4.9302e-10\n",
      "Epoch 97: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.9140e-10 - val_accuracy: 0.9987 - val_loss: 0.0082\n",
      "Epoch 98/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.8260e-10\n",
      "Epoch 98: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.8248e-10 - val_accuracy: 0.9987 - val_loss: 0.0064\n",
      "Epoch 99/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.0979e-10\n",
      "Epoch 99: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.1006e-10 - val_accuracy: 0.9987 - val_loss: 0.0087\n",
      "Epoch 100/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9673 - loss: 0.2648\n",
      "Epoch 100: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - accuracy: 0.9674 - loss: 0.2641 - val_accuracy: 0.9920 - val_loss: 0.0201\n",
      "Epoch 101/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9930 - loss: 0.0212\n",
      "Epoch 101: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - accuracy: 0.9930 - loss: 0.0212 - val_accuracy: 0.9949 - val_loss: 0.0132\n",
      "Epoch 102/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9979 - loss: 0.0067\n",
      "Epoch 102: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.9975 - val_loss: 0.0063\n",
      "Epoch 103/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 103: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9975 - val_loss: 0.0087\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp6/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:53:59.644180: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:53:59.647359: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.0354e-08\n",
      "\u001b[1m11/75\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9997 - loss: 0.0029    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:54:09.522815: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:54:09.523331: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9990 - loss: 0.0076\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9996 - loss: 0.0015\n",
      "Epoch 1/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4912 - loss: 1.3335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:54:33.004118: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:54:33.005494: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87547, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 66ms/step - accuracy: 0.4919 - loss: 1.3316 - val_accuracy: 0.8755 - val_loss: 0.3105\n",
      "Epoch 2/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8841 - loss: 0.2973\n",
      "Epoch 2: val_accuracy improved from 0.87547 to 0.93162, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 0.8842 - loss: 0.2971 - val_accuracy: 0.9316 - val_loss: 0.1528\n",
      "Epoch 3/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9307 - loss: 0.1679\n",
      "Epoch 3: val_accuracy improved from 0.93162 to 0.94639, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - accuracy: 0.9308 - loss: 0.1679 - val_accuracy: 0.9464 - val_loss: 0.1344\n",
      "Epoch 4/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9598 - loss: 0.1037\n",
      "Epoch 4: val_accuracy improved from 0.94639 to 0.94977, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.9598 - loss: 0.1036 - val_accuracy: 0.9498 - val_loss: 0.1265\n",
      "Epoch 5/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9751 - loss: 0.0683\n",
      "Epoch 5: val_accuracy improved from 0.94977 to 0.96032, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.9751 - loss: 0.0683 - val_accuracy: 0.9603 - val_loss: 0.1133\n",
      "Epoch 6/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9753 - loss: 0.0693\n",
      "Epoch 6: val_accuracy improved from 0.96032 to 0.98565, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9753 - loss: 0.0692 - val_accuracy: 0.9856 - val_loss: 0.0358\n",
      "Epoch 7/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9813 - loss: 0.0501\n",
      "Epoch 7: val_accuracy did not improve from 0.98565\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9813 - loss: 0.0501 - val_accuracy: 0.9574 - val_loss: 0.1056\n",
      "Epoch 8/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9881 - loss: 0.0367\n",
      "Epoch 8: val_accuracy improved from 0.98565 to 0.99198, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.9881 - loss: 0.0368 - val_accuracy: 0.9920 - val_loss: 0.0273\n",
      "Epoch 9/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9931 - loss: 0.0207\n",
      "Epoch 9: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0207 - val_accuracy: 0.9489 - val_loss: 0.1448\n",
      "Epoch 10/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9929 - loss: 0.0195\n",
      "Epoch 10: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - accuracy: 0.9929 - loss: 0.0195 - val_accuracy: 0.9899 - val_loss: 0.0266\n",
      "Epoch 11/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9934 - loss: 0.0201\n",
      "Epoch 11: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.9933 - loss: 0.0205 - val_accuracy: 0.9709 - val_loss: 0.1063\n",
      "Epoch 12/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9822 - loss: 0.0571\n",
      "Epoch 12: val_accuracy improved from 0.99198 to 0.99536, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 0.9822 - loss: 0.0570 - val_accuracy: 0.9954 - val_loss: 0.0162\n",
      "Epoch 13/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9922 - loss: 0.0245\n",
      "Epoch 13: val_accuracy did not improve from 0.99536\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.9922 - loss: 0.0245 - val_accuracy: 0.9941 - val_loss: 0.0151\n",
      "Epoch 14/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9949 - loss: 0.0137\n",
      "Epoch 14: val_accuracy did not improve from 0.99536\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9949 - loss: 0.0137 - val_accuracy: 0.9882 - val_loss: 0.0313\n",
      "Epoch 15/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9924 - loss: 0.0226\n",
      "Epoch 15: val_accuracy did not improve from 0.99536\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9924 - loss: 0.0226 - val_accuracy: 0.9924 - val_loss: 0.0214\n",
      "Epoch 16/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9953 - loss: 0.0137\n",
      "Epoch 16: val_accuracy did not improve from 0.99536\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.9903 - val_loss: 0.0536\n",
      "Epoch 17/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9961 - loss: 0.0143\n",
      "Epoch 17: val_accuracy did not improve from 0.99536\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9961 - loss: 0.0143 - val_accuracy: 0.9945 - val_loss: 0.0136\n",
      "Epoch 18/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9961 - loss: 0.0098\n",
      "Epoch 18: val_accuracy improved from 0.99536 to 0.99789, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9961 - loss: 0.0097 - val_accuracy: 0.9979 - val_loss: 0.0061\n",
      "Epoch 19/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0021\n",
      "Epoch 19: val_accuracy did not improve from 0.99789\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9979 - val_loss: 0.0057\n",
      "Epoch 20/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.0965e-04\n",
      "Epoch 20: val_accuracy improved from 0.99789 to 0.99873, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.0883e-04 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 21/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.2539e-04\n",
      "Epoch 21: val_accuracy improved from 0.99873 to 0.99916, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.2524e-04 - val_accuracy: 0.9992 - val_loss: 0.0037\n",
      "Epoch 22/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.4668e-05\n",
      "Epoch 22: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.4582e-05 - val_accuracy: 0.9992 - val_loss: 0.0034\n",
      "Epoch 23/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.0736e-05\n",
      "Epoch 23: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.0683e-05 - val_accuracy: 0.9992 - val_loss: 0.0031\n",
      "Epoch 24/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.5217e-05\n",
      "Epoch 24: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.5168e-05 - val_accuracy: 0.9992 - val_loss: 0.0030\n",
      "Epoch 25/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.5028e-05\n",
      "Epoch 25: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.5004e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 26/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.7979e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.7950e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 27/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2628e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.2605e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8439e-05\n",
      "Epoch 28: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8421e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.5191e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.5176e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 30/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2561e-05\n",
      "Epoch 30: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2553e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 31/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0419e-05\n",
      "Epoch 31: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0412e-05 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 32/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.6673e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.6614e-06 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 33/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.2498e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.2448e-06 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 34/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0123e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.0062e-06 - val_accuracy: 0.9992 - val_loss: 0.0030\n",
      "Epoch 35/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.9939e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.9905e-06 - val_accuracy: 0.9992 - val_loss: 0.0032\n",
      "Epoch 36/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1390e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.1347e-06 - val_accuracy: 0.9992 - val_loss: 0.0032\n",
      "Epoch 37/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.4108e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.4074e-06 - val_accuracy: 0.9992 - val_loss: 0.0033\n",
      "Epoch 38/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.7933e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7915e-06 - val_accuracy: 0.9992 - val_loss: 0.0032\n",
      "Epoch 39/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2839e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.2824e-06 - val_accuracy: 0.9992 - val_loss: 0.0032\n",
      "Epoch 40/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8442e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8424e-06 - val_accuracy: 0.9992 - val_loss: 0.0031\n",
      "Epoch 41/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4958e-06\n",
      "Epoch 41: val_accuracy improved from 0.99916 to 0.99958, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4953e-06 - val_accuracy: 0.9996 - val_loss: 0.0031\n",
      "Epoch 42/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.2184e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.2172e-06 - val_accuracy: 0.9996 - val_loss: 0.0030\n",
      "Epoch 43/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.9079e-07\n",
      "Epoch 43: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.8987e-07 - val_accuracy: 0.9996 - val_loss: 0.0030\n",
      "Epoch 44/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.1096e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.1022e-07 - val_accuracy: 0.9996 - val_loss: 0.0030\n",
      "Epoch 45/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.6361e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.6342e-07 - val_accuracy: 0.9996 - val_loss: 0.0031\n",
      "Epoch 46/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.4736e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.4693e-07 - val_accuracy: 0.9996 - val_loss: 0.0031\n",
      "Epoch 47/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.5343e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.5322e-07 - val_accuracy: 0.9996 - val_loss: 0.0031\n",
      "Epoch 48/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.7957e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7931e-07 - val_accuracy: 0.9996 - val_loss: 0.0032\n",
      "Epoch 49/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1536e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.1524e-07 - val_accuracy: 0.9996 - val_loss: 0.0032\n",
      "Epoch 50/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.6570e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6565e-07 - val_accuracy: 0.9996 - val_loss: 0.0032\n",
      "Epoch 51/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2277e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2270e-07 - val_accuracy: 0.9996 - val_loss: 0.0033\n",
      "Epoch 52/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8610e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8604e-07 - val_accuracy: 0.9996 - val_loss: 0.0033\n",
      "Epoch 53/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5685e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5682e-07 - val_accuracy: 0.9996 - val_loss: 0.0033\n",
      "Epoch 54/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3206e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3203e-07 - val_accuracy: 0.9996 - val_loss: 0.0034\n",
      "Epoch 55/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1183e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1182e-07 - val_accuracy: 0.9996 - val_loss: 0.0034\n",
      "Epoch 56/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.4546e-08\n",
      "Epoch 56: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.4543e-08 - val_accuracy: 0.9996 - val_loss: 0.0034\n",
      "Epoch 57/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.9969e-08\n",
      "Epoch 57: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.9970e-08 - val_accuracy: 0.9996 - val_loss: 0.0035\n",
      "Epoch 58/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.7875e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.7879e-08 - val_accuracy: 0.9996 - val_loss: 0.0035\n",
      "Epoch 59/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.8134e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.8137e-08 - val_accuracy: 0.9996 - val_loss: 0.0035\n",
      "Epoch 60/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.9593e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.9597e-08 - val_accuracy: 0.9996 - val_loss: 0.0035\n",
      "Epoch 61/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.2063e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2069e-08 - val_accuracy: 0.9996 - val_loss: 0.0035\n",
      "Epoch 62/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.6074e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.6077e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 63/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.0854e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.0859e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 64/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.6282e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.6288e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 65/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.2572e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.2579e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 66/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.9281e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9287e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 67/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6514e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6520e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 68/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4316e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4320e-08 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 69/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2093e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2098e-08 - val_accuracy: 0.9996 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0343e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0348e-08 - val_accuracy: 0.9996 - val_loss: 0.0037\n",
      "Epoch 71/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.8654e-09\n",
      "Epoch 71: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.8683e-09 - val_accuracy: 0.9996 - val_loss: 0.0037\n",
      "Epoch 72/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.4807e-09\n",
      "Epoch 72: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.4859e-09 - val_accuracy: 0.9996 - val_loss: 0.0037\n",
      "Epoch 73/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.5007e-09\n",
      "Epoch 73: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5030e-09 - val_accuracy: 0.9996 - val_loss: 0.0037\n",
      "Epoch 74/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.8434e-09\n",
      "Epoch 74: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8448e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 75/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.8528e-09\n",
      "Epoch 75: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.8560e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 76/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.1810e-09\n",
      "Epoch 76: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.1830e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 77/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6779e-09\n",
      "Epoch 77: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.6790e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 78/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.1694e-09\n",
      "Epoch 78: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1703e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 79/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.5787e-09\n",
      "Epoch 79: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5814e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 80/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.3006e-09\n",
      "Epoch 80: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3020e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 81/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.8609e-09\n",
      "Epoch 81: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8615e-09 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
      "Epoch 82/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.6151e-09\n",
      "Epoch 82: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.6163e-09 - val_accuracy: 0.9996 - val_loss: 0.0039\n",
      "Epoch 83/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.4608e-09\n",
      "Epoch 83: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.4615e-09 - val_accuracy: 0.9996 - val_loss: 0.0040\n",
      "Epoch 84/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3380e-09\n",
      "Epoch 84: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3383e-09 - val_accuracy: 0.9996 - val_loss: 0.0039\n",
      "Epoch 85/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.1340e-09\n",
      "Epoch 85: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1343e-09 - val_accuracy: 0.9996 - val_loss: 0.0039\n",
      "Epoch 86/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0672e-09\n",
      "Epoch 86: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.0673e-09 - val_accuracy: 0.9996 - val_loss: 0.0039\n",
      "Epoch 87/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 9.1733e-10\n",
      "Epoch 87: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.1716e-10 - val_accuracy: 0.9996 - val_loss: 0.0039\n",
      "Epoch 88/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.0213e-10\n",
      "Epoch 88: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.0226e-10 - val_accuracy: 0.9996 - val_loss: 0.0039\n",
      "Epoch 89/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.8201e-10\n",
      "Epoch 89: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.8211e-10 - val_accuracy: 0.9996 - val_loss: 0.0040\n",
      "Epoch 90/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.5146e-10\n",
      "Epoch 90: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.5274e-10 - val_accuracy: 0.9996 - val_loss: 0.0041\n",
      "Epoch 91/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.3806e-10\n",
      "Epoch 91: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.3832e-10 - val_accuracy: 0.9996 - val_loss: 0.0041\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp6/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m 5/75\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:14:14.938759: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 09:14:14.940025: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.1363e-06\n",
      "\u001b[1m15/75\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0012    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:14:20.436861: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 09:14:20.437238: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0017\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.6579e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5185 - loss: 1.2811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:14:36.920488: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 09:14:36.920835: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91473, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.5199 - loss: 1.2774 - val_accuracy: 0.9147 - val_loss: 0.2370\n",
      "Epoch 2/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9020 - loss: 0.2627\n",
      "Epoch 2: val_accuracy improved from 0.91473 to 0.95399, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.9021 - loss: 0.2623 - val_accuracy: 0.9540 - val_loss: 0.1259\n",
      "Epoch 3/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9495 - loss: 0.1379\n",
      "Epoch 3: val_accuracy did not improve from 0.95399\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.9496 - loss: 0.1378 - val_accuracy: 0.9232 - val_loss: 0.2006\n",
      "Epoch 4/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9654 - loss: 0.0947\n",
      "Epoch 4: val_accuracy improved from 0.95399 to 0.98227, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9654 - loss: 0.0946 - val_accuracy: 0.9823 - val_loss: 0.0517\n",
      "Epoch 5/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9706 - loss: 0.0879\n",
      "Epoch 5: val_accuracy did not improve from 0.98227\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.9706 - loss: 0.0879 - val_accuracy: 0.9126 - val_loss: 0.2654\n",
      "Epoch 6/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9774 - loss: 0.0690\n",
      "Epoch 6: val_accuracy did not improve from 0.98227\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9774 - loss: 0.0689 - val_accuracy: 0.9814 - val_loss: 0.0521\n",
      "Epoch 7/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0495\n",
      "Epoch 7: val_accuracy improved from 0.98227 to 0.98776, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9834 - loss: 0.0495 - val_accuracy: 0.9878 - val_loss: 0.0426\n",
      "Epoch 8/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0516\n",
      "Epoch 8: val_accuracy did not improve from 0.98776\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9837 - loss: 0.0515 - val_accuracy: 0.9721 - val_loss: 0.0742\n",
      "Epoch 9/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9909 - loss: 0.0283\n",
      "Epoch 9: val_accuracy improved from 0.98776 to 0.99198, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9909 - loss: 0.0282 - val_accuracy: 0.9920 - val_loss: 0.0274\n",
      "Epoch 10/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9912 - loss: 0.0279\n",
      "Epoch 10: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9911 - loss: 0.0282 - val_accuracy: 0.9751 - val_loss: 0.0765\n",
      "Epoch 11/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9844 - loss: 0.0492\n",
      "Epoch 11: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9845 - loss: 0.0490 - val_accuracy: 0.9869 - val_loss: 0.0388\n",
      "Epoch 12/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9916 - loss: 0.0242\n",
      "Epoch 12: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.9916 - loss: 0.0242 - val_accuracy: 0.9920 - val_loss: 0.0305\n",
      "Epoch 13/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9968 - loss: 0.0101\n",
      "Epoch 13: val_accuracy did not improve from 0.99198\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.9806 - val_loss: 0.0574\n",
      "Epoch 14/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9932 - loss: 0.0162\n",
      "Epoch 14: val_accuracy improved from 0.99198 to 0.99536, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.9933 - loss: 0.0162 - val_accuracy: 0.9954 - val_loss: 0.0112\n",
      "Epoch 15/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9976 - loss: 0.0078\n",
      "Epoch 15: val_accuracy improved from 0.99536 to 0.99789, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 0.9976 - loss: 0.0078 - val_accuracy: 0.9979 - val_loss: 0.0072\n",
      "Epoch 16/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9989 - loss: 0.0030\n",
      "Epoch 16: val_accuracy did not improve from 0.99789\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9937 - val_loss: 0.0246\n",
      "Epoch 17/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9846 - loss: 0.0520\n",
      "Epoch 17: val_accuracy did not improve from 0.99789\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - accuracy: 0.9846 - loss: 0.0519 - val_accuracy: 0.9620 - val_loss: 0.1270\n",
      "Epoch 18/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9483 - loss: 0.2316\n",
      "Epoch 18: val_accuracy improved from 0.99789 to 0.99831, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9485 - loss: 0.2307 - val_accuracy: 0.9983 - val_loss: 0.0097\n",
      "Epoch 19/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9989 - loss: 0.0045\n",
      "Epoch 19: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9975 - val_loss: 0.0111\n",
      "Epoch 20/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9970 - loss: 0.0108\n",
      "Epoch 20: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.9865 - val_loss: 0.0418\n",
      "Epoch 21/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9937 - loss: 0.0192\n",
      "Epoch 21: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.9983 - val_loss: 0.0054\n",
      "Epoch 22/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 7.3112e-04\n",
      "Epoch 22: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 7.3114e-04 - val_accuracy: 0.9962 - val_loss: 0.0146\n",
      "Epoch 23/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9984 - loss: 0.0046\n",
      "Epoch 23: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9970 - val_loss: 0.0143\n",
      "Epoch 24/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9985 - loss: 0.0063\n",
      "Epoch 24: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9979 - val_loss: 0.0041\n",
      "Epoch 25/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.9929e-04\n",
      "Epoch 25: val_accuracy did not improve from 0.99831\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.9699e-04 - val_accuracy: 0.9983 - val_loss: 0.0030\n",
      "Epoch 26/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.0950e-05\n",
      "Epoch 26: val_accuracy improved from 0.99831 to 0.99916, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.1031e-05 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 27/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.8404e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.8454e-05 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 28/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9332e-05\n",
      "Epoch 28: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.9364e-05 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 29/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.3384e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3406e-05 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 30/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8985e-05\n",
      "Epoch 30: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9008e-05 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 31/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5558e-05\n",
      "Epoch 31: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.5570e-05 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 32/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2883e-05\n",
      "Epoch 32: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2896e-05 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 33/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0704e-05\n",
      "Epoch 33: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0713e-05 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 34/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.9395e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.9467e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 35/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 7.5101e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5137e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 36/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.2890e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.2918e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 37/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2987e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.2998e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 38/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.4776e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.4791e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 39/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.7750e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.7762e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 40/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.1797e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.1806e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 41/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.6870e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.6879e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 42/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2595e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.2602e-06 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 43/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.9019e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.9023e-06 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 44/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.6043e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.6046e-06 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 45/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3477e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3480e-06 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 46/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1412e-06\n",
      "Epoch 46: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1413e-06 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 47/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.5989e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.6004e-07 - val_accuracy: 0.9992 - val_loss: 0.0025\n",
      "Epoch 48/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.1061e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.1072e-07 - val_accuracy: 0.9992 - val_loss: 0.0025\n",
      "Epoch 49/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.8517e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.8525e-07 - val_accuracy: 0.9992 - val_loss: 0.0025\n",
      "Epoch 50/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.7946e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7952e-07 - val_accuracy: 0.9992 - val_loss: 0.0025\n",
      "Epoch 51/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.8935e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.8941e-07 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 52/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1429e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.1432e-07 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 53/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.5022e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.5024e-07 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 54/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9635e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.9637e-07 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 55/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.5114e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.5114e-07 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 56/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.1295e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.1295e-07 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 57/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8055e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8055e-07 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 58/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.5322e-07\n",
      "Epoch 58: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.5322e-07 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 59/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3038e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3037e-07 - val_accuracy: 0.9987 - val_loss: 0.0027\n",
      "Epoch 60/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1044e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.1043e-07 - val_accuracy: 0.9987 - val_loss: 0.0027\n",
      "Epoch 61/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.3684e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.3679e-08 - val_accuracy: 0.9987 - val_loss: 0.0027\n",
      "Epoch 62/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.9381e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.9375e-08 - val_accuracy: 0.9987 - val_loss: 0.0027\n",
      "Epoch 63/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.7579e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.7574e-08 - val_accuracy: 0.9987 - val_loss: 0.0027\n",
      "Epoch 64/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.7083e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7079e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 65/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 4.8657e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 4.8655e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 66/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 4.1513e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 4.1507e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 67/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5126e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.5122e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 68/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.9804e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.9802e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 69/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.5464e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.5460e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 70/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.1704e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.1700e-08 - val_accuracy: 0.9987 - val_loss: 0.0028\n",
      "Epoch 71/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.8605e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.8604e-08 - val_accuracy: 0.9987 - val_loss: 0.0029\n",
      "Epoch 72/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5988e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5985e-08 - val_accuracy: 0.9987 - val_loss: 0.0029\n",
      "Epoch 73/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.3537e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.3535e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 74/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.1457e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1456e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 9.9593e-09\n",
      "Epoch 75: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 9.9570e-09 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.4556e-09\n",
      "Epoch 76: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.4539e-09 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp6/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m10/75\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:32:51.879924: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 09:32:51.880672: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.5527e-05\n",
      "\u001b[1m16/75\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:32:57.160338: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 09:32:57.160676: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9988 - loss: 0.0025\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0014\n",
      "Epoch 1/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4765 - loss: 1.2996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:33:12.747832: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 09:33:12.748209: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87547, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.4780 - loss: 1.2962 - val_accuracy: 0.8755 - val_loss: 0.3122\n",
      "Epoch 2/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8892 - loss: 0.2833\n",
      "Epoch 2: val_accuracy improved from 0.87547 to 0.96285, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.8894 - loss: 0.2830 - val_accuracy: 0.9629 - val_loss: 0.1031\n",
      "Epoch 3/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9497 - loss: 0.1446\n",
      "Epoch 3: val_accuracy improved from 0.96285 to 0.96792, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9498 - loss: 0.1444 - val_accuracy: 0.9679 - val_loss: 0.0891\n",
      "Epoch 4/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9681 - loss: 0.0912\n",
      "Epoch 4: val_accuracy did not improve from 0.96792\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 0.9681 - loss: 0.0911 - val_accuracy: 0.9671 - val_loss: 0.1000\n",
      "Epoch 5/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9688 - loss: 0.0903\n",
      "Epoch 5: val_accuracy did not improve from 0.96792\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9688 - loss: 0.0902 - val_accuracy: 0.9548 - val_loss: 0.1186\n",
      "Epoch 6/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9777 - loss: 0.0647\n",
      "Epoch 6: val_accuracy improved from 0.96792 to 0.98649, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9777 - loss: 0.0646 - val_accuracy: 0.9865 - val_loss: 0.0312\n",
      "Epoch 7/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9857 - loss: 0.0410\n",
      "Epoch 7: val_accuracy did not improve from 0.98649\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9857 - loss: 0.0410 - val_accuracy: 0.9717 - val_loss: 0.0755\n",
      "Epoch 8/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9886 - loss: 0.0328\n",
      "Epoch 8: val_accuracy improved from 0.98649 to 0.99114, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.9886 - loss: 0.0329 - val_accuracy: 0.9911 - val_loss: 0.0306\n",
      "Epoch 9/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9909 - loss: 0.0247\n",
      "Epoch 9: val_accuracy improved from 0.99114 to 0.99367, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9909 - loss: 0.0247 - val_accuracy: 0.9937 - val_loss: 0.0142\n",
      "Epoch 10/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9957 - loss: 0.0136\n",
      "Epoch 10: val_accuracy improved from 0.99367 to 0.99578, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9957 - loss: 0.0136 - val_accuracy: 0.9958 - val_loss: 0.0109\n",
      "Epoch 11/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9905 - loss: 0.0306\n",
      "Epoch 11: val_accuracy did not improve from 0.99578\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9904 - loss: 0.0307 - val_accuracy: 0.9764 - val_loss: 0.0581\n",
      "Epoch 12/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9876 - loss: 0.0296\n",
      "Epoch 12: val_accuracy did not improve from 0.99578\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9876 - loss: 0.0296 - val_accuracy: 0.9650 - val_loss: 0.1013\n",
      "Epoch 13/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9933 - loss: 0.0188\n",
      "Epoch 13: val_accuracy improved from 0.99578 to 0.99662, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9933 - loss: 0.0188 - val_accuracy: 0.9966 - val_loss: 0.0078\n",
      "Epoch 14/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9952 - loss: 0.0143\n",
      "Epoch 14: val_accuracy did not improve from 0.99662\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.9835 - val_loss: 0.0510\n",
      "Epoch 15/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9927 - loss: 0.0205\n",
      "Epoch 15: val_accuracy did not improve from 0.99662\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9927 - loss: 0.0205 - val_accuracy: 0.9818 - val_loss: 0.0647\n",
      "Epoch 16/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9844 - loss: 0.0581\n",
      "Epoch 16: val_accuracy did not improve from 0.99662\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9845 - loss: 0.0580 - val_accuracy: 0.9954 - val_loss: 0.0122\n",
      "Epoch 17/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9929 - loss: 0.0206\n",
      "Epoch 17: val_accuracy improved from 0.99662 to 0.99958, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 0.9996 - val_loss: 0.0036\n",
      "Epoch 18/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9971 - loss: 0.0092\n",
      "Epoch 18: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9983 - val_loss: 0.0050\n",
      "Epoch 19/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9997 - loss: 0.0022\n",
      "Epoch 19: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9979 - val_loss: 0.0043\n",
      "Epoch 20/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.9482e-04\n",
      "Epoch 20: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9294e-04 - val_accuracy: 0.9992 - val_loss: 0.0020\n",
      "Epoch 21/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.5901e-04\n",
      "Epoch 21: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.5833e-04 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 22/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2212e-04\n",
      "Epoch 22: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2191e-04 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 23/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.3240e-05\n",
      "Epoch 23: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.3029e-05 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 24/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.0333e-05\n",
      "Epoch 24: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0199e-05 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 25/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.5518e-05\n",
      "Epoch 25: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5454e-05 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 26/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.5131e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.5064e-05 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 27/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.7597e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.7565e-05 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 28/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.1852e-05\n",
      "Epoch 28: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1817e-05 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 29/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7516e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.7491e-05 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 30/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4267e-05\n",
      "Epoch 30: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4254e-05 - val_accuracy: 0.9992 - val_loss: 0.0015\n",
      "Epoch 31/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1705e-05\n",
      "Epoch 31: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.1695e-05 - val_accuracy: 0.9992 - val_loss: 0.0015\n",
      "Epoch 32/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 9.6366e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.6245e-06 - val_accuracy: 0.9992 - val_loss: 0.0015\n",
      "Epoch 33/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.9995e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.9931e-06 - val_accuracy: 0.9992 - val_loss: 0.0015\n",
      "Epoch 34/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.6679e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.6653e-06 - val_accuracy: 0.9992 - val_loss: 0.0015\n",
      "Epoch 35/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.5692e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.5649e-06 - val_accuracy: 0.9992 - val_loss: 0.0015\n",
      "Epoch 36/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.6598e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.6563e-06 - val_accuracy: 0.9992 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.9176e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.9162e-06 - val_accuracy: 0.9992 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.2953e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.2929e-06 - val_accuracy: 0.9992 - val_loss: 0.0016\n",
      "Epoch 39/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.7679e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 2.7658e-06 - val_accuracy: 0.9992 - val_loss: 0.0016\n",
      "Epoch 40/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.3329e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.3312e-06 - val_accuracy: 0.9992 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.9684e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.9669e-06 - val_accuracy: 0.9992 - val_loss: 0.0016\n",
      "Epoch 42/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.6539e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.6527e-06 - val_accuracy: 0.9992 - val_loss: 0.0017\n",
      "Epoch 43/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.4011e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3995e-06 - val_accuracy: 0.9992 - val_loss: 0.0017\n",
      "Epoch 44/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1698e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1690e-06 - val_accuracy: 0.9992 - val_loss: 0.0017\n",
      "Epoch 45/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.7194e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7104e-07 - val_accuracy: 0.9992 - val_loss: 0.0018\n",
      "Epoch 46/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.6313e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.6213e-07 - val_accuracy: 0.9992 - val_loss: 0.0018\n",
      "Epoch 47/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9060e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.8940e-07 - val_accuracy: 0.9992 - val_loss: 0.0019\n",
      "Epoch 48/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.8760e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.8654e-07 - val_accuracy: 0.9992 - val_loss: 0.0020\n",
      "Epoch 49/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.0482e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0390e-07 - val_accuracy: 0.9992 - val_loss: 0.0021\n",
      "Epoch 50/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.3991e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.3938e-07 - val_accuracy: 0.9992 - val_loss: 0.0022\n",
      "Epoch 51/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8385e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.8340e-07 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
      "Epoch 52/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3910e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.3872e-07 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 53/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.0160e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.0128e-07 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 54/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6902e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.6862e-07 - val_accuracy: 0.9992 - val_loss: 0.0025\n",
      "Epoch 55/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4285e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4251e-07 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 56/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2120e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2101e-07 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 57/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0241e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0225e-07 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 58/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.6615e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 8.6484e-08 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 59/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.3843e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.3787e-08 - val_accuracy: 0.9992 - val_loss: 0.0027\n",
      "Epoch 60/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3059e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.2917e-08 - val_accuracy: 0.9992 - val_loss: 0.0028\n",
      "Epoch 61/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.3252e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.3172e-08 - val_accuracy: 0.9992 - val_loss: 0.0028\n",
      "Epoch 62/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.5633e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.5599e-08 - val_accuracy: 0.9992 - val_loss: 0.0028\n",
      "Epoch 63/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.8995e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8937e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 64/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.3214e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.3140e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 65/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.8238e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.8176e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 66/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.4039e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.4022e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.0562e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.0518e-08 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp6/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m 1/75\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 186ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:48:25.692011: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 09:48:25.694506: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9999 - loss: 0.0017\n",
      "\u001b[1m14/75\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:48:32.133920: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 09:48:32.134243: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0036\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9993 - loss: 0.0044\n",
      "Epoch 1/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5240 - loss: 1.2335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:48:49.887207: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 09:48:49.887782: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67117, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.5254 - loss: 1.2299 - val_accuracy: 0.6712 - val_loss: 1.0292\n",
      "Epoch 2/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8612 - loss: 0.3907\n",
      "Epoch 2: val_accuracy improved from 0.67117 to 0.95526, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.8615 - loss: 0.3898 - val_accuracy: 0.9553 - val_loss: 0.1415\n",
      "Epoch 3/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9449 - loss: 0.1546\n",
      "Epoch 3: val_accuracy improved from 0.95526 to 0.97721, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.9450 - loss: 0.1545 - val_accuracy: 0.9772 - val_loss: 0.0727\n",
      "Epoch 4/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9663 - loss: 0.0918\n",
      "Epoch 4: val_accuracy improved from 0.97721 to 0.98269, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9664 - loss: 0.0917 - val_accuracy: 0.9827 - val_loss: 0.0477\n",
      "Epoch 5/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9815 - loss: 0.0524\n",
      "Epoch 5: val_accuracy improved from 0.98269 to 0.98818, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9815 - loss: 0.0525 - val_accuracy: 0.9882 - val_loss: 0.0303\n",
      "Epoch 6/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9852 - loss: 0.0458\n",
      "Epoch 6: val_accuracy improved from 0.98818 to 0.98945, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9852 - loss: 0.0459 - val_accuracy: 0.9894 - val_loss: 0.0261\n",
      "Epoch 7/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9835 - loss: 0.0511\n",
      "Epoch 7: val_accuracy improved from 0.98945 to 0.99156, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.9835 - loss: 0.0511 - val_accuracy: 0.9916 - val_loss: 0.0210\n",
      "Epoch 8/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9895 - loss: 0.0290\n",
      "Epoch 8: val_accuracy did not improve from 0.99156\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9895 - loss: 0.0291 - val_accuracy: 0.9823 - val_loss: 0.0592\n",
      "Epoch 9/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9781 - loss: 0.0672\n",
      "Epoch 9: val_accuracy did not improve from 0.99156\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9781 - loss: 0.0671 - val_accuracy: 0.9903 - val_loss: 0.0255\n",
      "Epoch 10/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9945 - loss: 0.0154\n",
      "Epoch 10: val_accuracy improved from 0.99156 to 0.99325, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9945 - loss: 0.0154 - val_accuracy: 0.9932 - val_loss: 0.0214\n",
      "Epoch 11/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9966 - loss: 0.0092\n",
      "Epoch 11: val_accuracy did not improve from 0.99325\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9764 - val_loss: 0.0879\n",
      "Epoch 12/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9796 - loss: 0.0568\n",
      "Epoch 12: val_accuracy improved from 0.99325 to 0.99873, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9797 - loss: 0.0567 - val_accuracy: 0.9987 - val_loss: 0.0069\n",
      "Epoch 13/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9985 - loss: 0.0051\n",
      "Epoch 13: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9531 - val_loss: 0.1706\n",
      "Epoch 14/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9901 - loss: 0.0287\n",
      "Epoch 14: val_accuracy did not improve from 0.99873\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9901 - loss: 0.0286 - val_accuracy: 0.9958 - val_loss: 0.0127\n",
      "Epoch 15/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9979 - loss: 0.0059\n",
      "Epoch 15: val_accuracy improved from 0.99873 to 0.99916, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9992 - val_loss: 0.0040\n",
      "Epoch 16/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9931 - loss: 0.0202\n",
      "Epoch 16: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 0.9931 - loss: 0.0203 - val_accuracy: 0.9983 - val_loss: 0.0041\n",
      "Epoch 17/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9984 - loss: 0.0038\n",
      "Epoch 17: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9984 - loss: 0.0038 - val_accuracy: 0.9954 - val_loss: 0.0114\n",
      "Epoch 18/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 18: val_accuracy did not improve from 0.99916\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9975 - val_loss: 0.0077\n",
      "Epoch 19/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9989 - loss: 0.0030\n",
      "Epoch 19: val_accuracy improved from 0.99916 to 0.99958, saving model to CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9996 - val_loss: 0.0017\n",
      "Epoch 20/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.9893e-05\n",
      "Epoch 20: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9801e-05 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 21/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.7688e-05\n",
      "Epoch 21: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.7628e-05 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.6183e-05\n",
      "Epoch 22: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6160e-05 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.8634e-05\n",
      "Epoch 23: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8597e-05 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 24/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3099e-05\n",
      "Epoch 24: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.3069e-05 - val_accuracy: 0.9996 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8858e-05\n",
      "Epoch 25: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8822e-05 - val_accuracy: 0.9996 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.4597e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4566e-05 - val_accuracy: 0.9996 - val_loss: 9.3923e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1406e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1398e-05 - val_accuracy: 0.9996 - val_loss: 9.2262e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.0596e-06\n",
      "Epoch 28: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0464e-06 - val_accuracy: 0.9996 - val_loss: 8.9141e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.2694e-06\n",
      "Epoch 29: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.2582e-06 - val_accuracy: 0.9996 - val_loss: 8.7756e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.8957e-06\n",
      "Epoch 30: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.8864e-06 - val_accuracy: 0.9996 - val_loss: 8.8071e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.7920e-06\n",
      "Epoch 31: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.7842e-06 - val_accuracy: 0.9996 - val_loss: 8.7196e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.8967e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8904e-06 - val_accuracy: 0.9996 - val_loss: 8.5668e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.1601e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1526e-06 - val_accuracy: 0.9996 - val_loss: 8.4028e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.6208e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.6167e-06 - val_accuracy: 0.9996 - val_loss: 8.2553e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1842e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1792e-06 - val_accuracy: 0.9996 - val_loss: 8.3178e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.8193e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.8165e-06 - val_accuracy: 0.9996 - val_loss: 8.3872e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5343e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5320e-06 - val_accuracy: 0.9996 - val_loss: 8.4356e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2971e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.2952e-06 - val_accuracy: 0.9996 - val_loss: 8.4876e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0981e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0957e-06 - val_accuracy: 0.9996 - val_loss: 8.4696e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.3275e-07\n",
      "Epoch 40: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.3139e-07 - val_accuracy: 0.9996 - val_loss: 8.6851e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.9373e-07\n",
      "Epoch 41: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 7.9201e-07 - val_accuracy: 0.9996 - val_loss: 8.6978e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.7805e-07\n",
      "Epoch 42: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.7658e-07 - val_accuracy: 0.9996 - val_loss: 8.6793e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7784e-07\n",
      "Epoch 43: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.7660e-07 - val_accuracy: 0.9996 - val_loss: 8.6777e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9236e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.9166e-07 - val_accuracy: 0.9992 - val_loss: 8.8025e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.2012e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.1953e-07 - val_accuracy: 0.9992 - val_loss: 8.8504e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.5808e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.5758e-07 - val_accuracy: 0.9992 - val_loss: 8.7530e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.0457e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.0394e-07 - val_accuracy: 0.9992 - val_loss: 8.9478e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.6007e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.5954e-07 - val_accuracy: 0.9992 - val_loss: 9.0887e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2194e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.2164e-07 - val_accuracy: 0.9992 - val_loss: 9.0952e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.8988e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.8963e-07 - val_accuracy: 0.9996 - val_loss: 9.1058e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.6234e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.6213e-07 - val_accuracy: 0.9996 - val_loss: 9.1843e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3861e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3834e-07 - val_accuracy: 0.9996 - val_loss: 9.3401e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.1777e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.1769e-07 - val_accuracy: 0.9996 - val_loss: 9.4819e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0029e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.0017e-07 - val_accuracy: 0.9996 - val_loss: 9.5490e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.5525e-08\n",
      "Epoch 55: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.5418e-08 - val_accuracy: 0.9996 - val_loss: 9.7336e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.2919e-08\n",
      "Epoch 56: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.2783e-08 - val_accuracy: 0.9996 - val_loss: 9.8445e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.2290e-08\n",
      "Epoch 57: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.2175e-08 - val_accuracy: 0.9996 - val_loss: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2999e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.2935e-08 - val_accuracy: 0.9996 - val_loss: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.4971e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.4889e-08 - val_accuracy: 0.9996 - val_loss: 0.0011\n",
      "Epoch 60/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9041e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.8994e-08 - val_accuracy: 0.9996 - val_loss: 0.0011\n",
      "Epoch 61/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.3082e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.3063e-08 - val_accuracy: 0.9996 - val_loss: 0.0011\n",
      "Epoch 62/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.8353e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.8320e-08 - val_accuracy: 0.9996 - val_loss: 0.0011\n",
      "Epoch 63/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.4037e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.4009e-08 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0892e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0868e-08 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.8008e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.7987e-08 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5460e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5442e-08 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2983e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2962e-08 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 68/200\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1155e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.1149e-08 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 69/200\n",
      "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.6780e-09\n",
      "Epoch 69: val_accuracy did not improve from 0.99958\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.6676e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp6/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m 5/75\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 10:04:51.837641: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 10:04:51.839080: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.9703e-05\n",
      "\u001b[1m16/75\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 10:04:57.067007: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 10:04:57.067439: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0021\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 4.3324e-04\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation / 5 fold cross validation )\n",
    "kSplits = 5\n",
    "# kfold = KFold(n_splits=kSplits, random_state=42, shuffle=True)\n",
    "kfold = StratifiedKFold(n_splits=kSplits, random_state=42, shuffle=True) # splits training data into 5 folds - class balance(stratify)\n",
    "\n",
    "# File path name to save best models\n",
    "foldername = \"CNN2D_results/V4_2_NOL_exp6/\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint #Saves the model with the highest validation accuracy for each fold\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "pred_all_val = np.zeros([len(X_2D_train),10])\n",
    "y_2D_val = np.zeros([len(X_2D_train),10])\n",
    "kfold_test_len = []\n",
    "\n",
    "fl1 = 0\n",
    "k = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True) #Stops training if validation accuracy doesn’t improve for 50 epochs, restoring the best weights.\n",
    "\n",
    "# Train the model \n",
    "# for train, test in kfold.split(X_2D_train,y_2D_train):\n",
    "for fold, (train, test) in enumerate(kfold.split(X_2D_train, y_label_train)):   \n",
    "\n",
    "  # Define where to save the best model\n",
    "  checkpoint_filepath = foldername + \"best_model_\" + str(k) + \".h5\"\n",
    "    \n",
    "  # Create a ModelCheckpoint callback\n",
    "  checkpoint = ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_accuracy',  # Monitor validation accuracy\n",
    "      save_best_only=True,  # Save only the best model\n",
    "      mode='max',  # Maximize accuracy\n",
    "      verbose=1\n",
    "  )        \n",
    "\n",
    "#For each fold, trains a new CNN model on the training subset (X_2D_train[train], y_2D_train[train]) for up to 200 epochs.\n",
    "  Classification_2D = CNN_2D()\n",
    "  # history = Classification_2D.model.fit(X_2D_train[train], y_2D_train[train], verbose=1, epochs=50) #epochs=12\n",
    "  history = Classification_2D.model.fit(\n",
    "        X_2D_train[train], y_2D_train[train],\n",
    "        validation_data=(X_2D_train[test], y_2D_train[test]),  # Validation set for monitoring\n",
    "        epochs=200,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint, early_stop]  # Save the best model\n",
    "  )\n",
    "  \n",
    "  print(\"Best model saved at:\", checkpoint_filepath)\n",
    "  CNN_2D_best_model = load_model(checkpoint_filepath)\n",
    "  print(\"Best model loaded successfully!\")\n",
    "  \n",
    "  fl2 = fl1 + len(test)\n",
    "  pred_all_val[fl1:fl2,:] = CNN_2D_best_model.predict(X_2D_train[test])\n",
    "  y_2D_val[fl1:fl2,:] = y_2D_train[test]\n",
    "  kfold_test_len.append(fl2-fl1)\n",
    "  fl1 = fl2  \n",
    "\n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  train_loss, train_accuracy = CNN_2D_best_model.evaluate(X_2D_train[train], y_2D_train[train]) \n",
    "  accuracy_train.append(train_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  val_loss, val_accuracy = CNN_2D_best_model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  accuracy_val.append(val_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  test_loss, test_accuracy = CNN_2D_best_model.evaluate(X_2D_test, y_2D_test) \n",
    "  accuracy_test.append(test_accuracy)  \n",
    "  \n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  # kf_loss, kf_accuracy = Classification_2D.model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  # accuracy_2D.append(kf_accuracy)\n",
    "  \n",
    "  k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7705181d-c6cb-4412-a002-8937240306ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 2D train accuracy = 99.98944759368896\n",
      "CNN 2D validation accuracy = 99.93246078491211\n",
      "CNN 2D test accuracy = 99.93247866630554\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAGzCAYAAAB+YC5UAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW6hJREFUeJzt3QdcVfX/P/AXguJAcYAIDhyZO00tV5brK45cObKozF2pOdKCLJyJKzVHqVlqpWX1y1IryZSGI3GlmQtDcQCKTEFBwft/vD/+75V7RS9XLtzD4fV8PI7cM+7hfc/Fe9/nM50MBoMBRERERDYoYsvBRERERIIJBBEREdmMCQQRERHZjAkEERER2YwJBBEREdmMCQQRERHZjAkEERER2YwJBBEREdmMCQQRERHZjAkE3SU8PBydO3eGu7s7nJyc8P3339v1/GfPnlXnXbNmjV3PW5C1a9dOLVS4vPzyy6hevbqjwyB6IEwgNOq///7DyJEjUbNmTRQvXhxlypRBmzZt8MEHH+D69et5+rsHDRqEf/75B++99x4+//xzNG/eHHr6wJbkRa5ndtdRkifZL8v8+fNtPn9UVBSmTp2Kv//+GwVJZmYmVq9erZKY8uXLw9XVVX2xDR48GPv37zcdJ0mfXBv5m7x48eJd55HnN2zY0GybnEeeM2bMmLuO/+2339S+b7/99r7xnT9/HtOmTcPjjz+OcuXKwcPDQ/2uX3/99a5j5fob30NZSpYsiWrVqqFHjx7qNaanp1u9Hlmff79F4icqrFwcHQDd7ccff0T//v3Vh/hLL72kPpBv3LiBnTt3YtKkSfj333+xcuXKPPnd8qW6Z88eTJ48GaNHj86T3+Hr66t+T9GiReEILi4uuHbtGjZv3owBAwaY7Vu3bp36ckxLS3ugc0sCIV908qXZpEmTHD/vl19+gaPIe/HMM89g69atePLJJ/H222+rJEJKir7++musXbsW586dQ5UqVUzPkS/h2bNnY8mSJTn+PR9//DECAwPh4+Njc4w//PAD5syZg969e6sENyMjA5999hn+97//4dNPP1WJjqWPPvoIbm5uKlZJdkJCQjBkyBAsWrQIW7ZsQdWqVe/5+yRxzkp+17Zt2+7aXq9ePeSGXJNbt27l6hxEDiOTaZF2REREGNzc3Ax169Y1REVF3bU/PDzcsGjRojz7/ZGRkTK5mmHevHkGPRo0aJChVKlShs6dOxt69+591/7atWsb+vbt+8DXYN++feq5q1evztHxqampBkcbNWqUinnhwoV37cvIyFDX4fz582pdXpcc26RJE4Orq6vh4sWLZsc/9dRThgYNGpht8/X1VdtcXFwMY8aMMdsXGhqqzvfNN9/cN8ajR48aYmNjzbalpaWp/ydVqlQx2z5lyhR1TsvjxRdffGEoUqSIoUWLFoYHuUYF4f0kyi+swtCYuXPnIiUlBZ988gm8vb3v2v/QQw9h7NixpnW5E5sxYwZq1aplKnaWO0jLYlrZ/vTTT6tSDCkGlrtsqR6RO6usRb9SOiCkpEOKaI31s/eqqzUWF2cld2pPPPEEypYtq+4A69Spo2Ky1gZix44daNu2LUqVKqWe26tXLxw/fjzb33f69GkVkxwnbTXkDlRKFXLq+eefx88//4zExETTtn379qkqDNlnKT4+HhMnTkSjRo3Ua5IqkK5du+Lw4cOmY6Q4+7HHHlOPJR5jMbfxdRqL9w8cOKDu9KVo3XhdLNtAyF22vEeWr9/Pz08V4UtJhz1cuHABK1asUHfy48aNu2u/s7Ozet1ZSx+ExC3VHlIKkRPytyOlaXLH/SCxN2jQQFVbZCV/7926dVOv4erVqzk6j7+/P4YNG4a9e/eqv9PcuN/7KSUm3bt3V6UtEqf8/5T/p3LNsrL8f2X8vyHVZ1LKaPx/LX9X8vdJpCVMIDRGitXli71169Y5Ol4+DIOCgtC0aVMsXLgQTz31FIKDgzFw4MC7jpUv3X79+qkvi/fff199EckHmFSJCCnGlnOI5557ThXXSnGvLeRckqhIAjN9+nT1e3r27Ildu3bd93lSly1fjpcvX1ZJwoQJE7B7927V7kM+VC1J1YN8achrlcfyJS1VBzklr1U+qL/77jvTtvXr16Nu3brqWlqKiIhQjUnltS1YsEAlWNJORK638QtRirPlNYsRI0ao6yeLfLkYxcXFqcRDqjfk2rZv3z7b+KSti6enp0okjF868kUvVR1SbfAg1QDZkSRKktAXX3zRpufVqFHD5oRAqsXkd+U06ciJmJgY9cUtS04ZX6s9qo3u9X7K36MkmvJ3LO9ls2bN1P/TgICAHJ1X/hbnzZun2kHNnDlT/R+Qv9mbN2/mOmYiu8m3sg6yKikpSRWT9urVK0fH//333+r4YcOGmW2fOHGi2r5jxw6zYmTZ9scff5i2Xb58WRVDv/HGG6ZtZ86cybb4Xor+5RyWjMXFRlIMfq/iY8vfkbWYX4rEK1asaIiLizNtO3z4sCpufumll+76fUOGDDE7Z58+fQwVKlS45++0rMIQ/fr1M3Ts2FE9zszMNFSqVMkwbdq0bK+BFJfLMZavQ67f9OnTc1SFIcX7sm/58uXZ7pMlq5CQEHX8zJkzTVVb2VW75Mb48ePV7zh06FCOjjdWYcjr/O+//1S1xOuvv261CqN79+7q8eDBgw3Fixc3Vc/ltAojO1KdJ+d68cUXc1yFIRISEtR++ZvJTRXG/d7Pa9eu3bVt5MiRhpIlS6q/pXv9vzL+7cnfcnx8vGn7Dz/8oLZv3rw5xzET5TWWQGhIcnKy+lm6dOkcHf/TTz+pn3KXk9Ubb7xhaoyZVf369VUVgZHc4Ur1gtxd24tUKRiLcHPaOCw6Olr1WpDSEGm8Z/TII4+o0hLj68zqlVdeMVuX1yV3g8ZrmBNSVSHVDnIXK9Un8jO76gshxchFitz+7yIlAvK7jNUzBw8ezPHvlPNk1+AvO9KVVu5ApVRD7j6lSkNKIRz5N5eVlJTJ3bwUtct7mBPvvPOOXUohpLpKGhqXKFHC5nPJ+yZyWu3xIO+nxGUkv+fKlSvqb1TiPnHihNXzPvvss6qE0Mj4/9ae/1eJcosJhIZIvbotH2yRkZHqS03aRWRVqVIl9UUu+7OSrmyW5EMqISEB9iIffFLtIFUrXl5eqipFWvLfL5kwxilfxpakWkA+fFNTU+/7Wowftra8Fqk/ly/ODRs2qN4XUs9seS2NJH6p3qldu7b60pD6eEnAjhw5gqSkpBz/zsqVK6NYsWI5Pl7qwiWpkgRr8eLFqFixotXnxMbGqmTIuEibGnv9zeU2IXiQpMOSJHDyd3Xs2DHV/dPW6hzj9XiQpCmn76dU5fXp00e1z5FrLH8rL7zwgtqXk78Xe/x9E+U1JhAaIh808mF49OhRm55n2YjxXqRBXHYMBsMD/w7LRmFy5/XHH3+oNg3yRSFfsJJUSEmC5bG5kZvXYiSJgNzZSzfFjRs33rP0QcyaNUuV9Eh7hi+++EJ1CZRGeNK4z5ZueFnvTHPi0KFDql2IkDYXOSGJkDTANS73G89C2nzYcu7sEgL5YrQlITC2hZBumQ9i+PDhqhumtDPo0KGDzc83/v+6V7Joi+zeT2mYK21jpIGtlB5Juyb5WzG+3pz8vdjj75sor3EcCI2RRnryYSxjMbRq1eq+x0qPCfkwkp4DWfujX7p0SX2IGXtU2IPcAWXtsWBkWcohpFSkY8eOapEGh/LlK18aoaGh6NSpU7avQ5w8efKufVLcK3f70jMjL0jSIOMISMzZNTw1kjtdaSAnvWOykmuStXdATpO5nJBSFykel6onaVQrPXTkrtbY0+NepDQl6yBZ8iV/L9IAUL6sJCmytSFl1lIIeX5OEwLpWSBJh1THtGjRwqbfJY1XZTAoabAoDX0fhHEsB2m0mxekWkyquKSBbtYGtGfOnMmT30fkKCyB0Jg333xTfVlKFYAkAtmNUCmtuo1F8MKyp4R8aQvpRmYv8qEvRa9SomAkd5xy527Z3dGScUCle40AKHfJcoyUBGRNUuROUVrKG19nXpCkQLrXLV26VFX93It8yVre/X3zzTd3jcZoTHSyS7Zs9dZbb6kBnOS6yHsq3f2kV4a1kRSlCkkSNeNyvwRCBlOSO3pj7w5LkqBKTxrpKpmThECqTHKadEiPAkmKckp6JUhpinSVzNqV2RbSu2HVqlUqOZcENy8YSw+y/r3IQHAffvhhnvw+IkdhCYTGyIexfMhJsb+UKmQdiVK6NcqXljQ2FI0bN1ZfKFJiYSw2DQsLU184MmLfvboIPgi5O5cvNLkDfv3111VjMBnp7+GHHzZrRChFtlKFIcmLlCxI8bt8cMo4AjI2xP2+HORuWD7Yhw4dqu6g5QtN6pClW2dekZIH+TLLScmQvDYpEZDSACnylzt9yy9nef+k/cny5ctVHbskFHKXLd0ebSGNOuW6TZkyxdSt1DjU9LvvvmvTF681kiBIYirvq9w1y2uVEidJXuTvTUqB7lc6I6SESe7spRRJqnWsMSYd8reaE5KoSnItbVDk/4WUeGQlVWTS5say1EgaTMr/HeNIlNKdWP7fyOvKK/L3IddP/m/KNZVSKbk2rH4g3cnzfh70QE6dOmUYPny4oXr16oZixYoZSpcubWjTpo1hyZIlZt3Abt68qboe1qhRw1C0aFFD1apVDYGBgWbHWHalu1/3wXt14xS//PKLoWHDhiqeOnXqqFH9LLtxbt++XXVD9fHxUcfJz+eee069HsvfYdnV8ddff1WvsUSJEoYyZcoYevToYTh27FiOuugZuxfKuXPajfNe7tWNU7q7ent7q/gkzj179mTb/VK63NWvX191ccz6OrPr4miU9TzJycnq/WratKl6fy27XUrXVvnd9iQjTq5atcrQtm1bg7u7u/pbkhik22XWLp5Zu3Fmd21l3/26cVp2w3R2ds5RN07j+36vRbqD3utY6eopo1U+/fTThk8//fSu/xu56cZ5r/dz165dhpYtW6q/Ffk/8Oabb5q65WaN9V7dOLP7/yfb5bURaYWT/OPoJIaIiIgKFraBICIiIpsxgSAiIiKbMYEgIiIimzGBICIiIpsxgSAiIiKbMYEgIiIimzGBICIiooI7EmUp3wcbhz8/pEa+6+gQiIjIzMN5evYS1R5srpXsXD/3JfSIJRBEREQWnJyK2G2xhUwF0KNHDzUzswyD/v3335v2yfwxMqVAo0aN1DD5coxMdxAVFXXXnET+/v5qhmcZWl+mBzBOY28k8xq1bdsWxYsXV3PiPMjw+EwgiIiINCI1NVXN17Js2bK79skcRDL3kMyHIz9l7hqZf6Znz55mx0ny8O+//6pp5Lds2aKSkhEjRpj2Jycno3Pnzmq+ogMHDqi5iGTOIZlXyRaaGcqaVRhERKSVKgx7fielRt6eQt5WUgIhE8nJ5Ij3sm/fPjz++OOIjIxEtWrVcPz4cdSvX19tb968uTpm69atalZjmVVXSi1kIkSZAE9mzy1WrJg6JiAgQJV2yOR5OcUSCCIiojyswkhPT1d3/VkX2WYPSUlJKtGQqgqxZ88e9diYPIhOnTqpmYf37t1rOubJJ580JQ/Cz89PlWYkJCTk+HczgSAiIsrDBCI4OBju7u5mi2zLrbS0NNUm4rnnnlPtHYSUKlSsWNHsOBcXF5QvX17tMx7j5eVldoxx3XhMgeqFQUREpEeBgYGYMGGC2TZXV9dcnVMaVA4YMEDmmFdVEo7ABIKIiMiCVAvYi6ura64ThuySB2n3sGPHDlPpg6hUqRIuX75sdnxGRobqmSH7jMdcunTJ7BjjuvGYnGAVBhERUbZfj/ZaYPfkITw8HL/++isqVKhgtr9Vq1ZITExUvSuMJMm4desWWrRoYTpGembIuYykx0adOnVQrly5HMfCBIKIiEgjUlJS8Pfff6tFnDlzRj0+d+6c+sLv168f9u/fj3Xr1iEzM1O1WZDlxo0b6vh69eqhS5cuGD58OMLCwrBr1y6MHj0aAwcOVD0wxPPPP68aUMr4ENLdc8OGDfjggw/uqmaxht04c4DdOImIClc3Tvdad8ZNyK2k/3I+vsJvv/2G9u3b37V90KBBaqyGGjVqZPu80NBQtGvXTj2W6gpJGjZv3qx6X/Tt2xeLFy+Gm5ub2UBSo0aNUt09PTw8MGbMGNUg0xZMIHKACQQRUeFKIMo+9IrdzpV4ejn0iFUYREREZDP2wiAiIrLgxPtrfSQQ86a+iO6dHoVvVU+06joZR46dg6trUaxdMgp1a/sgLe0mYuOSMXbyakRE3u6+4lmhDD5eMBI1fCvixo0MjHtnDXaFnVT7fv7qbVSr4oHk5Gtqfd3/7cTST7bm+es4ezYKAQELkZCQDDe3kpg9exxq1/aFVjC+3NFyfFqOTTA+fcZWEOK7F1snwSqMCsQV+v6nMHTqNwOR52PNtq/+MhRN2r+Jll0nY8u2A1g2Z5hp3/SAAQg7dBqN203CyIkrsXrxa3BxcTbtf2v6OrTq9o5a8iN5EEFByzBggB9CQlZg+PB+CAhYBC1hfPqNT8uxCcanz9gKQnyUjwnElStX1LSfffr0UX1JZZHHMptXbKz5F7y9SMlBVIz5+Nzp6TcREnrYtB528D/4VvEwrT/TvQU+WbdDPT545AyiLyWgbYu6cJS4uEQcPRqOnj1vt67182uNmJgriIw0n4bVURiffuPTcmyC8ekztoIQnxan8y5IbHpl0t3j4YcfVt1BZCxvmYxDFnks2+rWrav6p1qT3cQiBkNmbl4HRg3pjB+3HVSPy5d1Q1EXZ1yKTTLtj7xwBVUr3xlwY/pbAxAWMgtrl45C9aqeyGvR0Vfg6VneVAoio5x5e3siKipvki5bMT79xqfl2ATj02dsBSG++2ECYec2ENJPtH///li+fPldw3xKb9BXXnlFHSMzfd2PTCIybdo080DKNEKxso3xICaO6oGa1b3Q/bnZOTp+2PjluBgdrx6PHNQJ365+A807BTzQ7yYiIv1xgv2GstYrm1Kjw4cPY/z48dmOES7bZJ9x9CxrE4vIFKRZl6LuDfEgxo7ohl5dmqPPoPm4nnZ7JK74xBRkZN6Cl6e76Tip3jh/MU49NiYPYsXaX1GjqqcqtchL3t4eiI2NR0ZGpinhio6OhY9P3pd+5ATj0298Wo5NMD59xlYQ4qN8TCBkkg0ZGvNeZJ/lFKHZkUlFZPKPrIuT050Gjjk1ZlgX9O/ZEj385yDp//eoMNr4YxiG+ndQj5s+UgM+lcrhz70n4OxcBBU97kw80qtrc1y+kqySjrxUoUJZNGhQC5s2har1kJDd8PLygK/v7aFFHY3x6Tc+LccmGJ8+YysI8d0PqzDsPBLlsmXL8MYbb2DkyJHo2LGjKVmQWby2b9+Ojz/+GPPnz8drr70Ge45EuXjWYHTp0ESVKMQnpOBqahq6PPsewvcuRkTkJaSkpKnj0m9koF3vqeqxJAmrFr6iun7euJmBN4I+wx97jqNkCVeEfP02XIsVxa1bBsQlXEXAjPX45/i5PB+JMiLiAgIDFyEx8SpKlSqJ4OCxqFOnOrSC8ek3Pi3HJhifPmPL2/jydiRKr3qT7HauS8fnQY9sHspaJt1YuHChmulLJvIQzs7OaNasmZqIQ2YJexAcypqIiHKOCUSBG0jq2WefVYvMCiZdOoVMxFG0aNG8iI+IiCjf6bnqweEjUUrC4O3tbbdAiIiItIMJhDW8QkRERKTPuTCIiIjyE6swrGMCQUREZIEJhHW8QkRERGQzlkAQERFZcOL9tVVMIIiIiCywCsM6JhBEREQWspvzicwxxSIiIiKbsQSCiIjIAqswrGMCQUREZIGNKK3jFSIiIiKbsQSCiIjIAqswClACoeUps0v6ToOWXYuc4ugQiIh0hQmEdbxCREREVHBLIIiIiLSCjSitYwJBRERkiVUYVvEKERERkc1YAkFERGSBjSitYwJBRERkgXNhWMcEgoiIyAIbUVrHK0REREQ2YwkEERGRBbaBsI4JBBERkSW2gbCKKRYRERHZjCUQRERElnh7bRUTCCIiIkuswih8CcTZs1EICFiIhIRkuLmVxOzZ41C7tm+e/b75U19C905N4VvVEy27vo0jxyLh6loUny0Zjbq1K+N62g3ExiVj7OTViIi8pJ4zaVRP+Pdti4dqVMJzIxdh8y8HTOfzrFAGqxa8ghq+Xki/cRPj3lmDXWEnoMdrZyvGp8/YBOPTZ2wFIT56cLorpAkKWoYBA/wQErICw4f3Q0DAojz9fRt/CkOnftMReT7WbPunX+5A4/YTVVLx47YD+HDOMNO+0J1H0XvQXOzce3diMCPgWYQdOo1H2r2BVyauxJrFo+Di4gw9XjtbMT59xiYYnz5jKwjx3bcEwl6LTukqgYiLS8TRo+Ho2bO9Wvfza42YmCuIjIzKs98ppQMXY+LNtqWn30RI6GHTetjB0/Ct4mla3384AmctEg6jZ7q3xKp129XjA0ciEH0pAW1b1IUer50tGJ8+YxOMT5+xFYT4rH472mvRKbu/tPPnz2PIkCH3PSY9PR3JyclmS3r6jVz/7ujoK/D0LG+6Y5ehSL29PREVlf2XdX55bUgXbNl2p5riXsqXdUNRF2dcik0ybYu8EIuqlT3yOELtXjsjxqfP2ATj02dsBSE+0lgCER8fj7Vr1973mODgYLi7u5stwcEroEfS3qFWdS8Ezdng6FCIiCiHDE5Odlv0yuZGlJs2bbrv/oiICKvnCAwMxIQJE8y2ubqeQ255e3sgNjYeGRmZKuM1GAyIjo6Fj8+d6oP8NHZEN/Tq8hi6+werxpTWxCemICMzE16e7qZSCKn6OH/xSp7HqrVrZ4nx6TM2wfj0GVtBiO++9Pu977gSiN69e6NPnz7qZ3aLZWKQHVdXV5QpU8ZscXUthtyqUKEsGjSohU2bQtV6SMhueHl5wNfXB/ltzLCuGNCzNZ72D0ZS8rUcP++7H8MwzL+jetzskZrwqVQOf2bT2NLetHTtssP49BmbYHz6jK0gxHdfRZzst+iUk0FSQhtUrlwZH374IXr16pXt/r///hvNmjVDZmamjaGcgj1ERFxAYOAiJCZeRalSJREcPBZ16lTP1TlL+k67574ls4agS4dHValBXEIKUlKvo8uz7yF87xLVbTMlJU0dJ10yn+o9RT1+a0xvlSR4lC+Nq6lpqtFlq25v40r8VVT0KINVC19D9aqeuHEzAxOC1uKPPcfuG9+1yNvn1eK1syfGp8/YBOPTZ2x5G9/DyEu1262027nCfxsBPbI5gejZsyeaNGmC6dOnZ7v/8OHDePTRR3Hr1i2HJBB54X4JhBbYK4EgIio48jiBaP+x3c4VHjocemRzG4hJkyYhNTX1nvsfeughhIbeLq4iIiIqkPRb8+C4BKJt27b33V+qVCk89dRTuYmJiIiINE7HQ1wQEREVrEaUf/zxB3r06AEfHx81bsb3339vtl9aHQQFBcHb2xslSpRAp06dEB4eftdwCv7+/qqDQtmyZTF06FCkpKSYHXPkyBFVIFC8eHFUrVoVc+fOtf0S2fwMIiIivXPQUNapqalo3Lgxli1blu1++aJfvHgxli9fjr1796pSfz8/P6Sl3W6wLyR5+Pfff7Ft2zZs2bJFJSUjRtxpyCmDN3bu3Bm+vr44cOAA5s2bh6lTp2LlypWFezItIiKigqpr165qyY6UPixatAjvvPOOqSfkZ599Bi8vL1VSMXDgQBw/fhxbt27Fvn370Lx5c3XMkiVL0K1bN8yfP1+VbKxbtw43btzAp59+imLFiqFBgwaqB+WCBQvMEg1rWAJBRERkycl+S3q20zek2xzSmTNnEBMTo6otjGQk5xYtWmDPnj1qXX5KtYUxeRByfJEiRVSJhfGYJ598UiUPRlKKcfLkSSQkJOQ4HiYQREREedgGIjjb6RuCbQ5JkgchJQ5Zybpxn/ysWLGi2X4XFxeUL1/e7JjszpH1d+QEqzCIiIjyUGC20ze4oqBjAkFERJSH40C4urraJWGoVKmS+nnp0iXVC8NI1mWAR+Mxly9fNnteRkaG6plhfL78lOdkZVw3HpMTrMIgIiIqALNx1qhRQ33Bb9++3bRN2lNI24ZWrVqpdfmZmJioelcY7dixQ40OLW0ljMdIz4ybN2+ajpEeG3Xq1EG5cuVyHA8TCCIiIo2MA5GSkqJ6RMhibDgpj8+dO6fGhRg3bhxmzpypZsb+559/8NJLL6meFTKZpahXrx66dOmC4cOHIywsDLt27cLo0aNVDw05Tjz//POqAaWMDyHdPTds2IAPPvggR5NhZsUqDCIiIo3Yv38/2rdvb1o3fqkPGjQIa9aswZtvvqnGipDullLS8MQTT6humzIglJF005SkoWPHjqr3Rd++fdXYEUbSiPOXX37BqFGj1OSXHh4eanAqW7pwPtBkWnmHk2k9KE6mRUSFT95OpvVQjzV2O9fpzS9Dj1gCQUREZMmObRf0igmEDu7wS1TTdnzXz2m7BIeIiGzHBIKIiMiSjY0fCyMmEERERJaYP1jFbpxERERkM5ZAEBERWWIjSquYQBAREVliAmEVqzCIiIjIZiyBICIissTba6uYQBAREVliFYZVTCCIiIgsMX+wioU0REREZDOWQBAREVkwcCRKq5hAEBERWWIbCKtYhUFEREQ2010CcfZsFAYOnAQ/v5Ho23c8wsMjUZhje3/aIJzYtRjXz32JR+r7qm2urkXx9ccTcOS3Bdi7dTa2rHsbNX29TM+ZNKoXDoe+j9Sz69Cjc/Nsz/tU6wZIObMOo4d2RX7R8nur9fi0HJtgfPqMrSDEd09Odlx0SncJRFDQMgwY4IeQkBUYPrwfAgIWoTDH9t2Pe9Gx71REno812/7J+h14pN0EtOgSgC2/7MdHc0eY9oXuPIpeg+Zg594T2Z6zTOkSmBkwEFtDDyE/afm91Xp8Wo5NMD59xlYQ4rsnaQNhr0WndJVAxMUl4ujRcPTs2V6t+/m1RkzMFURGRhXa2HaFncDFmHizbenpNxES+rdpPezQafhW8TSt7z/8H86eu3zPcy6cMRizl3yP+IQU5Bctv7daj0/LsQnGp8/YCkJ8lM8JxPXr17Fz504cO3bsrn1paWn47LPPrJ4jPT0dycnJZkt6+g3kVnT0FXh6loeLi7Nad3Jygre3J6KizO++HUHLsY0a0gVbtu3P0bF9uj2OW7cM+HHbAeQnLV8/rcen5dgE49NnbAUhPquNKO216JRNCcSpU6dQr149PPnkk2jUqBGeeuopREdHm/YnJSVh8ODBVs8THBwMd3d3syU4eMWDvQLKFWnvUMvXC+/O/srqsV6e7nhrTB9MnLo2X2IjInIYtoGwbwLx1ltvoWHDhrh8+TJOnjyJ0qVLo02bNjh37pwtp0FgYKBKNrIugYEjkVve3h6IjY1HRkamWjcYDIiOjoWPz53ieUfRYmzjRnRHr66Pq/YO19OslwA92qgmKlUsh70/z1YNM/t0a4HAsc9g6qQBhfL6FZT4tBybYHz6jK0gxEf5mEDs3r1blR54eHjgoYcewubNm+Hn54e2bdsiIiIix+dxdXVFmTJlzBZX12LIrQoVyqJBg1rYtClUrYeE7IaXlwd8fX1yfW69xfb6sG7o36s1nvafhaTkazl6ztYdh1C92Suo2+Z1tWz8aS+CP/gOU+d9XeiuX0GKT8uxCcanz9gKQnz3xUaUVjkZJCXMIfmi37t3r6rGyGr06NH44YcfsH79erRr1w6ZmbezTducgj1ERFxAYOAiJCZeRalSJREcPBZ16lSHFuRVbCWqTbnnviXBQ9G1w6Pw8iyLuIQUpKReh9+AGTgdtgwRkZdwNeW6Ou7GjQw82etd9ViqKYa/0BEe5cvgamqaap/SsmsgrsRfNTv3yvdfwZFjkVj6yc/3je/6uWnQ+3ur9fi0HJtgfPqMLW/jexh5qdbQb+x2rv8+6Q8U9gTi8ccfx5gxY/Diiy/etU+SiHXr1qkGkY5MIAqj+yUQWmCvBIKIKL8SiJrD7JdARKzSZwJhUxVGnz598OWXX2a7b+nSpXjuuedUHRcRERHpm00lEHmLJRAPiiUQRFT45HEJxIhv7XauiJX9oEecTIuIiMiSjsdvsBddjURJRERE+YMlEERERJZ03P3SXphAEBERWWL5vFW8RERERGQzlkAQERFZYiNKq5hAEBERWWIbCKtYhUFEREQ2YwkEERGRBQOrMKxiAkFERGSJ5fNWMYEgIiKyxDYQVjHHIiIiIpuxBEIHtD5ZVUlf7cZ3LVLbE5ERkYOwDYRVTCCIiIgssQrDKlZhEBERkc1YAkFERGSJBRBWMYEgIiKyYGAVhlWswiAiIiKbsQSCiIjIEksgrGICQUREZIndOK1iFQYRERHZjCUQRERElnh7bRUTCCIiIkuswrCKCQQREZElNqK0ioU0REREGpGZmYl3330XNWrUQIkSJVCrVi3MmDEDBoPBdIw8DgoKgre3tzqmU6dOCA8PNztPfHw8/P39UaZMGZQtWxZDhw5FSkqKXWNlAkFERJRdCYS9FhvMmTMHH330EZYuXYrjx4+r9blz52LJkiWmY2R98eLFWL58Ofbu3YtSpUrBz88PaWlppmMkefj333+xbds2bNmyBX/88QdGjBgBe9JdFcbZs1EICFiIhIRkuLmVxOzZ41C7ti+0QMuxOSq++VNfQvdOTeFb1RMtu76NI8ci4epaFJ8tGY26tSvjetoNxMYlY+zk1YiIvKSeM2lUT/j3bYuHalTCcyMXYfMvB0znWzFvBFo2f1g9L/VaOt6c9jkOHIlAYX9/tRybYHz6jK0gxHcvBge1gdi9ezd69eqF7t27q/Xq1avjyy+/RFhY2O24DAYsWrQI77zzjjpOfPbZZ/Dy8sL333+PgQMHqsRj69at2LdvH5o3b66OkQSkW7dumD9/Pnx8fOwSq+5KIIKClmHAAD+EhKzA8OH9EBCwCFqh5dgcFd/Gn8LQqd90RJ6PNdv+6Zc70Lj9RJVU/LjtAD6cM8y0L3TnUfQeNBc7956463ybQvajaac31fPmL9uELz58HflFy++vlmMTjE+fsRWE+PJDeno6kpOTzRbZlp3WrVtj+/btOHXqlFo/fPgwdu7cia5du6r1M2fOICYmRlVbGLm7u6NFixbYs2ePWpefUm1hTB6EHF+kSBFVYmEvukog4uIScfRoOHr2bK/W/fxaIybmCiIjoxwdmqZjc2R8u8JO4GJMvNm29PSbCAk9bFoPO3gavlU8Tev7D0fgrEXCYfTjrweRmXnr9vMOhcOnUjk4Oxcp1O+vlmMTjE+fsRWE+O6riP2W4OBg9SWfdZFt2QkICFClCHXr1kXRokXx6KOPYty4capKQkjyIKTEIStZN+6TnxUrVjTb7+LigvLly5uOsdclsokUjaxevRonTty++5Ofr776KoYMGYIdO3bkIhu7gdyKjr4CT8/ycHFxVutOTk7w9vZEVFT2Xzb5ScuxaT2+14Z0wZZtd6opcmrUkC4qETEmFIX1+mk5NsH49BlbQYjvvqQKw05LYGAgkpKSzBbZlp2vv/4a69atw/r163Hw4EGsXbtWVTvIT62xKYGQOpUmTZpg4sSJKiuS9SeffBKnT59GZGQkOnfunKMkIvtsbEVuXgfplLR3qFXdC0FzNtj0vIF92uCZ7i0wOnBVnsVGRJQTrq6uqjdE1kW2ZWfSpEmmUohGjRrhxRdfxPjx400lFpUqVVI/L1263SbMSNaN++Tn5cuXzfZnZGSonhnGY/I9gZg+fbp6cXFxcaoU4vnnn8fw4cNVK0+ps5F9s2fPtnqe7LOxkcgtb28PxMbGIyMj09TYJDo6Fj4+d4q/HUXLsWk1vrEjuqFXl8dUewdpFJlTfZ9uibfHPoOnX5iNy1eSUVivX0GITTA+fcZWEOLTYi+Ma9euqbYKWTk7O+PWrdslqdK9U5IA+c41klJ8advQqlUrtS4/ExMTceDAnZJbubmXc0hbCYckENIl5OWXX1aPBwwYgKtXr6Jfv36m/VJHc+TIkQfMxoohtypUKIsGDWph06ZQtR4SshteXh7w9bVPi1O9xqbF+MYM64oBPVvjaf9gJCVfy/HzpNRhysT+6O4fjAtRcSis16+gxCYYnz5jKwjxaTGB6NGjB9577z38+OOPOHv2LDZu3IgFCxagT58+pmogaRMxc+ZMbNq0Cf/88w9eeukl1bOid+/e6ph69eqhS5cu6gZfem/s2rULo0ePVqUa9uqBoWIxZB2dwgqpapA6GRnYQpQuXVq1EK1Zs6Zal2oMafhx/fr1BwjldovT3IqIuIDAwEVITLyKUqVKIjh4LOrUqQ4t0HJseRlfSd9p99y3ZNYQdOnwKLw83RGXkIKU1Ovo8ux7CN+7RHXbTEm53a85/cZNPNV7inr81pjeGObfER7lS+NqappqdNmq29u4En8VSafX4lJsEuIT7gyY0u35WYhPzH4AlWuRt8+p9/dXy7EJxqfP2PI2voeRl3zn5axNX05ETuqAnJIbcxlIShIHqYaQL/znnntODRxVrNjtG2352p4yZQpWrlypShqeeOIJfPjhh3j44TvXRKorJGnYvHmzKtHo27evGjvCzc0NDkkgGjdurAa1kMxGHD16VCUM0rpT/Pnnnxg0aBAiIiIclkCQ9twvgXA0eyYQRJSf8jiBmG/HBGJizhOIgsSmgaSkt4UMs2nUsGFDs/0///wzOnTQ54UiIqLCw8C5MOybQLzyyiv33T9r1ixbTkdERKRNnI2zcA0kRURERPlDd3NhEBER5RqrMKxiAkFERGSJ+YNVrMIgIiIim7EEgoiIyILFYJCUDSYQREREFtgJwzrmWERERGQzlkAQERFZYAmEdUwgiIiILMikVXR/TCCIiIgsMH+wjm0giIiIyGYsgSAiIrLAEgjrmEBQoZ4y+6H+YdCy09887ugQiAolJ5bPW8VLRERERDZjCQQREZEFVmFYxwSCiIjIAifjtI5VGERERGQzlkAQERFZYBWGdUwgiIiILDCBsI5VGERERGQzlkAQERFZ4FwY1jGBICIissCBpKxjAkFERGSBBRDWMcciIiIim7EEgoiIyAJLIKxjAkFERGSBCUQhTCDOno1CQMBCJCQkw82tJGbPHofatX2hBVqOTTC++3uyiTfGD2yCoi5FkJaegXdW7sWJyETT/pYNvbD23Y4IXnsQa346obb5ViqNacMfR4UyxeHi7IQl3/6Dn3ZHIr/NnLkCO3aE4eLFy/j++w9Qr15NaImj39uCHJ+WYysI8ZGD20AYDAZoRVDQMgwY4IeQkBUYPrwfAgIWQSu0HJtgfPdWplQxvP/6E3hz6W48PfFHzP78IBa8/oRpv1vJopjk/yh+Pxhl9ry5o1rhp12R6DHpR/hP3Ya3XngUXuVLIL/5+bXB+vVzULlyRWgR//b0GVtBiO9+c2HYa9EruyQQrq6uOH78OBwtLi4RR4+Go2fP9mrdz681YmKuIDLS/EOdsd2N8d1fNS83JF5NR/iFJLW+/0QsfDxKokGN8mp96tDH8OH/HUVCSrrZ8+pWL4ffDl1Uj+OT01WJRffW1ZHfHnusISpV8oAWOfq9LcjxaTm2ghCftSoMey16ZVMVxoQJE7LdnpmZidmzZ6NChQpqfcGCBfc9T3p6ulqycnW9AVfXYsiN6Ogr8PQsDxcXZ9NAIN7enoiKioWvrw8cScuxMT7rzsZcRdnSrnj0YQ8cOnUFHZtXgVvJYqjsWQpVvdxw65YB2/dfQOcWVc2e929EPHq1rYGPNx1D1Ypu6vkXLqfkebwFiaPf24Icn5ZjKwjxUT4mEIsWLULjxo1RtmzZu6owpASiVKlSORq9Kzg4GNOmTTPbNmXKaEydOsaWcIjyTcq1mxjz/h+qmqJkcReVRISfT1SPh/SoB/8p27J93qSluxH4UjNsmtcNUbGp2HM0Bpm3tFPlR0TZ03PJgUMSiFmzZmHlypV4//330aFDB9P2okWLYs2aNahfv36OzhMYGHhXaYar6znklre3B2Jj45GRkakyXklsoqNj4ePjmetz6zk2wfis++vfS/jr/ycKxVyKYM/HfeHuVgwVy5bA5nnd1fZyZVxV6UR5d1cs+PIwLsamYvT7f5jO8enkDth5ODrfYi4ItPDeFtT4tBxbQYjvfpz03HjBEW0gAgICsGHDBrz66quYOHEibt68+cBtJsqUKWO25Lb6QlSoUBYNGtTCpk2haj0kZDe8vDw0UVSm5dgE47POs+ydxo+j+jXCnqOXsPank2g5/P/QbtT3atn61zks/eYflTyouN2Lm+5k2jb2xkNV3LFp59l8i7kg0MJ7W1Dj03JsBSE+yh0nwwN0oUhJScGoUaPw999/Y926dWjatKl6nNMSiOydgj1ERFxAYOAiJCZeRalSJREcPBZ16uR/o7WCFlthje+h/mE5Pva9kS3QvF5FuDgXwaFTsZj2yT5cvWaeRM8Z1QrHzySYunEO6PAQRvZpoKotLsdfw7RP9yH8/O2GmDlx+pvHYQ9BQUvx22/7ceVKAsqWLYNSpUpg27aV0IrC+LdXGGLL2/geRl56/JuddjtXWP87PbZQ2BMIo6+++grjxo1DbGws/vnnH00kEER5lUA4gr0SCCL9ydsEosW39ksg9vbTZwKRq4GkBg4ciCeeeAIHDhyAry8HBiEiIn1gI8p8GImySpUqaiEiIqLCQ3dDWRMREeUWO2FYxwSCiIjIAqsw8mkoayIiIipcWAJBRERkwYm311YxgSAiIrLAKgzrmGMRERGRzVgCQUREZCEnE0MWdkwgiIiILDB/sI5VGERERGQzlkAQERFZYAmEdSyBICIiyiaBsNdiq4sXL+KFF15AhQoVUKJECTRq1Aj79+837Zc5MIOCguDt7a32d+rUCeHh4WbniI+Ph7+/P8qUKYOyZcti6NChaiZte2IJBBVqWp/tsqTvNGjZtcgpjg6BSFdDWSckJKBNmzZo3749fv75Z3h6eqrkoFy5cqZj5s6di8WLF2Pt2rWoUaMG3n33Xfj5+eHYsWMoXry4OkaSh+joaGzbtg03b97E4MGDMWLECKxfv95useZqOm/74nTeRJaYQBA5Zjrvjj/vstu5tndtk+NjAwICsGvXLvz555/Z7pevbB8fH7zxxhuYOHGi2paUlAQvLy+sWbNGzZJ9/Phx1K9fH/v27UPz5s3VMVu3bkW3bt1w4cIF9Xx7YBUGERFRNiUQ9lrS09ORnJxstsi27GzatEl96ffv3x8VK1bEo48+io8//ti0/8yZM4iJiVHVFkbu7u5o0aIF9uzZo9blp1RbGJMHIccXKVIEe/futd81stuZiIiIdKKIk8FuS3BwsPqSz7rItuxERETgo48+Qu3atRESEoJXX30Vr7/+uqquEJI8CClxyErWjfvkpyQfWbm4uKB8+fKmY+yBbSCIiIjyUGBgICZMmGC2zdXVNdtjb926pUoOZs2apdalBOLo0aNYvnw5Bg0aBC1hCQQREVEeVmG4urqq3hBZl3slENKzQtovZFWvXj2cO3dOPa5UqZL6eenSJbNjZN24T35evnzZbH9GRobqmWE8xi7XyG5nIiIi0okidlxsIT0wTp48abbt1KlT8PX1VY+l14UkAdu3bzftlzYV0rahVatWal1+JiYm4sCBA6ZjduzYoUo3pK2EvbAKg4iISCPGjx+P1q1bqyqMAQMGICwsDCtXrlSLcY6OcePGYebMmaqdhLEbp/Ss6N27t6nEokuXLhg+fLiq+pBunKNHj1Y9NOzVA0MwgSAiIrIgjR8d4bHHHsPGjRtVu4np06erBGHRokVqXAejN998E6mpqWpcBylpeOKJJ1Q3TeMYEGLdunUqaejYsaPqfdG3b181doQ9cRwIIg3jOBBEjhkHotev2Y/D8CB+6NQWesQ2EERERGQzVmEQERFZ4N21dUwgiIiINDIXRkHCBIKIiMiCk4MaURYkLKUhIiIim+muBOLs2SgEBCxEQkIy3NxKYvbscahd+/YAHI6m5dgE4ytY8c2f+hK6d2oK36qeaNn1bRw5FglX16L4bMlo1K1dGdfTbiA2LhljJ69GROTtUesmjeoJ/75t8VCNSnhu5CJs/uXOQDOeFcpg1YJXUMPXC+k3bmLcO2uwK+wE8gPfW33GVhDiuxdWYRTCEoigoGUYMMAPISErMHx4PwQELIJWaDk2wfgKVnwbfwpDp37TEXk+1mz7p1/uQOP2E1VS8eO2A/hwzjDTvtCdR9F70Fzs3Ht3YjAj4FmEHTqNR9q9gVcmrsSaxaPg4uKM/MD3Vp+xFYT4tDYSZUGiq9cWF5eIo0fD0bNne7Xu59caMTFXEBkZ5ejQNB2bYHwFLz4pHbgYE2+2LT39JkJCD5vWww6ehm8VT9P6/sMROGuRcBg9070lVq27PTzugSMRiL6UgLYt6iKv8b3VZ2wFIT5yYAIhI2GtXr0akydPxtKlSxEXF5ej52U/N/oN5FZ09BV4epY33TXJkJ/e3p6Iisr+AzM/aTk2wfj0Gd9rQ7pgy7Y71RT3Ur6sG4q6OONSbJJpW+SFWFSt7FFor11BiE/LsRWE+PJrOm+9simBkBnCZDYvcf78eTRs2FCN271t2zZMmTJF7T9z5ozV82Q/N/qKB38VRHQXae9Qq7oXguZscHQoRIV6Nk69simBOHHihJoSVMg43TIpR2RkpJrsQ34+8sgjqjTCGnluUlKS2RIYOBK55e3tgdjYeGRkZKp1GaU7OjoWPj53inAdRcuxCcanr/jGjuiGXl0eU+0dpDGlNfGJKcjIzISXp7tpm1R9nL94pdBdu4IUn5ZjKwjxkYOqMPbs2YOpU6eq0gPh5uaGadOmYefOnVafm/3c6MWQWxUqlEWDBrWwaVOoWg8J2Q0vLw/4+tpv9jE9xiYYn37iGzOsKwb0bI2n/YORlHwtx8/77scwDPPvqB43e6QmfCqVw5/ZNLbU87UraPFpObaCEN/9sBGlnSfTkhm9Ll26BE9PT1SuXBkhISGqGsNISiHq1q2L69evw1GTaUVEXEBg4CIkJl5FqVIlERw8FnXqVIcWaDk2wfi0F9/9JtNaMmsIunR4VJUaxCWkICX1Oro8+x7C9y5R3TZTUtLUcdIl86netye9emtMb5UkeJQvjaupaarRZatub+NK/FVU9CiDVQtfQ/WqnrhxMwMTgtbijz3H8mUyrcL43haG2PI2vrydTOvlP36327nWPPkU9MjmBEISBhcXF4SHh2PNmjVqilCjP/74A88//zwuXLjwAKFwNk4iS5yNk+hemEAUqIGkpKFkVlJtkdXmzZvRtq0+py0lIqLCQ8+9JzSRQFiaN29ebuMhIiJyOD33nrAX3Q1lTURElFt6bvxoL7xGREREZDOWQBAREVlgGwjrmEAQERFZYBsI61iFQURERDZjCQQREZEFlkBYxwSCiIjIAovnreM1IiIiIpuxBIKIiMgCe2FYxwSCiIjIAttAWMcqDCIiIrIZSyCINEzrs12W8p0BrUqNfNfRIVABxrtr65hAEBERWWAVhnVMIIiIiCw4sRGlVSylISIiIpuxBIKIiMgCqzCsYwJBRERkgcXz1vEaERERkc1YAkFERGSBI1FaxwSCiIjIAttAWMcqDCIiIrIZSyCIiIgssATCOiYQREREFpwdHUABwCoMIiIishlLIIiIiCywF4Z1TCCIiIgssA1EIUwgzp6NQkDAQiQkJMPNrSRmzx6H2rV9oQVajk0wPv3G54jY5k19Ed07PQrfqp5o1XUyjhw7B1fXoli7ZBTq1vZBWtpNxMYlY+zk1YiIvKye41mhDD5eMBI1fCvixo0MjHtnDXaFnTSd8+1xfTCgVyu170rCVXQbGIz8wPdWv/HdCxOIQtgGIihoGQYM8ENIyAoMH94PAQGLoBVajk0wPv3G54jYvv8pDJ36zUDk+Viz7au/DEWT9m+iZdfJ2LLtAJbNGWbaNz1gAMIOnUbjdpMwcuJKrF78Glxcbjdne21wZzSsVxWPdQ7E435vY/CYD5Ff+N7qNz56cLpKIOLiEnH0aDh69myv1v38WiMm5goiI6McHZqmYxOMT7/xOSo2KTmIikkw25aefhMhoYdN62EH/4NvFQ/T+jPdW+CTdTvU44NHziD6UgLatqir1seN7I6g2V/j5s1MtX4pNgn5ge+tfuO7H2cn+y16ZVMCcfDgQZw5c8a0/vnnn6NNmzaoWrUqnnjiCXz11Vc5Ok96ejqSk5PNlvT0G8it6Ogr8PQsb7pjcXJygre3J6KizO+AHEHLsQnGp9/4tBzbqCGd8eO2g+px+bJuKOribJYYRF64gqqVK6C0W3FU9CiDpzs3xW/fT1VL36dboLBfPy3HVhDis1aFYa9Fr2xKIAYPHoz//vtPPV61ahVGjhyJ5s2bY/LkyXjssccwfPhwfPrpp1bPExwcDHd3d7MlOHjFg78KIipwJo7qgZrVvRA052urx7o4O6NoURcUdy2Gdr2n4qXRSzEnyB+N6lXLl1iJKJeNKMPDw1G7dm31+MMPP8QHH3ygkgYjSSLee+89DBky5L7nCQwMxIQJE8y2ubqeQ255e3sgNjYeGRmZKuM1GAyIjo6Fj49nrs+t59gE49NvfFqMbeyIbujVpTme9p+D62m3Sx/jE1OQkXkLXp7uplIIqd44fzEOCUmpuJpyHV9t3KW2n7twBXv2h6Np4xr453juPzsK2vUrCLEVhPjuh9047VwCUbJkSVy5ckU9vnjxIh5//HGz/S1atDCr4rgXV1dXlClTxmxxdS2G3KpQoSwaNKiFTZtC1XpIyG54eXnA19cn1+fWc2yC8ek3Pq3FNmZYF/Tv2RI9/OcgKfma2b6NP4ZhqH8H9bjpIzXgU6kc/tx7Qq1/s+kv/K/dI+pxOfdSaN64Jo4eP1/orl9Bia0gxHc/rMKwzskgKWEOvfjii+rLX6ovBgwYgDp16mDGjBlmVRNffvkljhw5Atudgj1ERFxAYOAiJCZeRalSJREcPBZ16lSHFmg5NsH49BtfXsVWyvfO/39Li2cNRpcOTVSJQnxCCq6mpqHLs+8hfO9iREReQkpKmjou/UaGqpYQ0s5h1cJXVNfPGzcz8EbQZ/hjz3FTG4nl84ejRrWKan3l57/i48+33/P3p0a+C3spjO+t9uN7GHlpybFf7HauMfU7A4U9gYiKilKNJqtVq6baPnz00Udo1qwZ6tWrh5MnT+Kvv/7Cxo0b0a1bN4clEESUf+6XQDiaPRMI0qK8TSA+tGMC8doDJhCzZ89WVf5jx47FokW3u7+mpaXhjTfeUJ0WpEOCn5+falLg5eVlet65c+fw6quvIjQ0FG5ubhg0aJC6wXdxcXFcFYaPjw8OHTqEVq1aYevWrao+KywsDL/88guqVKmCXbt2PWDyQEREpB2OrsLYt28fVqxYgUceuV1tZzR+/Hhs3rwZ33zzDX7//Xd1Y//MM8+Y9mdmZqJ79+64ceMGdu/ejbVr12LNmjUICgqCQ0sg8hZLIIgKGpZAkF5LIJYft18JxCv1bCuBSElJQdOmTVXJwsyZM9GkSRNVApGUlARPT0+sX78e/fr1U8eeOHFC1QLs2bMHLVu2xM8//4ynn35aJRbGUonly5fjrbfeQmxsLIoVy317Q10OJEVERGSvXhj2WtKzHfso/Z6/e9SoUaoUoVOnTmbbDxw4gJs3b5ptr1u3rmpWIAmEkJ+NGjUyq9KQag75nf/++699r5Fdz0ZERKQD9hyJMjjbsY+yn8dF2jbIoI3Z7Y+JiVElCGXLljXbLsmC7DMekzV5MO437rMn3U2mRURElFv27H4ZmO3YR653HXf+/HnVYHLbtm0oXrw4tI4lEERERHnINduxj+5OIKSK4vLly6r9g/SYkEUaSi5evFg9lpIEaRyZmJho9rxLly6hUqVK6rH8lHXL/cZ99sQEgoiISAO9MDp27Ih//vkHf//9t2mRIRP8/f1Nj4sWLYrt2++MfyJDKEi3TekdKeSnnEMSESMp0ZCkpX79+na9RqzCICIisuCIESRLly6Nhg0bmm0rVaoUKlSoYNo+dOhQVR1Svnx5lRSMGTNGJQ3SA0N07txZJQoy8OPcuXNVu4d33nlHNczMrtQjN5hAEBERFRALFy5EkSJF0LdvX7OBpIycnZ2xZcsWNZCUJBaSgMhAUtOnT7d7LBwHgogeGMeBIL2OA7H+v612O9fztbpAj1gCQUREZIENBK3jNSIiIiKbsQSCiIjIgp6n4bYXJhBEpMt2Blpun6H1a0dMIHKCVRhERERkM5ZAEBERWXB20kgHRQ1jAkFERGSBVRjWMYEgIiKywATCOraBICIiIpuxBIKIiMgCSyCsYwJBRERkwZkJhFWswiAiIiKbsQSCiIjIQhF247SKCQQREZEFFs9bx2tERERENmMJBBERkQX2wrCOCQQREZEF9sKwjlUYREREZDPdlUCcPRuFgICFSEhIhptbScyePQ61a/tCC7Qcm2B8+o1Py7E5Ir55U19E906PwreqJ1p1nYwjx87B1bUo1i4Zhbq1fZCWdhOxcckYO3k1IiIvq+d4ViiDjxeMRA3firhxIwPj3lmDXWEn1b5mjWti/tQX4erqos7zxdd/YuGKH5Ef+N7mDfbCKIQlEEFByzBggB9CQlZg+PB+CAhYBK3QcmyC8ek3Pi3H5oj4vv8pDJ36zUDk+Viz7au/DEWT9m+iZdfJ2LLtAJbNGWbaNz1gAMIOnUbjdpMwcuJKrF78GlxcnNW+pcFDMG/ZJrTu9i46PTMDY0d0U4lIfuB7m3dtIOy16JWuEoi4uEQcPRqOnj3bq3U/v9aIibmCyMgoR4em6dgE49NvfFqOzVHxSclBVEyC2bb09JsICT1sWg87+B98q3iY1p/p3gKfrNuhHh88cgbRlxLQtkVdtW6AAWXLlFSPS5Z0xY2bGUhITEVe43ubd5hA2DmBGDNmDP7880/kVnp6OpKTk82W9PQbuT5vdPQVeHqWN90VODk5wdvbE1FR5ncZjqDl2ATj0298Wo5Ny/GNGtIZP247qB6XL+uGoi7OuBSbZNofeeEKqlauoB6/MvFjvPtGP5zYvRCHf5uHqXO/Nju2sF27ghIf5WMCsWzZMrRr1w4PP/ww5syZg5iYmAf6pcHBwXB3dzdbgoNXPNC5iIjsbeKoHqhZ3QtBc77O0fETXu2BKXO/Rt3W49G8UwCmTOqfb1UYlHdfjvZa9Mrm1/bLL7+gW7dumD9/PqpVq4ZevXphy5YtuHXrVo7PERgYiKSkJLMlMHAkcsvb2wOxsfHIyMhU6waDAdHRsfDx8cz1ufUcm2B8+o1Py7FpMT5pv9CrS3P0GTQf19Nul4zGJ6YgI/MWvDzdTcdJ9cb5i3GoUM4NPf2a4esf9qjtZ8/HIuzQf2jZ7OFCd+0KWnz34+Rkv0WvbE4gGjVqhEWLFiEqKgpffPGFqo7o3bs3qlatismTJ+P06dNWz+Hq6ooyZcqYLa6uxZBbFSqURYMGtbBpU6haDwnZDS8vD/j6Ov5OQMuxCcan3/i0HJvW4hszrAv692yJHv5zkJR8zWzfxh/DMNS/g3rc9JEa8KlUDn/uPYGEpFSkXk/HU63r33495dzwWJOaOHbqQqG6dgUxPsodJ4OkhDlUpEgRVW1RsWJFs+3nzp3Dp59+ijVr1uD8+fPIzLydbdrmFOwhIuICAgMXITHxKkqVKong4LGoU6c6tEDLsQnGp9/4tBxbXsVXynfGPfctnjUYXTo0USUK8QkpuJqahi7PvofwvYsREXkJKSlp6rj0Gxlo13uqelzRowxWLXxFdf2URpJvBH2GP/YcV/vat2mAGYHPwsXZGS5FnbH2q9+wZNXW+8aXGvku7KEwvre35W0Jz75Y+3XDfcyzO/TILgmEkZzq119/xf/+9z+HJRBERNYSCC2wVwJReOVtArH/iv0SiOYe+kwgbKrC8PX1hbPz7da02ZEWtg+WPBAREZFuR6I8c+ZM3kVCRESkEXruPWEvuhvKmoiIKLecOJS1VUyyiIiIyGYsgSAiIrKg4+Eb7IYJBBERkQU9DwBlL0wgiIiILDB/sI5tIIiIiMhmLIEgIiKyoOdpuO2FCQQREZEF5g/WsQqDiIiIbMYSCCIiIgvshWEdEwgiIiILzB+sYwJBRLqk9dkuS/pOg5Zdi5zi6BBI45hAEBERWWAJhHVMIIiIiCywG6d17IVBRERENmMJBBERkQUWQFjHBIKIiMiCk5PB0SFoHhMIIiIiCyyBsI5tIIiIiMhmLIEgIiKywJEorWMCQUREZIHF89bxGhEREWlEcHAwHnvsMZQuXRoVK1ZE7969cfLkSbNj0tLSMGrUKFSoUAFubm7o27cvLl26ZHbMuXPn0L17d5QsWVKdZ9KkScjIyLBrrEwgiIiIsqnCsNdii99//10lB3/99Re2bduGmzdvonPnzkhNTTUdM378eGzevBnffPONOj4qKgrPPPOMaX9mZqZKHm7cuIHdu3dj7dq1WLNmDYKCgmBPTgaDQSN9VU45OgAionzDuTBy6+E8Pfu5lM12O1c1tx4P/NzY2FhVgiCJwpNPPomkpCR4enpi/fr16NevnzrmxIkTqFevHvbs2YOWLVvi559/xtNPP60SCy8vL3XM8uXL8dZbb6nzFStWzC6viyUQREREeSg9PR3Jyclmi2zLCUkYRPny5dXPAwcOqFKJTp06mY6pW7cuqlWrphIIIT8bNWpkSh6En5+f+r3//vuv3V6X7hKIs2ejMHDgJPj5jUTfvuMRHh4JrdBybILx6Tc+LccmGJ+5+VNfwvGdi3Atch0eqe+rtrm6FsWGleNxOHQ+/vp5FjZ/EYCavne+ICaN6om/d8xDypnP0aNzM7PzrZg3wvS87f83Bc0eqYn8ovX3Nj+qMIKDg+Hu7m62yDZrbt26hXHjxqFNmzZo2LCh2hYTE6NKEMqWLWt2rCQLss94TNbkwbjfuM9edJdABAUtw4ABfggJWYHhw/shIGARtELLsQnGp9/4tBybYHzmNv4Uhk79piPyfKzZ9k+/3IHG7SeiZde38eO2A/hwzjDTvtCdR9F70Fzs3HvirvNtCtmPpp3eVM+bv2wTvvjwdeQXrb+39+JkxyUwMFCVJGRdZJs10hbi6NGj+Oqrr6BFukog4uIScfRoOHr2bK/W/fxaIybmCiIjoxwdmqZjE4xPv/FpOTbB+O62K+wELsbEm21LT7+JkNDDpvWwg6fhW8XTtL7/cATOWiQcRj/+ehCZmbduP+9QOHwqlYOzc95//Gv9vc0vrq6uKFOmjNki2+5n9OjR2LJlC0JDQ1GlShXT9kqVKqnGkYmJiWbHSy8M2Wc8xrJXhnHdeIw96CqBiI6+Ak/P8nBxcVbrTk5O8Pb2RFRU9v+pGNsdjE+/8Wk5NsH4HsxrQ7pgy7YDNj9v1JAuKhExJhSF8drldDpvey22kH4Nkjxs3LgRO3bsQI0aNcz2N2vWDEWLFsX27dtN26Sbp3TbbNWqlVqXn//88w8uX75sOkZ6dEjiUr9+fTgsgVi6dCleeuklU5HK559/rgKSRhxvv/12jvqZZt+g5MaDvQIiokJG2jvUqu6FoDkbbHrewD5t8Ez3FhgduCrPYtMLe1Zh2EKqLb744gvVy0LGgpA2C7Jcv35d7Zf2E0OHDsWECRNU6YQ0qhw8eLBKGqQHhpBun/K9/OKLL+Lw4cMICQnBO++8o85treQjzxKImTNnqiTh2rVrqh/qnDlz1E9/f38MGjQIq1atwowZM6yeJ/sGJSuQW97eHoiNjUdGRqYpk4uOjoWPz51iPkfRcmyC8ek3Pi3HJhifbcaO6IZeXR5T7R2up+X8xqvv0y3x9thn8PQLs3H5SjIK47WzdTZOey22+Oijj1QbiXbt2sHb29u0bNhwJ1lcuHCh6qYpA0hJ106plvjuu+9M+52dnVX1h/yUxOKFF15QN/7Tp0+HPdmUQMhAFLJ8++232Lp1KyZPnowPPvhA/ZQGIStWrFBZkzXZNygZidyqUKEsGjSohU2bQtV6SMhueHl5wNfXJ9fn1nNsgvHpNz4txyYYX86NGdYVA3q2xtP+wUhKvpbj50mpw5SJ/dHdPxgXouJQGK9dQWEwGLJdXn75ZdMxxYsXx7JlyxAfH68GmJLkwbJtg6+vL3766Sd1wy9jP8yfPx8uLi6OG0hKhsSUASukv6mQriSHDh1CgwYN1HpkZKQqNsk6YlZ+DyQVEXEBgYGLkJh4FaVKlURw8FjUqVMdWqDl2ATj0298Wo6tsMZ3v4Gklswagi4dHoWXpzviElKQknodXZ59D+F7lyAi8hJSUtLUcek3buKp3rcHfHprTG8M8+8Ij/KlcTU1TTW6bNXtbVyJv4qk02txKTYJ8Qkppt/R7flZiE+8s55XA0nl3XubtwNJXbq+yW7n8irRE3pkUwJRs2ZNfPjhh+jSpQvCw8NVuwdpC9G/f3+1X7IdqWM5c+bMA4TCkSiJqPDgSJTaTiAup9kvgahYXJ8JhE3lGdLWQepRevXqpVqAvvnmm5g4cSLi4uJU69r33nvPNLQmERER6ZdNCcS0adNQokQJNUzm8OHDERAQgMaNG6tEQupZevTokaNGlERERFpma++JwoiTaREROQCrMLRdhRFnxyqMCjqtwtDVQFJERESUP+zbp4OIiEgHZBIsuj8mEERERHdhBmENqzCIiIjIZiyBICIisuDEEgirmEAQERFZcHJiAb01TCCIiIjuwhIIa5hiERERkc1YAkFERGSBbSCsYwJBRER0FyYQ1rAKg4iIiGzGEggiIgfQ+lwTJappO77r577M0/OzF4Z1TCCIiIjuwioMa5hiERERkc1YAkFERGSBvTCsYwJBRERkgQmEdazCICIiIpuxBIKIiOguvL+2hgkEERGRBScnVmFYwwSCiIjoLkwgrGEZDREREdmMJRBEREQW2AvDOiYQREREd2EBvTW8QkRERGQzlkAQERFZYBVGIUwgzp6NQkDAQiQkJMPNrSRmzx6H2rV9oQVajk0wPv3Gp+XYBOMrWLG9P20QundqBt+qnmjRJQBHjkXC1bUoPl86BnVrV8H1tBuIjUvG629/gojIS+o5k0b1wgv9nsRDNSph4IiF2PzLftP5mjeupc5ZrFhRFJfzfPM7FizfDEdiN85CWIURFLQMAwb4ISRkBYYP74eAgEXQCi3HJhiffuPTcmyC8RWs2L77cS869p2KyPOxZts/Wb8Dj7SboJKKLb/sx0dzR5j2he48il6D5mDn3hN3nW/p7GGYu+wHtOoWiA7PTMHYEd1Rt3blPH8dlDu6SiDi4hJx9Gg4evZsr9b9/FojJuYKIiOjHB2apmMTjE+/8Wk5NsH4Cl5su8JO4GJMvNm29PSbCAn927Qedug0fKt4mtb3H/4PZ89dzvZ8BgPgXqakelyqpCtu3sxAQmIKHMvJjos+2ZxAREdHIygoCB06dEC9evXQoEED9OjRA5988gkyMzPzJsocx3YFnp7l4eLibCqC8vb2RFSUeZbM2O7G+PQbn5ZjE4xPn7GNGtIFW7bdqaa4n5ETl2PKG/1xas8SHPl9IYLmbsCl2CQ4khOK2G3RK5te2f79+1XS8NNPP+HmzZsIDw9Hs2bNUKpUKUycOBFPPvkkrl69avU86enpSE5ONlvS02/k5nUQEZFGSHuHWr5eeHf2Vzk6fuJrPRE05ys83GoMmnaahGmTnmUVht4SiHHjxmH8+PEqkfjzzz+xZs0anDp1Cl999RUiIiJw7do1vPPOO1bPExwcDHd3d7MlOHgFcsvb2wOxsfHIyLhdEmIwGBAdHQsfnzvFaI6i5dgE49NvfFqOTTA+fcU2bkR39Or6uGrvII0pralQrjR6+j2GDT/sVutSzRF2KBytmteBY7EKw64JxMGDB/Hiiy+a1p9//nm17dKlSyhXrhzmzp2Lb7/91up5AgMDkZSUZLYEBo5EblWoUBYNGtTCpk2haj0kZDe8vDzg6+uT63PrOTbB+PQbn5ZjE4xPP7G9Pqwb+vdqjaf9ZyEp+VqOnpOQlILU6+l4qnUDU0LxWJOHcOzkeTiSVAfZa9ErJ4OkrDlUvXp1rFu3Dm3atDG1h6hcuTJSU1NRokQJnD17VlVxXL9+/QFCOQV7iIi4gMDARUhMvIpSpUoiOHgs6tSpDi3QcmyC8ek3Pi3HJhif9mIrUW3KPfctCR6Krh0ehZdnWcQlpCAl9Tr8BszA6bBlqtvm1ZTb3wE3bmTgyV7vqsdvjemD4S90hEf5MriamqaqrVt2DcSV+Kto/0RDzAx8Di7Oziha1BlrvgzF4lU/3Te+6+e+RF66ceuA3c5VrEgzoLAnEFKFsX37dsybNw+urq6YMWOGKjILDTVmvyEYNWoUTp8+7bAEgoiIkKcJhBYwgShgA0nNnDlTlTpIrwvpcdGqVSt88cUXpv1SVCPtG4iIiAoyPfeecEgJhFFaWhoyMjLg5uZmt0BYAkFEpB2FvQTi5q07Y1rkVtEiTaBHDzSUdfHixe0fCRERERUYupsLg4iIKLc4mZZ1TCCIiIgs6Ln7pb2wlQgRERHZjCUQREREd+H9tTVMIIiIiCywDYR1TLGIiIjIZiyBICIiugtLIKxhCQQREZGGJtNatmyZmntKxlxq0aIFwsLCoEVMIIiIiLL9erTXknMbNmzAhAkTMGXKFDXbdePGjeHn54fLly9Da5hAEBERacSCBQswfPhwDB48GPXr18fy5ctRsmRJfPrpp9AatoEgIiLKw14Y6enpaslKZrSWJasbN27gwIEDCAwMNG0rUqQIOnXqhD179kBzDDqUlpZmmDJlivqpNVqOTTA+fcYmGJ8+YxOMT9umTJkik1aaLbLN0sWLF9W+3bt3m22fNGmS4fHHHzdozQPNxql1ycnJcHd3R1JSEsqUKQMt0XJsgvHpMzbB+PQZm2B82paewxKIqKgoVK5cGbt370arVq1M29988038/vvv2Lt3L7SEVRhERER5yDWbZCE7Hh4ecHZ2xqVLl8y2y3qlSpWgNWxESUREpAHFihVDs2bNsH37dtO2W7duqfWsJRJawRIIIiIijZgwYQIGDRqE5s2b4/HHH8eiRYuQmpqqemVojS4TCCkqkj60OSkyym9ajk0wPn3GJhifPmMTjE8/nn32WcTGxiIoKAgxMTFo0qQJtm7dCi8vL2iNLhtREhERUd5iGwgiIiKyGRMIIiIishkTCCIiIrIZEwgiIiKyGRMIIiIispnuEgitzqP+xx9/oEePHvDx8VHzw3///ffQkuDgYDz22GMoXbo0KlasiN69e+PkyZPQgo8++giPPPKIGgJXFhlQ5eeff4ZWzZ49W73H48aNgxZMnTpVxZN1qVu3LrTi4sWLeOGFF1ChQgWUKFECjRo1wv79+6EF8lliee1kGTVqFLQgMzMT7777LmrUqKGuXa1atTBjxgyZ4whacPXqVfX/wNfXV8XXunVr7Nu3z9FhkZ3oKoHQ8jzqMhCIxCMJjhbJOOvyofjXX39h27ZtuHnzJjp37qzidrQqVaqoL2WZpU6+WDp06IBevXrh33//hdbIh+OKFStUwqMlDRo0QHR0tGnZuXMntCAhIQFt2rRB0aJFVVJ47NgxvP/++yhXrhy08n5mvW7yf0P0798fWjBnzhyVYC9duhTHjx9X63PnzsWSJUugBcOGDVPX7PPPP8c///yjPlNkZklJGkkHDDois5WNGjXKtJ6ZmWnw8fExBAcHG7RELvvGjRsNWnb58mUV5++//27QonLlyhlWrVpl0JKrV68aateubdi2bZvhqaeeMowdO9agBTLrX+PGjQ1a9NZbbxmeeOIJQ0Eh72mtWrUMt27dMmhB9+7dDUOGDDHb9swzzxj8/f0Njnbt2jWDs7OzYcuWLWbbmzZtapg8ebLD4iL70U0JhHEedcluC8Q86hons+aJ8uXLQ0ukyParr75SJSNaGxteSnC6d+9u9jeoFeHh4ar6rGbNmvD398e5c+egBZs2bVJD9sodvVSdPfroo/j444+h1c+YL774AkOGDFHVGFogVQIyT8KpU6fU+uHDh1XpUteuXR0dGjIyMtT/V6lOzkqqMrRSAka5o5uhrK9cuaL+WC2H+5T1EydOOCyugkgmb5F6SylabtiwIbRAij8lYUhLS4Obmxs2btyI+vXrQyskqZFqMy3W70pboDVr1qBOnTqqGH7atGlo27Ytjh49qtq8OFJERIQqgpeqx7fffltdv9dff11NKiTzAWiJtFtKTEzEyy+/DK0ICAhQU2VLmxaZxVE+A9977z2VJDqa/G3J/1lpk1GvXj31Wfzll1+qG7qHHnrI0eGRHegmgSD73knLl4uW7hLky+/vv/9WJSPffvut+nKRdhtaSCLOnz+PsWPHqrpey7stLch6NyptMyShkEZtX3/9NYYOHerwZFVKIGbNmqXWpQRC/vaWL1+uuQTik08+UddSSnK0Qt7DdevWYf369aqdi/wfkeRfYtTC9ZO2D1JiU7lyZZXgNG3aFM8995wqLaaCTzcJREGbR12rRo8ejS1btqheI9J4USvkjtR41yLT3cqd6gcffKAaLDqafBhKQ135cDSSO0G5htK4LT09Xf1takXZsmXx8MMP4/Tp044OBd7e3nclgXK3+n//93/QksjISPz666/47rvvoCWTJk1SpRADBw5U69KDRWKVXlVaSCCkV4gk+lLlKCUl8n7LZFFSlUYFn27aQBS0edS1Rtp2SvIgVQM7duxQ3cK0TN5b+WLWgo4dO6oqFrn7My5yVy3FyPJYS8mDSElJwX///ac+zB1NqsksuwtLfb6UkGjJ6tWrVRsNaeOiJdeuXVNtvbKSvzf5/6ElpUqVUn9v0usmJCRE9aKigk83JRBan0ddPrSz3vGdOXNGfblII8Vq1apBC9UWUgz6ww8/qLpLmUZWuLu7q0ZPjhQYGKiKjuU6Sb9yifO3335TH0RaINfLsq2IfGDKuAZaaEMyceJENQaJfClHRUWpbs7yJSNFyY42fvx41RBQqjAGDBigxm1ZuXKlWrRCvowlgZDPFhcXbX1kyvsqbR7k/4ZUYRw6dAgLFixQ1QZaIP9H5eZEqiDl809KTKS9hhY+k8kODDqzZMkSQ7Vq1QzFihVT3Tr/+usvgxaEhoaqbpGWy6BBgwxakF1ssqxevdrRoaluar6+vuo99fT0NHTs2NHwyy+/GLRMS904n332WYO3t7e6fpUrV1brp0+fNmjF5s2bDQ0bNjS4uroa6tata1i5cqVBS0JCQtT/hZMnTxq0Jjk5Wf2dyWde8eLFDTVr1lRdJNPT0w1asGHDBhWT/O1VqlRJdbNPTEx0dFhkJ07yjz0SESIiIio8dNMGgoiIiPIPEwgiIiKyGRMIIiIishkTCCIiIrIZEwgiIiKyGRMIIiIishkTCCIiIrIZEwgiIiKyGRMIIiIishkTCCIiIrIZEwgiIiKCrf4fz6q05yR21CIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/93\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 10:05:04.803692: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 10:05:04.804027: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Classification_2D.model.summary()\n",
    "\n",
    "CNN_2D_train_accuracy = np.average(accuracy_train)*100\n",
    "print('CNN 2D train accuracy =', CNN_2D_train_accuracy)\n",
    "# print(accuracy_train)\n",
    "\n",
    "CNN_2D_val_accuracy = np.average(accuracy_val)*100\n",
    "print('CNN 2D validation accuracy =', CNN_2D_val_accuracy)\n",
    "# print(accuracy_val)\n",
    "\n",
    "CNN_2D_test_accuracy = np.average(accuracy_test)*100\n",
    "print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "# print(accuracy_test)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test set\n",
    "# CNN_2D_test_loss, CNN_2D_test_accuracy = Classification_2D.model.evaluate(X_2D_test, y_2D_test)\n",
    "# CNN_2D_test_accuracy*=100\n",
    "# print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "  y_pred = np.argmax(Model.predict(X), axis=1)\n",
    "  ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "  return ConfusionMat\n",
    "\n",
    "# Plot results - CNN 2D\n",
    "plt.figure(5)\n",
    "plt.title('Confusion Matrix - CNN 2D Train') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_train, y_2D_train) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.title('Confusion Matrix - CNN 2D Test') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_test, y_2D_test) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7)\n",
    "plt.title('Train - Accuracy - CNN 2D')\n",
    "plt.bar(np.arange(1,kSplits+1),[i*100 for i in accuracy_val])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70,100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(8)\n",
    "plt.title('Train vs Test Accuracy - CNN 2D')\n",
    "plt.bar([1,2],[CNN_2D_train_accuracy,CNN_2D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.xticks([1,2],['Train', 'Test'])\n",
    "plt.ylim([70,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d304a-13a4-42ce-bd02-0c15bc3ecc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b387e8-173c-4018-8896-a0340889bd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
