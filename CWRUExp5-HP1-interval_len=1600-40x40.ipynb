{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5ab9cc-9d31-4bd8-9339-c80842c4c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32209d77-1aef-4ca4-81d7-ea6457e51333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 1\n",
    "random.seed(SEED)            # Python random module\n",
    "np.random.seed(SEED)         # NumPy\n",
    "tf.random.set_seed(SEED)     # TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71899bcf-951f-483f-9b14-081df6aa4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce deterministic behavior for GPU operations\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic execution\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Deterministic cuDNN algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd1cd7b-5ae6-45e4-9888-9da0cae55811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control GPU memory allocation (prevents TensorFlow from using all GPU memory)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # Enable memory growth\n",
    "\n",
    "# Restrict parallelism (ensures consistent execution order)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0842921e-69f2-4b98-a50d-a8cbf80872d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import scipy.io #to load matlab files \n",
    "# import numpy as np\n",
    "from sklearn.model_selection import train_test_split #for data splitting #, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras import layers, models #build and train CNN model\n",
    "import matplotlib.pyplot as plt #for plotting confusion matrices and accuracy metrics\n",
    "import seaborn as sns \n",
    "# import pandas as pd\n",
    "\n",
    "from scipy import signal #for computing spectograms\n",
    "from skimage.transform import resize #for resizing data\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9d9640-93e2-47e2-98d4-06a74ec1a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Read CWRU Bearing Data (Load - 2HP)\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "def ImportData():\n",
    "  folder_path = 'CWRU_BearingData_Load_1HP' \n",
    "  # X99_normal = scipy.io.loadmat('content/drive/MyDrive/BearingData_CaseWestern/99.mat')['X099_DE_time'] \n",
    "  file_path1 = os.path.join(folder_path, '98.mat')\n",
    "  X098_normal = scipy.io.loadmat(file_path1)['X098_DE_time'] #vibration data extracted from X099_DE_time key (drive-end accelerometer data)\n",
    "\n",
    " \n",
    "\n",
    "  file_path2 = os.path.join(folder_path, '110.mat')\n",
    "  X110_InnerRace_007  = scipy.io.loadmat(file_path2)['X110_DE_time']\n",
    "  # mat_data = scipy.io.loadmat(file_path2)\n",
    "  # print(mat_data.keys())\n",
    "\n",
    "  file_path2 = os.path.join(folder_path, '123.mat')\n",
    "  X123_Ball_007  = scipy.io.loadmat(file_path2)['X123_DE_time']\n",
    "\n",
    "  file_path3 = os.path.join(folder_path, '136.mat')\n",
    "  X136_Outer_007 = scipy.io.loadmat(file_path3)['X136_DE_time']\n",
    "\n",
    "  file_path6 = os.path.join(folder_path, '175.mat')\n",
    "  X175_InnerRace_014 = scipy.io.loadmat(file_path6)['X175_DE_time']\n",
    "    \n",
    "  file_path7 = os.path.join(folder_path, '190.mat')\n",
    "  X190_Ball_014 = scipy.io.loadmat(file_path7)['X190_DE_time']\n",
    "\n",
    "  file_path8 = os.path.join(folder_path, '202.mat')\n",
    "  X202_Outer_014  = scipy.io.loadmat(file_path8)['X202_DE_time']\n",
    "    \n",
    "  file_path9 = os.path.join(folder_path, '214.mat')\n",
    "  X214_InnerRace_021  = scipy.io.loadmat(file_path9)['X214_DE_time']\n",
    "\n",
    "  file_path10 = os.path.join(folder_path, '227.mat')\n",
    "  X227_Ball_021  = scipy.io.loadmat(file_path10)['X227_DE_time'] \n",
    "\n",
    "  file_path11 = os.path.join(folder_path, '239.mat')\n",
    "  X239_Outer_021  = scipy.io.loadmat(file_path11)['X239_DE_time'] \n",
    "    \n",
    "  return [X098_normal,X110_InnerRace_007,X123_Ball_007,X136_Outer_007,X175_InnerRace_014,X190_Ball_014,X202_Outer_014,X214_InnerRace_021,X227_Ball_021,X239_Outer_021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3827a-7567-422b-9d6a-08b5aa1ce7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6fbfd8-76a9-49e1-94e2-2924bd737533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data Processing and Feature Extraction\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "# def Sampling(Data, interval_length, samples_per_block):\n",
    "#     No_of_blocks = (round(len(Data)/interval_length) - round(samples_per_block/interval_length) - 1)\n",
    "#     SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "#     for i in range(No_of_blocks):\n",
    "#         SplitData[i,:] = Data[i*interval_length:(i*interval_length)+samples_per_block].T\n",
    "#     return SplitData\n",
    "\n",
    "#segments the time-series data into smaller blocks for processing\n",
    "#data: 1D numpy array of vibration data\n",
    "#interval length: step size (in samples) betweeen the start of consectuive blocks\n",
    "#samples_per_block: no. of samples in each block (fixed at 1600 in the code)\n",
    "#ignore_points: no. of points to skip at start and end of data(default is 0)\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    # Adjust data length to ignore the first and last 'ignore_points'\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    # Adjust the number of blocks\n",
    "    No_of_blocks = (round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1)\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block]) #splitdata matrix where each row is a block of samples_per_block samples\n",
    "    \n",
    "    for i in range(No_of_blocks):\n",
    "        # Skip the first 'ignore_points' and start sampling from that position\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx:(start_idx + samples_per_block)].T #.T transpose ensure the data is correctly oriented (since the input is a column vector)\n",
    "    \n",
    "    return SplitData #2D array of shape - no.ofblocks, samples_per_block)\n",
    "\n",
    "\n",
    "def DataPreparation(Data, interval_length, samples_per_block):\n",
    "  for count,i in enumerate(Data):\n",
    "    SplitData = Sampling(i, interval_length, samples_per_block) #for each dataset calls samplying to create blocks of 1600 samples\n",
    "    y = np.zeros([len(SplitData),10]) #y (one-hot encoded): Shape (No_of_blocks, 10), where the column corresponding to the class is set to 1 (e.g., for class 0, [1, 0, 0, ..., 0])\n",
    "    y[:,count] = 1\n",
    "    y1 = np.zeros([len(SplitData),1]) #y1 (integer labels): Shape (No_of_blocks, 1), where each element is the class index (0 to 9).\n",
    "    y1[:,0] = count \n",
    "    # Stack up and label the data   \n",
    "    if count==0:\n",
    "      X = SplitData\n",
    "      LabelPositional = y\n",
    "      Label = y1\n",
    "    else:\n",
    "      X = np.append(X, SplitData, axis=0)\n",
    "      LabelPositional = np.append(LabelPositional,y,axis=0)\n",
    "      Label = np.append(Label,y1,axis=0)\n",
    "  print(X)\n",
    "  return X, LabelPositional, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44975d7a-8b19-44e0-a88f-ca7bf2c4749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(ary):\n",
    "    ary = (ary - ary.min()) / np.abs(ary.max() - ary.min())\n",
    "    return ary\n",
    "\n",
    "def generate_spectrogram_image(data_y_vector, image_shape):\n",
    "    \"\"\"\n",
    "    Calculate the spectrogram of an array data_y_vector and resize it in \n",
    "    the image_shape resolution\n",
    "    \"\"\"\n",
    "    fs = 48000\n",
    "    # data_y_vector_len = np.shape(data_y_vector)[0]\n",
    "\n",
    "    f, t, sxx = signal.spectrogram(\n",
    "        data_y_vector,\n",
    "        fs)\n",
    "\n",
    "    sxx = min_max_norm(sxx)\n",
    "    sxx = resize(sxx, image_shape, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    return sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c91be0-79cd-438c-876c-9291efc88572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (483903, 1)\n",
      "Dataset 2 shape: (486224, 1)\n",
      "Dataset 3 shape: (487384, 1)\n",
      "Dataset 4 shape: (486804, 1)\n",
      "Dataset 5 shape: (381890, 1)\n",
      "Dataset 6 shape: (486224, 1)\n",
      "Dataset 7 shape: (484483, 1)\n",
      "Dataset 8 shape: (485063, 1)\n",
      "Dataset 9 shape: (486804, 1)\n",
      "Dataset 10 shape: (489125, 1)\n",
      "[[ 0.046104   -0.03713354 -0.089496   ...  0.04714708 -0.00125169\n",
      "  -0.07134646]\n",
      " [-0.14164985 -0.15792185 -0.10952308 ...  0.06133292 -0.00292062\n",
      "  -0.03775938]\n",
      " [-0.01293415  0.05799508  0.111192   ... -0.13142769 -0.13267938\n",
      "  -0.07802215]\n",
      " ...\n",
      " [ 0.47158667  0.38645067  0.30465333 ... -0.01418933 -0.06176533\n",
      "  -0.07094667]\n",
      " [-0.055088   -0.020032    0.017528   ...  0.27544     0.35723733\n",
      "   0.37226133]\n",
      " [ 0.33887467  0.247896    0.10934133 ... -0.11852267 -0.06426933\n",
      "  -0.03422133]]\n",
      "Shape of Input Data = (2954, 1600)\n",
      "Shape of Label Y_CNN = (2954, 10)\n",
      "Shape of Label Y = (2954, 1)\n"
     ]
    }
   ],
   "source": [
    "Data = ImportData()\n",
    "for i, d in enumerate(Data):\n",
    "    print(f\"Dataset {i+1} shape: {d.shape}\")\n",
    "interval_length = 1600 #320 #290 #200  \n",
    "samples_per_block = 1600 #1600 #1650-25*2\n",
    "\n",
    "\n",
    "# Y_CNN is of shape (n, 10) representing 10 classes as 10 columns. In each sample, for the class to which it belongs, \n",
    "# the corresponding column value is marked 1 and the rest as 0, facilitating Softmax implementation in CNN \n",
    "# Y is of shape (m, 1) where column values are between 0 and 9 representing the classes directly. - 1-hot encoding\n",
    "X, Y_CNN, Y = DataPreparation(Data, interval_length, samples_per_block) \n",
    "\n",
    "\n",
    "print('Shape of Input Data =', X.shape)\n",
    "print('Shape of Label Y_CNN =', Y_CNN.shape)\n",
    "print('Shape of Label Y =', Y.shape)\n",
    "\n",
    "# XX = {'X':X}\n",
    "# scipy.io.savemat('Data.mat', XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaaee3ff-4250-4baf-bf15-23256e6d8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2954, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Training\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "## 2-Dimensional Convolutional Neural Network Classification\n",
    "\n",
    "# Reshape the data - 2 dimensional feed \n",
    "Input_2D = X.reshape([-1,40,40,1])\n",
    "\n",
    "# Input_2D = X_image.reshape([-1,96,96,1])\n",
    "print(Input_2D.shape)\n",
    "\n",
    "# Test-Train Split \n",
    "X_2D_train, X_2D_test, y_2D_train, y_2D_test, y_label_train, y_label_test = train_test_split(Input_2D, Y_CNN, Y, train_size=0.8, test_size=0.2, random_state=42, stratify=Y)\n",
    "#(ensuring class balance via stratify=Y)\n",
    "# X_2D_train, X_2D_test, y_2D_train, y_2D_test = train_test_split(Input_2D, Y_CNN, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define the CNN Classification model\n",
    "class CNN_2D():\n",
    "  def __init__(self):\n",
    "    self.model = self.CreateModel()\n",
    "\n",
    "  def CreateModel(self):\n",
    "    model = models.Sequential([\n",
    "        # layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding ='same',activation='relu'),\n",
    "        layers.Conv2D(filters=16, kernel_size=(3,3), padding='same',activation='relu', input_shape=(40,40,1)),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=32, kernel_size=(3,3), padding ='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=64, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100,activation='relu'),\n",
    "        layers.Dense(50,activation='relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Softmax()\n",
    "        ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf41e7c-a3e8-4875-ac08-918e90ad86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gayathri/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-06-10 08:25:09.658430: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:25:09.658821: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1847 - loss: 2.0707\n",
      "Epoch 1: val_accuracy improved from -inf to 0.43129, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.1892 - loss: 2.0595 - val_accuracy: 0.4313 - val_loss: 1.3200\n",
      "Epoch 2/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5711 - loss: 1.0907\n",
      "Epoch 2: val_accuracy improved from 0.43129 to 0.78647, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5745 - loss: 1.0828 - val_accuracy: 0.7865 - val_loss: 0.6218\n",
      "Epoch 3/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8049 - loss: 0.5202\n",
      "Epoch 3: val_accuracy improved from 0.78647 to 0.83087, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8058 - loss: 0.5185 - val_accuracy: 0.8309 - val_loss: 0.4682\n",
      "Epoch 4/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8476 - loss: 0.4399\n",
      "Epoch 4: val_accuracy improved from 0.83087 to 0.83510, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8486 - loss: 0.4387 - val_accuracy: 0.8351 - val_loss: 0.4244\n",
      "Epoch 5/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8997 - loss: 0.2781\n",
      "Epoch 5: val_accuracy did not improve from 0.83510\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9001 - loss: 0.2771 - val_accuracy: 0.8224 - val_loss: 0.4700\n",
      "Epoch 6/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8860 - loss: 0.3192\n",
      "Epoch 6: val_accuracy improved from 0.83510 to 0.83721, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8866 - loss: 0.3174 - val_accuracy: 0.8372 - val_loss: 0.4410\n",
      "Epoch 7/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8968 - loss: 0.2795\n",
      "Epoch 7: val_accuracy did not improve from 0.83721\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8974 - loss: 0.2781 - val_accuracy: 0.8182 - val_loss: 0.4990\n",
      "Epoch 8/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9195 - loss: 0.2269\n",
      "Epoch 8: val_accuracy improved from 0.83721 to 0.92812, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9201 - loss: 0.2250 - val_accuracy: 0.9281 - val_loss: 0.1963\n",
      "Epoch 9/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9518 - loss: 0.1373\n",
      "Epoch 9: val_accuracy did not improve from 0.92812\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9519 - loss: 0.1369 - val_accuracy: 0.8414 - val_loss: 0.5118\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9394 - loss: 0.1947\n",
      "Epoch 10: val_accuracy improved from 0.92812 to 0.93869, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9396 - loss: 0.1938 - val_accuracy: 0.9387 - val_loss: 0.1568\n",
      "Epoch 11/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9524 - loss: 0.1159\n",
      "Epoch 11: val_accuracy did not improve from 0.93869\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9524 - loss: 0.1162 - val_accuracy: 0.7569 - val_loss: 0.7825\n",
      "Epoch 12/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9198 - loss: 0.2588\n",
      "Epoch 12: val_accuracy did not improve from 0.93869\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9206 - loss: 0.2561 - val_accuracy: 0.7992 - val_loss: 0.5871\n",
      "Epoch 13/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9190 - loss: 0.2335\n",
      "Epoch 13: val_accuracy did not improve from 0.93869\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9201 - loss: 0.2300 - val_accuracy: 0.8985 - val_loss: 0.2962\n",
      "Epoch 14/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9508 - loss: 0.1292\n",
      "Epoch 14: val_accuracy did not improve from 0.93869\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9510 - loss: 0.1285 - val_accuracy: 0.9281 - val_loss: 0.1999\n",
      "Epoch 15/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9754 - loss: 0.0761\n",
      "Epoch 15: val_accuracy improved from 0.93869 to 0.95983, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9757 - loss: 0.0753 - val_accuracy: 0.9598 - val_loss: 0.1246\n",
      "Epoch 16/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9792 - loss: 0.0571\n",
      "Epoch 16: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9791 - loss: 0.0572 - val_accuracy: 0.9450 - val_loss: 0.2029\n",
      "Epoch 17/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9820 - loss: 0.0507\n",
      "Epoch 17: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9818 - loss: 0.0511 - val_accuracy: 0.9514 - val_loss: 0.1289\n",
      "Epoch 18/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9880 - loss: 0.0359\n",
      "Epoch 18: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9878 - loss: 0.0361 - val_accuracy: 0.9302 - val_loss: 0.2119\n",
      "Epoch 19/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9800 - loss: 0.0543\n",
      "Epoch 19: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9799 - loss: 0.0543 - val_accuracy: 0.9556 - val_loss: 0.1264\n",
      "Epoch 20/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.0424\n",
      "Epoch 20: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9821 - loss: 0.0430 - val_accuracy: 0.9514 - val_loss: 0.1702\n",
      "Epoch 21/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9880 - loss: 0.0383\n",
      "Epoch 21: val_accuracy improved from 0.95983 to 0.96406, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9880 - loss: 0.0383 - val_accuracy: 0.9641 - val_loss: 0.1235\n",
      "Epoch 22/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9890 - loss: 0.0328\n",
      "Epoch 22: val_accuracy did not improve from 0.96406\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9887 - loss: 0.0331 - val_accuracy: 0.9408 - val_loss: 0.1740\n",
      "Epoch 23/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9779 - loss: 0.0661\n",
      "Epoch 23: val_accuracy did not improve from 0.96406\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9778 - loss: 0.0662 - val_accuracy: 0.9323 - val_loss: 0.2078\n",
      "Epoch 24/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9741 - loss: 0.0668\n",
      "Epoch 24: val_accuracy did not improve from 0.96406\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9739 - loss: 0.0673 - val_accuracy: 0.9175 - val_loss: 0.2690\n",
      "Epoch 25/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9934 - loss: 0.0331\n",
      "Epoch 25: val_accuracy improved from 0.96406 to 0.96829, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9934 - loss: 0.0327 - val_accuracy: 0.9683 - val_loss: 0.0959\n",
      "Epoch 26/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9941 - loss: 0.0174\n",
      "Epoch 26: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9941 - loss: 0.0176 - val_accuracy: 0.9493 - val_loss: 0.1847\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9840 - loss: 0.0369\n",
      "Epoch 27: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9839 - loss: 0.0370 - val_accuracy: 0.9471 - val_loss: 0.1732\n",
      "Epoch 28/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9844 - loss: 0.0361\n",
      "Epoch 28: val_accuracy improved from 0.96829 to 0.97463, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9844 - loss: 0.0359 - val_accuracy: 0.9746 - val_loss: 0.1103\n",
      "Epoch 29/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9923 - loss: 0.0164\n",
      "Epoch 29: val_accuracy did not improve from 0.97463\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9922 - loss: 0.0165 - val_accuracy: 0.8414 - val_loss: 0.5167\n",
      "Epoch 30/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9649 - loss: 0.0984\n",
      "Epoch 30: val_accuracy did not improve from 0.97463\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9649 - loss: 0.0981 - val_accuracy: 0.9260 - val_loss: 0.2598\n",
      "Epoch 31/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9788 - loss: 0.0925\n",
      "Epoch 31: val_accuracy did not improve from 0.97463\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9789 - loss: 0.0916 - val_accuracy: 0.9641 - val_loss: 0.1477\n",
      "Epoch 32/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9896 - loss: 0.0225\n",
      "Epoch 32: val_accuracy improved from 0.97463 to 0.97674, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9896 - loss: 0.0225 - val_accuracy: 0.9767 - val_loss: 0.0923\n",
      "Epoch 33/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9846 - loss: 0.0382\n",
      "Epoch 33: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9847 - loss: 0.0382 - val_accuracy: 0.9619 - val_loss: 0.1157\n",
      "Epoch 34/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9938 - loss: 0.0179\n",
      "Epoch 34: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9938 - loss: 0.0180 - val_accuracy: 0.9408 - val_loss: 0.1962\n",
      "Epoch 35/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9935 - loss: 0.0180\n",
      "Epoch 35: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9936 - loss: 0.0179 - val_accuracy: 0.9704 - val_loss: 0.1083\n",
      "Epoch 36/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9986 - loss: 0.0059\n",
      "Epoch 36: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.9641 - val_loss: 0.1260\n",
      "Epoch 37/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9990 - loss: 0.0079\n",
      "Epoch 37: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9989 - loss: 0.0080 - val_accuracy: 0.9704 - val_loss: 0.1094\n",
      "Epoch 38/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9984 - loss: 0.0065\n",
      "Epoch 38: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.9725 - val_loss: 0.1152\n",
      "Epoch 39/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9942 - loss: 0.0141\n",
      "Epoch 39: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9940 - loss: 0.0145 - val_accuracy: 0.9493 - val_loss: 0.1710\n",
      "Epoch 40/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9801 - loss: 0.0709\n",
      "Epoch 40: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9799 - loss: 0.0722 - val_accuracy: 0.8055 - val_loss: 1.1033\n",
      "Epoch 41/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9409 - loss: 0.2264\n",
      "Epoch 41: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9414 - loss: 0.2244 - val_accuracy: 0.9577 - val_loss: 0.1370\n",
      "Epoch 42/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9946 - loss: 0.0186\n",
      "Epoch 42: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9947 - loss: 0.0184 - val_accuracy: 0.9619 - val_loss: 0.1332\n",
      "Epoch 43/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9941 - loss: 0.0148\n",
      "Epoch 43: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9942 - loss: 0.0147 - val_accuracy: 0.9556 - val_loss: 0.1469\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9954 - loss: 0.0122\n",
      "Epoch 44: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9954 - loss: 0.0123 - val_accuracy: 0.9641 - val_loss: 0.1380\n",
      "Epoch 45/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9942 - loss: 0.0166\n",
      "Epoch 45: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.9683 - val_loss: 0.1394\n",
      "Epoch 46/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9980 - loss: 0.0062\n",
      "Epoch 46: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9979 - loss: 0.0064 - val_accuracy: 0.9577 - val_loss: 0.1762\n",
      "Epoch 47/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9986 - loss: 0.0062\n",
      "Epoch 47: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9683 - val_loss: 0.1263\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9988 - loss: 0.0049\n",
      "Epoch 48: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.9619 - val_loss: 0.1156\n",
      "Epoch 49/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9977 - loss: 0.0069\n",
      "Epoch 49: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9471 - val_loss: 0.2096\n",
      "Epoch 50/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9989 - loss: 0.0065\n",
      "Epoch 50: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9988 - loss: 0.0066 - val_accuracy: 0.9239 - val_loss: 0.3230\n",
      "Epoch 51/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9740 - loss: 0.0745\n",
      "Epoch 51: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9743 - loss: 0.0738 - val_accuracy: 0.9514 - val_loss: 0.1618\n",
      "Epoch 52/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9964 - loss: 0.0110\n",
      "Epoch 52: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9964 - loss: 0.0110 - val_accuracy: 0.9746 - val_loss: 0.0998\n",
      "Epoch 53/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 53: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9767 - val_loss: 0.0892\n",
      "Epoch 54/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.9038e-04\n",
      "Epoch 54: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 4.9645e-04 - val_accuracy: 0.9767 - val_loss: 0.0935\n",
      "Epoch 55/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 4.1785e-04\n",
      "Epoch 55: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.2258e-04 - val_accuracy: 0.9767 - val_loss: 0.0985\n",
      "Epoch 56/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.9430e-04\n",
      "Epoch 56: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 3.9792e-04 - val_accuracy: 0.9767 - val_loss: 0.1027\n",
      "Epoch 57/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.7261e-04\n",
      "Epoch 57: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.7533e-04 - val_accuracy: 0.9767 - val_loss: 0.1070\n",
      "Epoch 58/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.6310e-04\n",
      "Epoch 58: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.6410e-04 - val_accuracy: 0.9767 - val_loss: 0.1104\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.3888e-04\n",
      "Epoch 59: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.3961e-04 - val_accuracy: 0.9767 - val_loss: 0.1135\n",
      "Epoch 60/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.2330e-04\n",
      "Epoch 60: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.2378e-04 - val_accuracy: 0.9767 - val_loss: 0.1157\n",
      "Epoch 61/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.9818e-04\n",
      "Epoch 61: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.9886e-04 - val_accuracy: 0.9767 - val_loss: 0.1177\n",
      "Epoch 62/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.7717e-04\n",
      "Epoch 62: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.7750e-04 - val_accuracy: 0.9767 - val_loss: 0.1187\n",
      "Epoch 63/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.4806e-04\n",
      "Epoch 63: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.4808e-04 - val_accuracy: 0.9767 - val_loss: 0.1175\n",
      "Epoch 64/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 2.0826e-04\n",
      "Epoch 64: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.0809e-04 - val_accuracy: 0.9767 - val_loss: 0.1141\n",
      "Epoch 65/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.5871e-04\n",
      "Epoch 65: val_accuracy improved from 0.97674 to 0.97886, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.5856e-04 - val_accuracy: 0.9789 - val_loss: 0.1101\n",
      "Epoch 66/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.1367e-04\n",
      "Epoch 66: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.1369e-04 - val_accuracy: 0.9789 - val_loss: 0.1086\n",
      "Epoch 67/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.4967e-05\n",
      "Epoch 67: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 9.5085e-05 - val_accuracy: 0.9789 - val_loss: 0.1092\n",
      "Epoch 68/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.7803e-05\n",
      "Epoch 68: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.7858e-05 - val_accuracy: 0.9789 - val_loss: 0.1097\n",
      "Epoch 69/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 8.1393e-05\n",
      "Epoch 69: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 8.1447e-05 - val_accuracy: 0.9789 - val_loss: 0.1102\n",
      "Epoch 70/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.5882e-05\n",
      "Epoch 70: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 7.5935e-05 - val_accuracy: 0.9789 - val_loss: 0.1107\n",
      "Epoch 71/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.0760e-05\n",
      "Epoch 71: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 7.0869e-05 - val_accuracy: 0.9789 - val_loss: 0.1112\n",
      "Epoch 72/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.6324e-05\n",
      "Epoch 72: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.6430e-05 - val_accuracy: 0.9789 - val_loss: 0.1117\n",
      "Epoch 73/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.2319e-05\n",
      "Epoch 73: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.2421e-05 - val_accuracy: 0.9789 - val_loss: 0.1121\n",
      "Epoch 74/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.8622e-05\n",
      "Epoch 74: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.8721e-05 - val_accuracy: 0.9789 - val_loss: 0.1127\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.5384e-05\n",
      "Epoch 75: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.5432e-05 - val_accuracy: 0.9789 - val_loss: 0.1133\n",
      "Epoch 76/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.2363e-05\n",
      "Epoch 76: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.2454e-05 - val_accuracy: 0.9789 - val_loss: 0.1138\n",
      "Epoch 77/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.9473e-05\n",
      "Epoch 77: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.9563e-05 - val_accuracy: 0.9789 - val_loss: 0.1143\n",
      "Epoch 78/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.6833e-05\n",
      "Epoch 78: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.6919e-05 - val_accuracy: 0.9789 - val_loss: 0.1149\n",
      "Epoch 79/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 4.4428e-05\n",
      "Epoch 79: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.4510e-05 - val_accuracy: 0.9789 - val_loss: 0.1154\n",
      "Epoch 80/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.2262e-05\n",
      "Epoch 80: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.2302e-05 - val_accuracy: 0.9789 - val_loss: 0.1159\n",
      "Epoch 81/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.0076e-05\n",
      "Epoch 81: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.0194e-05 - val_accuracy: 0.9789 - val_loss: 0.1164\n",
      "Epoch 82/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.8162e-05\n",
      "Epoch 82: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.8238e-05 - val_accuracy: 0.9789 - val_loss: 0.1169\n",
      "Epoch 83/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.6394e-05\n",
      "Epoch 83: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.6465e-05 - val_accuracy: 0.9789 - val_loss: 0.1174\n",
      "Epoch 84/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4667e-05\n",
      "Epoch 84: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.4739e-05 - val_accuracy: 0.9789 - val_loss: 0.1178\n",
      "Epoch 85/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.3089e-05\n",
      "Epoch 85: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.3157e-05 - val_accuracy: 0.9789 - val_loss: 0.1183\n",
      "Epoch 86/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.1532e-05\n",
      "Epoch 86: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 3.1599e-05 - val_accuracy: 0.9789 - val_loss: 0.1187\n",
      "Epoch 87/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.0121e-05\n",
      "Epoch 87: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 3.0187e-05 - val_accuracy: 0.9789 - val_loss: 0.1191\n",
      "Epoch 88/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.8775e-05\n",
      "Epoch 88: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.8807e-05 - val_accuracy: 0.9789 - val_loss: 0.1196\n",
      "Epoch 89/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.7386e-05\n",
      "Epoch 89: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.7484e-05 - val_accuracy: 0.9789 - val_loss: 0.1200\n",
      "Epoch 90/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.6194e-05\n",
      "Epoch 90: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.6257e-05 - val_accuracy: 0.9789 - val_loss: 0.1205\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.5094e-05\n",
      "Epoch 91: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.5123e-05 - val_accuracy: 0.9789 - val_loss: 0.1210\n",
      "Epoch 92/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.3983e-05\n",
      "Epoch 92: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.4012e-05 - val_accuracy: 0.9789 - val_loss: 0.1214\n",
      "Epoch 93/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2918e-05\n",
      "Epoch 93: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.2976e-05 - val_accuracy: 0.9789 - val_loss: 0.1219\n",
      "Epoch 94/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.1949e-05\n",
      "Epoch 94: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2004e-05 - val_accuracy: 0.9789 - val_loss: 0.1224\n",
      "Epoch 95/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1026e-05\n",
      "Epoch 95: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.1053e-05 - val_accuracy: 0.9789 - val_loss: 0.1228\n",
      "Epoch 96/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0095e-05\n",
      "Epoch 96: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.0148e-05 - val_accuracy: 0.9789 - val_loss: 0.1233\n",
      "Epoch 97/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.9226e-05\n",
      "Epoch 97: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.9305e-05 - val_accuracy: 0.9789 - val_loss: 0.1238\n",
      "Epoch 98/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8422e-05\n",
      "Epoch 98: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.8499e-05 - val_accuracy: 0.9789 - val_loss: 0.1242\n",
      "Epoch 99/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.7657e-05\n",
      "Epoch 99: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.7706e-05 - val_accuracy: 0.9789 - val_loss: 0.1247\n",
      "Epoch 100/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.6957e-05\n",
      "Epoch 100: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7004e-05 - val_accuracy: 0.9789 - val_loss: 0.1252\n",
      "Epoch 101/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.6268e-05\n",
      "Epoch 101: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.6290e-05 - val_accuracy: 0.9789 - val_loss: 0.1256\n",
      "Epoch 102/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5585e-05\n",
      "Epoch 102: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.5630e-05 - val_accuracy: 0.9789 - val_loss: 0.1261\n",
      "Epoch 103/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4953e-05\n",
      "Epoch 103: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.4975e-05 - val_accuracy: 0.9789 - val_loss: 0.1266\n",
      "Epoch 104/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.4381e-05\n",
      "Epoch 104: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.4401e-05 - val_accuracy: 0.9789 - val_loss: 0.1270\n",
      "Epoch 105/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.3780e-05\n",
      "Epoch 105: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.3820e-05 - val_accuracy: 0.9789 - val_loss: 0.1275\n",
      "Epoch 106/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.3214e-05\n",
      "Epoch 106: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3274e-05 - val_accuracy: 0.9789 - val_loss: 0.1279\n",
      "Epoch 107/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2727e-05\n",
      "Epoch 107: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.2765e-05 - val_accuracy: 0.9789 - val_loss: 0.1283\n",
      "Epoch 108/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.2238e-05\n",
      "Epoch 108: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2256e-05 - val_accuracy: 0.9789 - val_loss: 0.1288\n",
      "Epoch 109/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1750e-05\n",
      "Epoch 109: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.1786e-05 - val_accuracy: 0.9789 - val_loss: 0.1293\n",
      "Epoch 110/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.1317e-05\n",
      "Epoch 110: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.1334e-05 - val_accuracy: 0.9789 - val_loss: 0.1297\n",
      "Epoch 111/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.0870e-05\n",
      "Epoch 111: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0903e-05 - val_accuracy: 0.9789 - val_loss: 0.1302\n",
      "Epoch 112/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.0449e-05\n",
      "Epoch 112: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0482e-05 - val_accuracy: 0.9789 - val_loss: 0.1306\n",
      "Epoch 113/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0064e-05\n",
      "Epoch 113: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.0096e-05 - val_accuracy: 0.9789 - val_loss: 0.1311\n",
      "Epoch 114/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.6617e-06\n",
      "Epoch 114: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 9.7090e-06 - val_accuracy: 0.9789 - val_loss: 0.1315\n",
      "Epoch 115/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.3360e-06\n",
      "Epoch 115: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.3505e-06 - val_accuracy: 0.9789 - val_loss: 0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp5/best_model_1.h5\n",
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:31:26.999076: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:31:27.000415: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0885e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9815 - loss: 0.0717\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9877 - loss: 0.0499\n",
      "Epoch 1/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.1719 - loss: 2.0568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:31:34.442518: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:31:34.442853: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67019, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.1762 - loss: 2.0509 - val_accuracy: 0.6702 - val_loss: 1.3473\n",
      "Epoch 2/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6321 - loss: 1.1751\n",
      "Epoch 2: val_accuracy improved from 0.67019 to 0.75053, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.6330 - loss: 1.1697 - val_accuracy: 0.7505 - val_loss: 0.6190\n",
      "Epoch 3/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7534 - loss: 0.6297\n",
      "Epoch 3: val_accuracy improved from 0.75053 to 0.78858, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.7536 - loss: 0.6297 - val_accuracy: 0.7886 - val_loss: 0.5209\n",
      "Epoch 4/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7550 - loss: 0.6212\n",
      "Epoch 4: val_accuracy improved from 0.78858 to 0.79070, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.7551 - loss: 0.6219 - val_accuracy: 0.7907 - val_loss: 0.4885\n",
      "Epoch 5/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8405 - loss: 0.4194\n",
      "Epoch 5: val_accuracy improved from 0.79070 to 0.83510, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8404 - loss: 0.4196 - val_accuracy: 0.8351 - val_loss: 0.4041\n",
      "Epoch 6/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8993 - loss: 0.2886\n",
      "Epoch 6: val_accuracy improved from 0.83510 to 0.85624, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8990 - loss: 0.2892 - val_accuracy: 0.8562 - val_loss: 0.3191\n",
      "Epoch 7/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9286 - loss: 0.2198\n",
      "Epoch 7: val_accuracy improved from 0.85624 to 0.87315, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9279 - loss: 0.2216 - val_accuracy: 0.8732 - val_loss: 0.3324\n",
      "Epoch 8/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9200 - loss: 0.2345\n",
      "Epoch 8: val_accuracy did not improve from 0.87315\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9198 - loss: 0.2349 - val_accuracy: 0.8668 - val_loss: 0.3514\n",
      "Epoch 9/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9371 - loss: 0.1847\n",
      "Epoch 9: val_accuracy improved from 0.87315 to 0.89852, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9368 - loss: 0.1851 - val_accuracy: 0.8985 - val_loss: 0.2653\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9453 - loss: 0.1563\n",
      "Epoch 10: val_accuracy did not improve from 0.89852\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9453 - loss: 0.1563 - val_accuracy: 0.8689 - val_loss: 0.2865\n",
      "Epoch 11/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9516 - loss: 0.1389\n",
      "Epoch 11: val_accuracy improved from 0.89852 to 0.91121, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9513 - loss: 0.1393 - val_accuracy: 0.9112 - val_loss: 0.2059\n",
      "Epoch 12/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9548 - loss: 0.1288\n",
      "Epoch 12: val_accuracy improved from 0.91121 to 0.94292, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9547 - loss: 0.1286 - val_accuracy: 0.9429 - val_loss: 0.1385\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9636 - loss: 0.0943\n",
      "Epoch 13: val_accuracy did not improve from 0.94292\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9635 - loss: 0.0945 - val_accuracy: 0.9091 - val_loss: 0.2238\n",
      "Epoch 14/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9587 - loss: 0.1031\n",
      "Epoch 14: val_accuracy did not improve from 0.94292\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9587 - loss: 0.1030 - val_accuracy: 0.9070 - val_loss: 0.2496\n",
      "Epoch 15/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9496 - loss: 0.1229\n",
      "Epoch 15: val_accuracy did not improve from 0.94292\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9497 - loss: 0.1227 - val_accuracy: 0.9239 - val_loss: 0.1906\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9697 - loss: 0.0828\n",
      "Epoch 16: val_accuracy improved from 0.94292 to 0.95983, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9696 - loss: 0.0828 - val_accuracy: 0.9598 - val_loss: 0.1096\n",
      "Epoch 17/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9784 - loss: 0.0560\n",
      "Epoch 17: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9784 - loss: 0.0561 - val_accuracy: 0.9598 - val_loss: 0.1097\n",
      "Epoch 18/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9801 - loss: 0.0511\n",
      "Epoch 18: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9800 - loss: 0.0512 - val_accuracy: 0.9471 - val_loss: 0.1192\n",
      "Epoch 19/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9826 - loss: 0.0433\n",
      "Epoch 19: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9826 - loss: 0.0436 - val_accuracy: 0.9429 - val_loss: 0.1792\n",
      "Epoch 20/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9529 - loss: 0.1195\n",
      "Epoch 20: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.9530 - loss: 0.1194 - val_accuracy: 0.9070 - val_loss: 0.2829\n",
      "Epoch 21/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9546 - loss: 0.1148\n",
      "Epoch 21: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9546 - loss: 0.1150 - val_accuracy: 0.8816 - val_loss: 0.3755\n",
      "Epoch 22/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9414 - loss: 0.1501\n",
      "Epoch 22: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9418 - loss: 0.1495 - val_accuracy: 0.9471 - val_loss: 0.1459\n",
      "Epoch 23/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9795 - loss: 0.0555\n",
      "Epoch 23: val_accuracy did not improve from 0.95983\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9793 - loss: 0.0559 - val_accuracy: 0.9535 - val_loss: 0.1371\n",
      "Epoch 24/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9840 - loss: 0.0462\n",
      "Epoch 24: val_accuracy improved from 0.95983 to 0.96829, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9840 - loss: 0.0460 - val_accuracy: 0.9683 - val_loss: 0.1020\n",
      "Epoch 25/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9912 - loss: 0.0266\n",
      "Epoch 25: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9911 - loss: 0.0268 - val_accuracy: 0.9662 - val_loss: 0.0975\n",
      "Epoch 26/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9944 - loss: 0.0197\n",
      "Epoch 26: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9943 - loss: 0.0200 - val_accuracy: 0.9493 - val_loss: 0.1548\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9888 - loss: 0.0281\n",
      "Epoch 27: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.9888 - loss: 0.0281 - val_accuracy: 0.9598 - val_loss: 0.1277\n",
      "Epoch 28/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9889 - loss: 0.0216\n",
      "Epoch 28: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9889 - loss: 0.0216 - val_accuracy: 0.9514 - val_loss: 0.1263\n",
      "Epoch 29/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9936 - loss: 0.0158\n",
      "Epoch 29: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9935 - loss: 0.0160 - val_accuracy: 0.9514 - val_loss: 0.1389\n",
      "Epoch 30/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9934 - loss: 0.0144\n",
      "Epoch 30: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9934 - loss: 0.0145 - val_accuracy: 0.9535 - val_loss: 0.1539\n",
      "Epoch 31/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9942 - loss: 0.0171\n",
      "Epoch 31: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9943 - loss: 0.0171 - val_accuracy: 0.9598 - val_loss: 0.1393\n",
      "Epoch 32/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9956 - loss: 0.0160\n",
      "Epoch 32: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9956 - loss: 0.0161 - val_accuracy: 0.9408 - val_loss: 0.2782\n",
      "Epoch 33/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9528 - loss: 0.1339\n",
      "Epoch 33: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9530 - loss: 0.1333 - val_accuracy: 0.9535 - val_loss: 0.1289\n",
      "Epoch 34/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9902 - loss: 0.0271\n",
      "Epoch 34: val_accuracy did not improve from 0.96829\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9900 - loss: 0.0273 - val_accuracy: 0.9493 - val_loss: 0.1595\n",
      "Epoch 35/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9765 - loss: 0.0528\n",
      "Epoch 35: val_accuracy improved from 0.96829 to 0.97040, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9768 - loss: 0.0523 - val_accuracy: 0.9704 - val_loss: 0.1040\n",
      "Epoch 36/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9843 - loss: 0.0840\n",
      "Epoch 36: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9821 - loss: 0.0948 - val_accuracy: 0.8943 - val_loss: 0.3304\n",
      "Epoch 37/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9379 - loss: 0.2273\n",
      "Epoch 37: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9388 - loss: 0.2245 - val_accuracy: 0.9387 - val_loss: 0.1541\n",
      "Epoch 38/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9771 - loss: 0.0602\n",
      "Epoch 38: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9771 - loss: 0.0602 - val_accuracy: 0.9641 - val_loss: 0.1135\n",
      "Epoch 39/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9965 - loss: 0.0238\n",
      "Epoch 39: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9965 - loss: 0.0238 - val_accuracy: 0.9662 - val_loss: 0.1000\n",
      "Epoch 40/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 40: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9662 - val_loss: 0.0844\n",
      "Epoch 41/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9935 - loss: 0.0225\n",
      "Epoch 41: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9934 - loss: 0.0228 - val_accuracy: 0.9598 - val_loss: 0.1258\n",
      "Epoch 42/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9907 - loss: 0.0304\n",
      "Epoch 42: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9909 - loss: 0.0301 - val_accuracy: 0.9641 - val_loss: 0.0948\n",
      "Epoch 43/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 43: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9662 - val_loss: 0.1007\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 44: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9662 - val_loss: 0.1053\n",
      "Epoch 45/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 45: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9683 - val_loss: 0.0993\n",
      "Epoch 46/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 46: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9662 - val_loss: 0.0998\n",
      "Epoch 47/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 47: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9619 - val_loss: 0.1253\n",
      "Epoch 48/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 48: val_accuracy did not improve from 0.97040\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9704 - val_loss: 0.1047\n",
      "Epoch 49/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.6102e-04\n",
      "Epoch 49: val_accuracy improved from 0.97040 to 0.97252, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.7957e-04 - val_accuracy: 0.9725 - val_loss: 0.1007\n",
      "Epoch 50/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9967 - loss: 0.0109\n",
      "Epoch 50: val_accuracy did not improve from 0.97252\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9619 - val_loss: 0.1621\n",
      "Epoch 51/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9855 - loss: 0.0379\n",
      "Epoch 51: val_accuracy did not improve from 0.97252\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9856 - loss: 0.0377 - val_accuracy: 0.9662 - val_loss: 0.1140\n",
      "Epoch 52/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 52: val_accuracy did not improve from 0.97252\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9683 - val_loss: 0.0716\n",
      "Epoch 53/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 53: val_accuracy improved from 0.97252 to 0.97674, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9767 - val_loss: 0.0701\n",
      "Epoch 54/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.5181e-04\n",
      "Epoch 54: val_accuracy did not improve from 0.97674\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.7116e-04 - val_accuracy: 0.9767 - val_loss: 0.0701\n",
      "Epoch 55/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 55: val_accuracy improved from 0.97674 to 0.98097, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9810 - val_loss: 0.0740\n",
      "Epoch 56/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2408e-04\n",
      "Epoch 56: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.2974e-04 - val_accuracy: 0.9789 - val_loss: 0.0669\n",
      "Epoch 57/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.7848e-04\n",
      "Epoch 57: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.7857e-04 - val_accuracy: 0.9810 - val_loss: 0.0821\n",
      "Epoch 58/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.2622e-04\n",
      "Epoch 58: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.2838e-04 - val_accuracy: 0.9810 - val_loss: 0.0868\n",
      "Epoch 59/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.6820e-04\n",
      "Epoch 59: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.6707e-04 - val_accuracy: 0.9810 - val_loss: 0.0732\n",
      "Epoch 60/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8896e-04\n",
      "Epoch 60: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.8949e-04 - val_accuracy: 0.9810 - val_loss: 0.0769\n",
      "Epoch 61/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9081e-04\n",
      "Epoch 61: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.9097e-04 - val_accuracy: 0.9810 - val_loss: 0.0775\n",
      "Epoch 62/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.6864e-04\n",
      "Epoch 62: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.6898e-04 - val_accuracy: 0.9810 - val_loss: 0.0781\n",
      "Epoch 63/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5324e-04\n",
      "Epoch 63: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5347e-04 - val_accuracy: 0.9810 - val_loss: 0.0787\n",
      "Epoch 64/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4012e-04\n",
      "Epoch 64: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.4023e-04 - val_accuracy: 0.9810 - val_loss: 0.0792\n",
      "Epoch 65/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.2636e-04\n",
      "Epoch 65: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2677e-04 - val_accuracy: 0.9810 - val_loss: 0.0796\n",
      "Epoch 66/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1681e-04\n",
      "Epoch 66: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1721e-04 - val_accuracy: 0.9810 - val_loss: 0.0799\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.0709e-04\n",
      "Epoch 67: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0722e-04 - val_accuracy: 0.9810 - val_loss: 0.0802\n",
      "Epoch 68/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.8815e-05\n",
      "Epoch 68: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.9082e-05 - val_accuracy: 0.9810 - val_loss: 0.0804\n",
      "Epoch 69/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.1555e-05\n",
      "Epoch 69: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.1686e-05 - val_accuracy: 0.9810 - val_loss: 0.0806\n",
      "Epoch 70/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.4780e-05\n",
      "Epoch 70: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.5037e-05 - val_accuracy: 0.9810 - val_loss: 0.0808\n",
      "Epoch 71/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.8779e-05\n",
      "Epoch 71: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.9035e-05 - val_accuracy: 0.9810 - val_loss: 0.0809\n",
      "Epoch 72/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.3044e-05\n",
      "Epoch 72: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.3290e-05 - val_accuracy: 0.9810 - val_loss: 0.0810\n",
      "Epoch 73/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.7633e-05\n",
      "Epoch 73: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.7866e-05 - val_accuracy: 0.9810 - val_loss: 0.0814\n",
      "Epoch 74/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3160e-05\n",
      "Epoch 74: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.3377e-05 - val_accuracy: 0.9810 - val_loss: 0.0823\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7230e-05\n",
      "Epoch 75: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.7330e-05 - val_accuracy: 0.9810 - val_loss: 0.0842\n",
      "Epoch 76/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2295e-05\n",
      "Epoch 76: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.2385e-05 - val_accuracy: 0.9810 - val_loss: 0.0807\n",
      "Epoch 77/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.5914e-05\n",
      "Epoch 77: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.6164e-05 - val_accuracy: 0.9810 - val_loss: 0.0824\n",
      "Epoch 78/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.2470e-05\n",
      "Epoch 78: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.2647e-05 - val_accuracy: 0.9810 - val_loss: 0.0862\n",
      "Epoch 79/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.9151e-05\n",
      "Epoch 79: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.9247e-05 - val_accuracy: 0.9810 - val_loss: 0.0861\n",
      "Epoch 80/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.4590e-05\n",
      "Epoch 80: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 3.4681e-05 - val_accuracy: 0.9810 - val_loss: 0.0869\n",
      "Epoch 81/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.0610e-05\n",
      "Epoch 81: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.0651e-05 - val_accuracy: 0.9810 - val_loss: 0.0879\n",
      "Epoch 82/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.7231e-05\n",
      "Epoch 82: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.7310e-05 - val_accuracy: 0.9810 - val_loss: 0.0885\n",
      "Epoch 83/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.4868e-05\n",
      "Epoch 83: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.4933e-05 - val_accuracy: 0.9810 - val_loss: 0.0900\n",
      "Epoch 84/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2721e-05\n",
      "Epoch 84: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2782e-05 - val_accuracy: 0.9810 - val_loss: 0.0910\n",
      "Epoch 85/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0815e-05\n",
      "Epoch 85: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.0869e-05 - val_accuracy: 0.9810 - val_loss: 0.0923\n",
      "Epoch 86/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.9093e-05\n",
      "Epoch 86: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.9142e-05 - val_accuracy: 0.9810 - val_loss: 0.0933\n",
      "Epoch 87/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.7645e-05\n",
      "Epoch 87: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7689e-05 - val_accuracy: 0.9810 - val_loss: 0.0943\n",
      "Epoch 88/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6427e-05\n",
      "Epoch 88: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.6467e-05 - val_accuracy: 0.9810 - val_loss: 0.0953\n",
      "Epoch 89/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5267e-05\n",
      "Epoch 89: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.5305e-05 - val_accuracy: 0.9810 - val_loss: 0.0960\n",
      "Epoch 90/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.4306e-05\n",
      "Epoch 90: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.4340e-05 - val_accuracy: 0.9810 - val_loss: 0.0967\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3402e-05\n",
      "Epoch 91: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.3417e-05 - val_accuracy: 0.9810 - val_loss: 0.0973\n",
      "Epoch 92/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2679e-05\n",
      "Epoch 92: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.2707e-05 - val_accuracy: 0.9810 - val_loss: 0.0979\n",
      "Epoch 93/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2024e-05\n",
      "Epoch 93: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.2037e-05 - val_accuracy: 0.9810 - val_loss: 0.0985\n",
      "Epoch 94/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1373e-05\n",
      "Epoch 94: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1385e-05 - val_accuracy: 0.9810 - val_loss: 0.0989\n",
      "Epoch 95/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0773e-05\n",
      "Epoch 95: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.0807e-05 - val_accuracy: 0.9810 - val_loss: 0.0994\n",
      "Epoch 96/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0269e-05\n",
      "Epoch 96: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0300e-05 - val_accuracy: 0.9810 - val_loss: 0.0999\n",
      "Epoch 97/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.7519e-06\n",
      "Epoch 97: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.7826e-06 - val_accuracy: 0.9810 - val_loss: 0.1004\n",
      "Epoch 98/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.3999e-06\n",
      "Epoch 98: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.4163e-06 - val_accuracy: 0.9810 - val_loss: 0.1005\n",
      "Epoch 99/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 8.8487e-06\n",
      "Epoch 99: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.8769e-06 - val_accuracy: 0.9810 - val_loss: 0.1011\n",
      "Epoch 100/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 8.5608e-06\n",
      "Epoch 100: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.5681e-06 - val_accuracy: 0.9810 - val_loss: 0.1013\n",
      "Epoch 101/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.0383e-06\n",
      "Epoch 101: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.0461e-06 - val_accuracy: 0.9810 - val_loss: 0.1016\n",
      "Epoch 102/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.6831e-06\n",
      "Epoch 102: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.6980e-06 - val_accuracy: 0.9810 - val_loss: 0.1019\n",
      "Epoch 103/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.3050e-06\n",
      "Epoch 103: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.3271e-06 - val_accuracy: 0.9810 - val_loss: 0.1022\n",
      "Epoch 104/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.9941e-06\n",
      "Epoch 104: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.0147e-06 - val_accuracy: 0.9810 - val_loss: 0.1026\n",
      "Epoch 105/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.6874e-06\n",
      "Epoch 105: val_accuracy did not improve from 0.98097\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.7074e-06 - val_accuracy: 0.9810 - val_loss: 0.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp5/best_model_2.h5\n",
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:36:53.263704: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:36:53.264057: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.3150e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9855 - loss: 0.0481\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9908 - loss: 0.0398\n",
      "Epoch 1/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1870 - loss: 2.0449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:37:00.199799: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:37:00.200164: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50106, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.1912 - loss: 2.0366 - val_accuracy: 0.5011 - val_loss: 1.4231\n",
      "Epoch 2/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5999 - loss: 1.1426\n",
      "Epoch 2: val_accuracy improved from 0.50106 to 0.81395, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6035 - loss: 1.1324 - val_accuracy: 0.8140 - val_loss: 0.4984\n",
      "Epoch 3/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8602 - loss: 0.3695\n",
      "Epoch 3: val_accuracy improved from 0.81395 to 0.86892, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8605 - loss: 0.3692 - val_accuracy: 0.8689 - val_loss: 0.4188\n",
      "Epoch 4/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8804 - loss: 0.3296\n",
      "Epoch 4: val_accuracy did not improve from 0.86892\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8802 - loss: 0.3300 - val_accuracy: 0.8266 - val_loss: 0.5324\n",
      "Epoch 5/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8879 - loss: 0.3188\n",
      "Epoch 5: val_accuracy did not improve from 0.86892\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8878 - loss: 0.3187 - val_accuracy: 0.8520 - val_loss: 0.4431\n",
      "Epoch 6/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9073 - loss: 0.2444\n",
      "Epoch 6: val_accuracy did not improve from 0.86892\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9072 - loss: 0.2446 - val_accuracy: 0.8689 - val_loss: 0.4323\n",
      "Epoch 7/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9264 - loss: 0.2071\n",
      "Epoch 7: val_accuracy improved from 0.86892 to 0.89641, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9263 - loss: 0.2077 - val_accuracy: 0.8964 - val_loss: 0.3030\n",
      "Epoch 8/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9224 - loss: 0.1836\n",
      "Epoch 8: val_accuracy improved from 0.89641 to 0.92389, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9225 - loss: 0.1840 - val_accuracy: 0.9239 - val_loss: 0.2696\n",
      "Epoch 9/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9422 - loss: 0.1482\n",
      "Epoch 9: val_accuracy did not improve from 0.92389\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9421 - loss: 0.1486 - val_accuracy: 0.8964 - val_loss: 0.3196\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9524 - loss: 0.1353\n",
      "Epoch 10: val_accuracy improved from 0.92389 to 0.93023, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9524 - loss: 0.1353 - val_accuracy: 0.9302 - val_loss: 0.2871\n",
      "Epoch 11/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9680 - loss: 0.0909\n",
      "Epoch 11: val_accuracy did not improve from 0.93023\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9679 - loss: 0.0911 - val_accuracy: 0.9133 - val_loss: 0.2544\n",
      "Epoch 12/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9686 - loss: 0.0873\n",
      "Epoch 12: val_accuracy did not improve from 0.93023\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9685 - loss: 0.0877 - val_accuracy: 0.9154 - val_loss: 0.2964\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9669 - loss: 0.1219\n",
      "Epoch 13: val_accuracy did not improve from 0.93023\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9669 - loss: 0.1216 - val_accuracy: 0.8837 - val_loss: 0.2960\n",
      "Epoch 14/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9447 - loss: 0.1595\n",
      "Epoch 14: val_accuracy did not improve from 0.93023\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9449 - loss: 0.1587 - val_accuracy: 0.8985 - val_loss: 0.2711\n",
      "Epoch 15/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9631 - loss: 0.0920\n",
      "Epoch 15: val_accuracy improved from 0.93023 to 0.93446, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9635 - loss: 0.0913 - val_accuracy: 0.9345 - val_loss: 0.1997\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9723 - loss: 0.0684\n",
      "Epoch 16: val_accuracy did not improve from 0.93446\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9725 - loss: 0.0682 - val_accuracy: 0.9260 - val_loss: 0.2229\n",
      "Epoch 17/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9687 - loss: 0.0717\n",
      "Epoch 17: val_accuracy did not improve from 0.93446\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9689 - loss: 0.0714 - val_accuracy: 0.9239 - val_loss: 0.2435\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9765 - loss: 0.0624\n",
      "Epoch 18: val_accuracy did not improve from 0.93446\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9767 - loss: 0.0621 - val_accuracy: 0.9323 - val_loss: 0.2499\n",
      "Epoch 19/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9768 - loss: 0.0551\n",
      "Epoch 19: val_accuracy did not improve from 0.93446\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9768 - loss: 0.0555 - val_accuracy: 0.9260 - val_loss: 0.2899\n",
      "Epoch 20/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9665 - loss: 0.1034\n",
      "Epoch 20: val_accuracy did not improve from 0.93446\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9665 - loss: 0.1037 - val_accuracy: 0.8985 - val_loss: 0.3736\n",
      "Epoch 21/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9743 - loss: 0.0831\n",
      "Epoch 21: val_accuracy did not improve from 0.93446\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9746 - loss: 0.0820 - val_accuracy: 0.9197 - val_loss: 0.2717\n",
      "Epoch 22/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9729 - loss: 0.0652\n",
      "Epoch 22: val_accuracy improved from 0.93446 to 0.94503, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9731 - loss: 0.0648 - val_accuracy: 0.9450 - val_loss: 0.1787\n",
      "Epoch 23/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9635 - loss: 0.0918\n",
      "Epoch 23: val_accuracy did not improve from 0.94503\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9636 - loss: 0.0918 - val_accuracy: 0.9260 - val_loss: 0.2249\n",
      "Epoch 24/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9667 - loss: 0.0695\n",
      "Epoch 24: val_accuracy improved from 0.94503 to 0.96195, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9667 - loss: 0.0697 - val_accuracy: 0.9619 - val_loss: 0.1443\n",
      "Epoch 25/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9865 - loss: 0.0455\n",
      "Epoch 25: val_accuracy improved from 0.96195 to 0.97674, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9866 - loss: 0.0451 - val_accuracy: 0.9767 - val_loss: 0.1259\n",
      "Epoch 26/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9990 - loss: 0.0102\n",
      "Epoch 26: val_accuracy improved from 0.97674 to 0.97886, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9990 - loss: 0.0102 - val_accuracy: 0.9789 - val_loss: 0.0858\n",
      "Epoch 27/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9989 - loss: 0.0054\n",
      "Epoch 27: val_accuracy did not improve from 0.97886\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 0.9789 - val_loss: 0.0972\n",
      "Epoch 28/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9995 - loss: 0.0036\n",
      "Epoch 28: val_accuracy improved from 0.97886 to 0.98097, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9810 - val_loss: 0.0747\n",
      "Epoch 29/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 29: val_accuracy improved from 0.98097 to 0.98309, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9831 - val_loss: 0.0756\n",
      "Epoch 30/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 30: val_accuracy improved from 0.98309 to 0.98520, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9852 - val_loss: 0.0767\n",
      "Epoch 31/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 31: val_accuracy did not improve from 0.98520\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9852 - val_loss: 0.0753\n",
      "Epoch 32/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.2328e-04\n",
      "Epoch 32: val_accuracy did not improve from 0.98520\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.2660e-04 - val_accuracy: 0.9852 - val_loss: 0.0779\n",
      "Epoch 33/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.5536e-04\n",
      "Epoch 33: val_accuracy did not improve from 0.98520\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.5730e-04 - val_accuracy: 0.9852 - val_loss: 0.0812\n",
      "Epoch 34/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.4786e-04\n",
      "Epoch 34: val_accuracy did not improve from 0.98520\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.4838e-04 - val_accuracy: 0.9852 - val_loss: 0.0828\n",
      "Epoch 35/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.4831e-04\n",
      "Epoch 35: val_accuracy did not improve from 0.98520\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.4921e-04 - val_accuracy: 0.9852 - val_loss: 0.0834\n",
      "Epoch 36/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.7428e-04\n",
      "Epoch 36: val_accuracy did not improve from 0.98520\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.7471e-04 - val_accuracy: 0.9852 - val_loss: 0.0844\n",
      "Epoch 37/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.1776e-04\n",
      "Epoch 37: val_accuracy improved from 0.98520 to 0.98731, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.1861e-04 - val_accuracy: 0.9873 - val_loss: 0.0852\n",
      "Epoch 38/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.7835e-04\n",
      "Epoch 38: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.7911e-04 - val_accuracy: 0.9873 - val_loss: 0.0859\n",
      "Epoch 39/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.4474e-04\n",
      "Epoch 39: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.4578e-04 - val_accuracy: 0.9852 - val_loss: 0.0863\n",
      "Epoch 40/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2075e-04\n",
      "Epoch 40: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.2165e-04 - val_accuracy: 0.9852 - val_loss: 0.0870\n",
      "Epoch 41/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9774e-04\n",
      "Epoch 41: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.9830e-04 - val_accuracy: 0.9852 - val_loss: 0.0875\n",
      "Epoch 42/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7790e-04\n",
      "Epoch 42: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.7871e-04 - val_accuracy: 0.9852 - val_loss: 0.0880\n",
      "Epoch 43/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6191e-04\n",
      "Epoch 43: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.6240e-04 - val_accuracy: 0.9852 - val_loss: 0.0885\n",
      "Epoch 44/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4722e-04\n",
      "Epoch 44: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.4793e-04 - val_accuracy: 0.9852 - val_loss: 0.0889\n",
      "Epoch 45/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3447e-04\n",
      "Epoch 45: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.3516e-04 - val_accuracy: 0.9852 - val_loss: 0.0892\n",
      "Epoch 46/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2395e-04\n",
      "Epoch 46: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.2416e-04 - val_accuracy: 0.9852 - val_loss: 0.0895\n",
      "Epoch 47/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1373e-04\n",
      "Epoch 47: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.1416e-04 - val_accuracy: 0.9852 - val_loss: 0.0898\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0523e-04\n",
      "Epoch 48: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.0544e-04 - val_accuracy: 0.9852 - val_loss: 0.0901\n",
      "Epoch 49/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.7113e-05\n",
      "Epoch 49: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.7521e-05 - val_accuracy: 0.9852 - val_loss: 0.0903\n",
      "Epoch 50/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0043e-05\n",
      "Epoch 50: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 9.0645e-05 - val_accuracy: 0.9852 - val_loss: 0.0906\n",
      "Epoch 51/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.3613e-05\n",
      "Epoch 51: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 8.4197e-05 - val_accuracy: 0.9852 - val_loss: 0.0908\n",
      "Epoch 52/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.7999e-05\n",
      "Epoch 52: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 7.8367e-05 - val_accuracy: 0.9852 - val_loss: 0.0911\n",
      "Epoch 53/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.2559e-05\n",
      "Epoch 53: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.3108e-05 - val_accuracy: 0.9852 - val_loss: 0.0913\n",
      "Epoch 54/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.7778e-05\n",
      "Epoch 54: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.8311e-05 - val_accuracy: 0.9852 - val_loss: 0.0915\n",
      "Epoch 55/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3806e-05\n",
      "Epoch 55: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.3972e-05 - val_accuracy: 0.9852 - val_loss: 0.0917\n",
      "Epoch 56/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.9570e-05\n",
      "Epoch 56: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.9897e-05 - val_accuracy: 0.9852 - val_loss: 0.0920\n",
      "Epoch 57/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.5915e-05\n",
      "Epoch 57: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.6231e-05 - val_accuracy: 0.9852 - val_loss: 0.0923\n",
      "Epoch 58/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2283e-05\n",
      "Epoch 58: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.2746e-05 - val_accuracy: 0.9852 - val_loss: 0.0926\n",
      "Epoch 59/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.9198e-05\n",
      "Epoch 59: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.9644e-05 - val_accuracy: 0.9852 - val_loss: 0.0928\n",
      "Epoch 60/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.6352e-05\n",
      "Epoch 60: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.6780e-05 - val_accuracy: 0.9852 - val_loss: 0.0931\n",
      "Epoch 61/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.3817e-05\n",
      "Epoch 61: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.4086e-05 - val_accuracy: 0.9852 - val_loss: 0.0933\n",
      "Epoch 62/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.1453e-05\n",
      "Epoch 62: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 4.1580e-05 - val_accuracy: 0.9852 - val_loss: 0.0936\n",
      "Epoch 63/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.8948e-05\n",
      "Epoch 63: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.9195e-05 - val_accuracy: 0.9852 - val_loss: 0.0939\n",
      "Epoch 64/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.6753e-05\n",
      "Epoch 64: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.6991e-05 - val_accuracy: 0.9852 - val_loss: 0.0941\n",
      "Epoch 65/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.4687e-05\n",
      "Epoch 65: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.4916e-05 - val_accuracy: 0.9852 - val_loss: 0.0942\n",
      "Epoch 66/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.2898e-05\n",
      "Epoch 66: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.3116e-05 - val_accuracy: 0.9852 - val_loss: 0.0946\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.1234e-05\n",
      "Epoch 67: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.1337e-05 - val_accuracy: 0.9852 - val_loss: 0.0948\n",
      "Epoch 68/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.9601e-05\n",
      "Epoch 68: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.9700e-05 - val_accuracy: 0.9852 - val_loss: 0.0950\n",
      "Epoch 69/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.8002e-05\n",
      "Epoch 69: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.8193e-05 - val_accuracy: 0.9852 - val_loss: 0.0952\n",
      "Epoch 70/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6551e-05\n",
      "Epoch 70: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.6831e-05 - val_accuracy: 0.9852 - val_loss: 0.0955\n",
      "Epoch 71/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.5220e-05\n",
      "Epoch 71: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.5394e-05 - val_accuracy: 0.9852 - val_loss: 0.0957\n",
      "Epoch 72/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.4072e-05\n",
      "Epoch 72: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.4154e-05 - val_accuracy: 0.9852 - val_loss: 0.0959\n",
      "Epoch 73/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.2813e-05\n",
      "Epoch 73: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2972e-05 - val_accuracy: 0.9852 - val_loss: 0.0960\n",
      "Epoch 74/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.1765e-05\n",
      "Epoch 74: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.1916e-05 - val_accuracy: 0.9852 - val_loss: 0.0963\n",
      "Epoch 75/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.0656e-05\n",
      "Epoch 75: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.0801e-05 - val_accuracy: 0.9852 - val_loss: 0.0965\n",
      "Epoch 76/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.9688e-05\n",
      "Epoch 76: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.9826e-05 - val_accuracy: 0.9852 - val_loss: 0.0966\n",
      "Epoch 77/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8902e-05\n",
      "Epoch 77: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.8967e-05 - val_accuracy: 0.9852 - val_loss: 0.0969\n",
      "Epoch 78/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7885e-05\n",
      "Epoch 78: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.8009e-05 - val_accuracy: 0.9852 - val_loss: 0.0970\n",
      "Epoch 79/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.7086e-05\n",
      "Epoch 79: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7204e-05 - val_accuracy: 0.9852 - val_loss: 0.0970\n",
      "Epoch 80/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.6344e-05\n",
      "Epoch 80: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.6457e-05 - val_accuracy: 0.9852 - val_loss: 0.0972\n",
      "Epoch 81/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5595e-05\n",
      "Epoch 81: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.5702e-05 - val_accuracy: 0.9831 - val_loss: 0.0973\n",
      "Epoch 82/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4970e-05\n",
      "Epoch 82: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5021e-05 - val_accuracy: 0.9831 - val_loss: 0.0974\n",
      "Epoch 83/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.4247e-05\n",
      "Epoch 83: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4346e-05 - val_accuracy: 0.9831 - val_loss: 0.0976\n",
      "Epoch 84/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3634e-05\n",
      "Epoch 84: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.3680e-05 - val_accuracy: 0.9831 - val_loss: 0.0975\n",
      "Epoch 85/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.3112e-05\n",
      "Epoch 85: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3156e-05 - val_accuracy: 0.9831 - val_loss: 0.0978\n",
      "Epoch 86/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.2468e-05\n",
      "Epoch 86: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2554e-05 - val_accuracy: 0.9831 - val_loss: 0.0979\n",
      "Epoch 87/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2025e-05\n",
      "Epoch 87: val_accuracy did not improve from 0.98731\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.2066e-05 - val_accuracy: 0.9831 - val_loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp5/best_model_3.h5\n",
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:41:17.163869: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:41:17.164228: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.4972e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9880 - loss: 0.0618\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9949 - loss: 0.0197\n",
      "Epoch 1/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1937 - loss: 1.9773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:41:23.592608: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:41:23.592966: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54025, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.1957 - loss: 1.9731 - val_accuracy: 0.5403 - val_loss: 1.1183\n",
      "Epoch 2/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6264 - loss: 0.9812\n",
      "Epoch 2: val_accuracy improved from 0.54025 to 0.71610, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6281 - loss: 0.9771 - val_accuracy: 0.7161 - val_loss: 0.6318\n",
      "Epoch 3/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7826 - loss: 0.5850\n",
      "Epoch 3: val_accuracy improved from 0.71610 to 0.81780, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.7835 - loss: 0.5833 - val_accuracy: 0.8178 - val_loss: 0.4339\n",
      "Epoch 4/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8553 - loss: 0.3958\n",
      "Epoch 4: val_accuracy improved from 0.81780 to 0.83263, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8554 - loss: 0.3954 - val_accuracy: 0.8326 - val_loss: 0.4524\n",
      "Epoch 5/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8616 - loss: 0.3731\n",
      "Epoch 5: val_accuracy improved from 0.83263 to 0.86017, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8617 - loss: 0.3725 - val_accuracy: 0.8602 - val_loss: 0.3307\n",
      "Epoch 6/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8896 - loss: 0.2791\n",
      "Epoch 6: val_accuracy improved from 0.86017 to 0.87924, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8897 - loss: 0.2800 - val_accuracy: 0.8792 - val_loss: 0.3541\n",
      "Epoch 7/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9059 - loss: 0.2961\n",
      "Epoch 7: val_accuracy improved from 0.87924 to 0.90678, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9061 - loss: 0.2947 - val_accuracy: 0.9068 - val_loss: 0.2515\n",
      "Epoch 8/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9232 - loss: 0.1959\n",
      "Epoch 8: val_accuracy improved from 0.90678 to 0.92373, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.9234 - loss: 0.1956 - val_accuracy: 0.9237 - val_loss: 0.2296\n",
      "Epoch 9/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9438 - loss: 0.1426\n",
      "Epoch 9: val_accuracy improved from 0.92373 to 0.94280, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.9438 - loss: 0.1427 - val_accuracy: 0.9428 - val_loss: 0.1840\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9625 - loss: 0.1017\n",
      "Epoch 10: val_accuracy did not improve from 0.94280\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9624 - loss: 0.1018 - val_accuracy: 0.8962 - val_loss: 0.2647\n",
      "Epoch 11/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9369 - loss: 0.1632\n",
      "Epoch 11: val_accuracy improved from 0.94280 to 0.94492, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9369 - loss: 0.1631 - val_accuracy: 0.9449 - val_loss: 0.1481\n",
      "Epoch 12/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9709 - loss: 0.0846\n",
      "Epoch 12: val_accuracy improved from 0.94492 to 0.96186, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9709 - loss: 0.0845 - val_accuracy: 0.9619 - val_loss: 0.1129\n",
      "Epoch 13/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9794 - loss: 0.0624\n",
      "Epoch 13: val_accuracy improved from 0.96186 to 0.97881, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9793 - loss: 0.0623 - val_accuracy: 0.9788 - val_loss: 0.0525\n",
      "Epoch 14/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9886 - loss: 0.0350\n",
      "Epoch 14: val_accuracy did not improve from 0.97881\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.9886 - loss: 0.0350 - val_accuracy: 0.9725 - val_loss: 0.0750\n",
      "Epoch 15/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9899 - loss: 0.0321\n",
      "Epoch 15: val_accuracy did not improve from 0.97881\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9897 - loss: 0.0326 - val_accuracy: 0.9492 - val_loss: 0.1751\n",
      "Epoch 16/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9781 - loss: 0.0615\n",
      "Epoch 16: val_accuracy did not improve from 0.97881\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9782 - loss: 0.0612 - val_accuracy: 0.9725 - val_loss: 0.0851\n",
      "Epoch 17/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9880 - loss: 0.0310\n",
      "Epoch 17: val_accuracy improved from 0.97881 to 0.98305, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.9877 - loss: 0.0317 - val_accuracy: 0.9831 - val_loss: 0.0584\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9895 - loss: 0.0342\n",
      "Epoch 18: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9894 - loss: 0.0344 - val_accuracy: 0.8898 - val_loss: 0.2998\n",
      "Epoch 19/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9737 - loss: 0.0693\n",
      "Epoch 19: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9739 - loss: 0.0689 - val_accuracy: 0.9809 - val_loss: 0.0879\n",
      "Epoch 20/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9853 - loss: 0.0394\n",
      "Epoch 20: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9855 - loss: 0.0392 - val_accuracy: 0.9809 - val_loss: 0.0477\n",
      "Epoch 21/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9886 - loss: 0.0320\n",
      "Epoch 21: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9887 - loss: 0.0320 - val_accuracy: 0.9831 - val_loss: 0.0429\n",
      "Epoch 22/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9919 - loss: 0.0302\n",
      "Epoch 22: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9919 - loss: 0.0303 - val_accuracy: 0.9809 - val_loss: 0.0546\n",
      "Epoch 23/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9902 - loss: 0.0274\n",
      "Epoch 23: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9901 - loss: 0.0277 - val_accuracy: 0.9831 - val_loss: 0.0790\n",
      "Epoch 24/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9845 - loss: 0.0409\n",
      "Epoch 24: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9841 - loss: 0.0420 - val_accuracy: 0.9682 - val_loss: 0.0985\n",
      "Epoch 25/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9733 - loss: 0.0802\n",
      "Epoch 25: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9729 - loss: 0.0815 - val_accuracy: 0.9534 - val_loss: 0.1588\n",
      "Epoch 26/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9690 - loss: 0.1210\n",
      "Epoch 26: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9695 - loss: 0.1190 - val_accuracy: 0.9534 - val_loss: 0.0947\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9685 - loss: 0.0779\n",
      "Epoch 27: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9685 - loss: 0.0778 - val_accuracy: 0.9555 - val_loss: 0.0863\n",
      "Epoch 28/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9563 - loss: 0.1223\n",
      "Epoch 28: val_accuracy did not improve from 0.98305\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9567 - loss: 0.1213 - val_accuracy: 0.9809 - val_loss: 0.0854\n",
      "Epoch 29/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9969 - loss: 0.0193\n",
      "Epoch 29: val_accuracy improved from 0.98305 to 0.98941, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9969 - loss: 0.0192 - val_accuracy: 0.9894 - val_loss: 0.0240\n",
      "Epoch 30/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9973 - loss: 0.0086\n",
      "Epoch 30: val_accuracy did not improve from 0.98941\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9973 - loss: 0.0088 - val_accuracy: 0.9852 - val_loss: 0.0799\n",
      "Epoch 31/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9763 - loss: 0.0504\n",
      "Epoch 31: val_accuracy improved from 0.98941 to 0.99153, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9764 - loss: 0.0503 - val_accuracy: 0.9915 - val_loss: 0.0292\n",
      "Epoch 32/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9907 - loss: 0.0244\n",
      "Epoch 32: val_accuracy did not improve from 0.99153\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9906 - loss: 0.0248 - val_accuracy: 0.9746 - val_loss: 0.0941\n",
      "Epoch 33/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9932 - loss: 0.0215\n",
      "Epoch 33: val_accuracy did not improve from 0.99153\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9931 - loss: 0.0215 - val_accuracy: 0.9852 - val_loss: 0.0378\n",
      "Epoch 34/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9996 - loss: 0.0051\n",
      "Epoch 34: val_accuracy did not improve from 0.99153\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 0.9915 - val_loss: 0.0274\n",
      "Epoch 35/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 35: val_accuracy improved from 0.99153 to 0.99364, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9936 - val_loss: 0.0229\n",
      "Epoch 36/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.0972e-04\n",
      "Epoch 36: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.0726e-04 - val_accuracy: 0.9936 - val_loss: 0.0233\n",
      "Epoch 37/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.5393e-04\n",
      "Epoch 37: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.5183e-04 - val_accuracy: 0.9936 - val_loss: 0.0232\n",
      "Epoch 38/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.9197e-04\n",
      "Epoch 38: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 4.9163e-04 - val_accuracy: 0.9936 - val_loss: 0.0241\n",
      "Epoch 39/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.0534e-04\n",
      "Epoch 39: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0584e-04 - val_accuracy: 0.9936 - val_loss: 0.0248\n",
      "Epoch 40/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4667e-04\n",
      "Epoch 40: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.4750e-04 - val_accuracy: 0.9936 - val_loss: 0.0256\n",
      "Epoch 41/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.9770e-04\n",
      "Epoch 41: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.9882e-04 - val_accuracy: 0.9936 - val_loss: 0.0265\n",
      "Epoch 42/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.6038e-04\n",
      "Epoch 42: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.6104e-04 - val_accuracy: 0.9936 - val_loss: 0.0274\n",
      "Epoch 43/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2843e-04\n",
      "Epoch 43: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.2985e-04 - val_accuracy: 0.9936 - val_loss: 0.0282\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.0330e-04\n",
      "Epoch 44: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.0400e-04 - val_accuracy: 0.9936 - val_loss: 0.0291\n",
      "Epoch 45/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.7934e-04\n",
      "Epoch 45: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.8076e-04 - val_accuracy: 0.9936 - val_loss: 0.0301\n",
      "Epoch 46/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.6047e-04\n",
      "Epoch 46: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.6114e-04 - val_accuracy: 0.9936 - val_loss: 0.0309\n",
      "Epoch 47/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.4141e-04\n",
      "Epoch 47: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.4265e-04 - val_accuracy: 0.9936 - val_loss: 0.0319\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.2532e-04\n",
      "Epoch 48: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2585e-04 - val_accuracy: 0.9936 - val_loss: 0.0328\n",
      "Epoch 49/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.1066e-04\n",
      "Epoch 49: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1155e-04 - val_accuracy: 0.9936 - val_loss: 0.0337\n",
      "Epoch 50/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.8545e-05\n",
      "Epoch 50: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.9240e-05 - val_accuracy: 0.9936 - val_loss: 0.0343\n",
      "Epoch 51/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 8.8678e-05\n",
      "Epoch 51: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.9210e-05 - val_accuracy: 0.9936 - val_loss: 0.0346\n",
      "Epoch 52/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 8.0796e-05\n",
      "Epoch 52: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.1415e-05 - val_accuracy: 0.9936 - val_loss: 0.0346\n",
      "Epoch 53/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 7.4136e-05\n",
      "Epoch 53: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.4466e-05 - val_accuracy: 0.9936 - val_loss: 0.0349\n",
      "Epoch 54/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.8189e-05\n",
      "Epoch 54: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 6.8468e-05 - val_accuracy: 0.9936 - val_loss: 0.0351\n",
      "Epoch 55/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.3042e-05\n",
      "Epoch 55: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.3283e-05 - val_accuracy: 0.9936 - val_loss: 0.0353\n",
      "Epoch 56/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.8118e-05\n",
      "Epoch 56: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.8328e-05 - val_accuracy: 0.9936 - val_loss: 0.0353\n",
      "Epoch 57/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.3889e-05\n",
      "Epoch 57: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.4078e-05 - val_accuracy: 0.9936 - val_loss: 0.0356\n",
      "Epoch 58/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.0069e-05\n",
      "Epoch 58: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.0231e-05 - val_accuracy: 0.9936 - val_loss: 0.0357\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.6663e-05\n",
      "Epoch 59: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.6732e-05 - val_accuracy: 0.9936 - val_loss: 0.0359\n",
      "Epoch 60/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.3071e-05\n",
      "Epoch 60: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.3134e-05 - val_accuracy: 0.9936 - val_loss: 0.0361\n",
      "Epoch 61/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.9926e-05\n",
      "Epoch 61: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.9981e-05 - val_accuracy: 0.9936 - val_loss: 0.0361\n",
      "Epoch 62/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.6807e-05\n",
      "Epoch 62: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.6859e-05 - val_accuracy: 0.9936 - val_loss: 0.0362\n",
      "Epoch 63/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4052e-05\n",
      "Epoch 63: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.4100e-05 - val_accuracy: 0.9936 - val_loss: 0.0361\n",
      "Epoch 64/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 3.1538e-05\n",
      "Epoch 64: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 3.1636e-05 - val_accuracy: 0.9936 - val_loss: 0.0366\n",
      "Epoch 65/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.9252e-05\n",
      "Epoch 65: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.9297e-05 - val_accuracy: 0.9936 - val_loss: 0.0369\n",
      "Epoch 66/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.7157e-05\n",
      "Epoch 66: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.7201e-05 - val_accuracy: 0.9936 - val_loss: 0.0373\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.5230e-05\n",
      "Epoch 67: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.5272e-05 - val_accuracy: 0.9936 - val_loss: 0.0378\n",
      "Epoch 68/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.3362e-05\n",
      "Epoch 68: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.3478e-05 - val_accuracy: 0.9936 - val_loss: 0.0381\n",
      "Epoch 69/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1654e-05\n",
      "Epoch 69: val_accuracy improved from 0.99364 to 0.99576, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.1726e-05 - val_accuracy: 0.9958 - val_loss: 0.0382\n",
      "Epoch 70/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.0071e-05\n",
      "Epoch 70: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.0138e-05 - val_accuracy: 0.9958 - val_loss: 0.0386\n",
      "Epoch 71/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.8667e-05\n",
      "Epoch 71: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.8697e-05 - val_accuracy: 0.9958 - val_loss: 0.0389\n",
      "Epoch 72/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.7336e-05\n",
      "Epoch 72: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.7388e-05 - val_accuracy: 0.9958 - val_loss: 0.0390\n",
      "Epoch 73/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5983e-05\n",
      "Epoch 73: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.6029e-05 - val_accuracy: 0.9958 - val_loss: 0.0390\n",
      "Epoch 74/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.4796e-05\n",
      "Epoch 74: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4838e-05 - val_accuracy: 0.9958 - val_loss: 0.0392\n",
      "Epoch 75/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.3678e-05\n",
      "Epoch 75: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3716e-05 - val_accuracy: 0.9958 - val_loss: 0.0394\n",
      "Epoch 76/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.2717e-05\n",
      "Epoch 76: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.2751e-05 - val_accuracy: 0.9958 - val_loss: 0.0396\n",
      "Epoch 77/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1901e-05\n",
      "Epoch 77: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.1930e-05 - val_accuracy: 0.9958 - val_loss: 0.0396\n",
      "Epoch 78/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.1040e-05\n",
      "Epoch 78: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.1066e-05 - val_accuracy: 0.9958 - val_loss: 0.0397\n",
      "Epoch 79/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0262e-05\n",
      "Epoch 79: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.0285e-05 - val_accuracy: 0.9958 - val_loss: 0.0399\n",
      "Epoch 80/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.5532e-06\n",
      "Epoch 80: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.5636e-06 - val_accuracy: 0.9936 - val_loss: 0.0399\n",
      "Epoch 81/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.8945e-06\n",
      "Epoch 81: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.9131e-06 - val_accuracy: 0.9936 - val_loss: 0.0400\n",
      "Epoch 82/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.2754e-06\n",
      "Epoch 82: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.2836e-06 - val_accuracy: 0.9936 - val_loss: 0.0403\n",
      "Epoch 83/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.7173e-06\n",
      "Epoch 83: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.7249e-06 - val_accuracy: 0.9936 - val_loss: 0.0404\n",
      "Epoch 84/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.1628e-06\n",
      "Epoch 84: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.1773e-06 - val_accuracy: 0.9936 - val_loss: 0.0406\n",
      "Epoch 85/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 6.7218e-06\n",
      "Epoch 85: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 6.7348e-06 - val_accuracy: 0.9936 - val_loss: 0.0408\n",
      "Epoch 86/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.3349e-06\n",
      "Epoch 86: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.3464e-06 - val_accuracy: 0.9936 - val_loss: 0.0410\n",
      "Epoch 87/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.9597e-06\n",
      "Epoch 87: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.9700e-06 - val_accuracy: 0.9936 - val_loss: 0.0412\n",
      "Epoch 88/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.6208e-06\n",
      "Epoch 88: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.6299e-06 - val_accuracy: 0.9936 - val_loss: 0.0413\n",
      "Epoch 89/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.3042e-06\n",
      "Epoch 89: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 5.3082e-06 - val_accuracy: 0.9936 - val_loss: 0.0414\n",
      "Epoch 90/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.0252e-06\n",
      "Epoch 90: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.0288e-06 - val_accuracy: 0.9936 - val_loss: 0.0417\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.7441e-06\n",
      "Epoch 91: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.7474e-06 - val_accuracy: 0.9936 - val_loss: 0.0419\n",
      "Epoch 92/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.5135e-06\n",
      "Epoch 92: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.5197e-06 - val_accuracy: 0.9936 - val_loss: 0.0422\n",
      "Epoch 93/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.2874e-06\n",
      "Epoch 93: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.2903e-06 - val_accuracy: 0.9936 - val_loss: 0.0424\n",
      "Epoch 94/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.0678e-06\n",
      "Epoch 94: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 4.0705e-06 - val_accuracy: 0.9936 - val_loss: 0.0426\n",
      "Epoch 95/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.8665e-06\n",
      "Epoch 95: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.8689e-06 - val_accuracy: 0.9936 - val_loss: 0.0429\n",
      "Epoch 96/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.6772e-06\n",
      "Epoch 96: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.6816e-06 - val_accuracy: 0.9936 - val_loss: 0.0431\n",
      "Epoch 97/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4982e-06\n",
      "Epoch 97: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.5023e-06 - val_accuracy: 0.9936 - val_loss: 0.0433\n",
      "Epoch 98/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.3294e-06\n",
      "Epoch 98: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 3.3332e-06 - val_accuracy: 0.9936 - val_loss: 0.0435\n",
      "Epoch 99/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.1646e-06\n",
      "Epoch 99: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.1663e-06 - val_accuracy: 0.9936 - val_loss: 0.0437\n",
      "Epoch 100/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.0154e-06\n",
      "Epoch 100: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 3.0188e-06 - val_accuracy: 0.9936 - val_loss: 0.0440\n",
      "Epoch 101/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.8690e-06\n",
      "Epoch 101: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.8721e-06 - val_accuracy: 0.9936 - val_loss: 0.0442\n",
      "Epoch 102/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.7315e-06\n",
      "Epoch 102: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.7345e-06 - val_accuracy: 0.9936 - val_loss: 0.0444\n",
      "Epoch 103/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.6049e-06\n",
      "Epoch 103: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.6078e-06 - val_accuracy: 0.9936 - val_loss: 0.0446\n",
      "Epoch 104/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.4830e-06\n",
      "Epoch 104: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.4857e-06 - val_accuracy: 0.9936 - val_loss: 0.0449\n",
      "Epoch 105/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.3656e-06\n",
      "Epoch 105: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.3669e-06 - val_accuracy: 0.9936 - val_loss: 0.0451\n",
      "Epoch 106/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2580e-06\n",
      "Epoch 106: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.2606e-06 - val_accuracy: 0.9936 - val_loss: 0.0453\n",
      "Epoch 107/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1548e-06\n",
      "Epoch 107: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.1573e-06 - val_accuracy: 0.9936 - val_loss: 0.0456\n",
      "Epoch 108/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0595e-06\n",
      "Epoch 108: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.0620e-06 - val_accuracy: 0.9936 - val_loss: 0.0459\n",
      "Epoch 109/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.9608e-06\n",
      "Epoch 109: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.9632e-06 - val_accuracy: 0.9936 - val_loss: 0.0461\n",
      "Epoch 110/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.8762e-06\n",
      "Epoch 110: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.8773e-06 - val_accuracy: 0.9936 - val_loss: 0.0464\n",
      "Epoch 111/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.7937e-06\n",
      "Epoch 111: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.7960e-06 - val_accuracy: 0.9936 - val_loss: 0.0468\n",
      "Epoch 112/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.7097e-06\n",
      "Epoch 112: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.7131e-06 - val_accuracy: 0.9936 - val_loss: 0.0471\n",
      "Epoch 113/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6363e-06\n",
      "Epoch 113: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.6385e-06 - val_accuracy: 0.9936 - val_loss: 0.0475\n",
      "Epoch 114/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5627e-06\n",
      "Epoch 114: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.5648e-06 - val_accuracy: 0.9936 - val_loss: 0.0479\n",
      "Epoch 115/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.4947e-06\n",
      "Epoch 115: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.4957e-06 - val_accuracy: 0.9936 - val_loss: 0.0484\n",
      "Epoch 116/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.4287e-06\n",
      "Epoch 116: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.4296e-06 - val_accuracy: 0.9936 - val_loss: 0.0488\n",
      "Epoch 117/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.3686e-06\n",
      "Epoch 117: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.3706e-06 - val_accuracy: 0.9936 - val_loss: 0.0493\n",
      "Epoch 118/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.3090e-06\n",
      "Epoch 118: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.3110e-06 - val_accuracy: 0.9936 - val_loss: 0.0496\n",
      "Epoch 119/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.2503e-06\n",
      "Epoch 119: val_accuracy did not improve from 0.99576\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.2513e-06 - val_accuracy: 0.9936 - val_loss: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp5/best_model_4.h5\n",
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:47:46.953961: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:47:46.955557: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.6266e-05\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9912 - loss: 0.0656\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9925 - loss: 0.0236\n",
      "Epoch 1/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1972 - loss: 1.9979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:47:53.464576: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-10 08:47:53.464906: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55932, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.1991 - loss: 1.9941 - val_accuracy: 0.5593 - val_loss: 1.1056\n",
      "Epoch 2/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6512 - loss: 0.9930\n",
      "Epoch 2: val_accuracy improved from 0.55932 to 0.76695, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6521 - loss: 0.9901 - val_accuracy: 0.7669 - val_loss: 0.5543\n",
      "Epoch 3/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7874 - loss: 0.5616\n",
      "Epoch 3: val_accuracy improved from 0.76695 to 0.81992, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7884 - loss: 0.5593 - val_accuracy: 0.8199 - val_loss: 0.4897\n",
      "Epoch 4/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8698 - loss: 0.3564\n",
      "Epoch 4: val_accuracy improved from 0.81992 to 0.87924, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8700 - loss: 0.3560 - val_accuracy: 0.8792 - val_loss: 0.3868\n",
      "Epoch 5/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8245 - loss: 0.4473\n",
      "Epoch 5: val_accuracy improved from 0.87924 to 0.91314, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8251 - loss: 0.4460 - val_accuracy: 0.9131 - val_loss: 0.2585\n",
      "Epoch 6/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9089 - loss: 0.2459\n",
      "Epoch 6: val_accuracy did not improve from 0.91314\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9090 - loss: 0.2458 - val_accuracy: 0.8411 - val_loss: 0.4102\n",
      "Epoch 7/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9259 - loss: 0.2372\n",
      "Epoch 7: val_accuracy did not improve from 0.91314\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9260 - loss: 0.2368 - val_accuracy: 0.8835 - val_loss: 0.3076\n",
      "Epoch 8/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9177 - loss: 0.2235\n",
      "Epoch 8: val_accuracy improved from 0.91314 to 0.91949, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9179 - loss: 0.2231 - val_accuracy: 0.9195 - val_loss: 0.3000\n",
      "Epoch 9/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9410 - loss: 0.1836\n",
      "Epoch 9: val_accuracy improved from 0.91949 to 0.94068, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9411 - loss: 0.1831 - val_accuracy: 0.9407 - val_loss: 0.1962\n",
      "Epoch 10/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9519 - loss: 0.1262\n",
      "Epoch 10: val_accuracy improved from 0.94068 to 0.96610, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9522 - loss: 0.1254 - val_accuracy: 0.9661 - val_loss: 0.1335\n",
      "Epoch 11/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9748 - loss: 0.0760\n",
      "Epoch 11: val_accuracy did not improve from 0.96610\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9746 - loss: 0.0761 - val_accuracy: 0.9576 - val_loss: 0.1317\n",
      "Epoch 12/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9792 - loss: 0.0645\n",
      "Epoch 12: val_accuracy did not improve from 0.96610\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9788 - loss: 0.0654 - val_accuracy: 0.9534 - val_loss: 0.1604\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9784 - loss: 0.0646\n",
      "Epoch 13: val_accuracy did not improve from 0.96610\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9783 - loss: 0.0650 - val_accuracy: 0.8242 - val_loss: 0.5934\n",
      "Epoch 14/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9520 - loss: 0.1178\n",
      "Epoch 14: val_accuracy improved from 0.96610 to 0.97458, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9523 - loss: 0.1173 - val_accuracy: 0.9746 - val_loss: 0.0760\n",
      "Epoch 15/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9597 - loss: 0.0922\n",
      "Epoch 15: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9599 - loss: 0.0925 - val_accuracy: 0.9534 - val_loss: 0.1862\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9557 - loss: 0.1226\n",
      "Epoch 16: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9559 - loss: 0.1221 - val_accuracy: 0.9640 - val_loss: 0.1315\n",
      "Epoch 17/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9703 - loss: 0.0853\n",
      "Epoch 17: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9703 - loss: 0.0849 - val_accuracy: 0.9746 - val_loss: 0.1036\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9873 - loss: 0.0410\n",
      "Epoch 18: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9873 - loss: 0.0409 - val_accuracy: 0.9534 - val_loss: 0.1419\n",
      "Epoch 19/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9784 - loss: 0.0466\n",
      "Epoch 19: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9786 - loss: 0.0464 - val_accuracy: 0.9576 - val_loss: 0.1668\n",
      "Epoch 20/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9850 - loss: 0.0393\n",
      "Epoch 20: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9851 - loss: 0.0393 - val_accuracy: 0.9492 - val_loss: 0.1859\n",
      "Epoch 21/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9832 - loss: 0.0422\n",
      "Epoch 21: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9832 - loss: 0.0421 - val_accuracy: 0.9492 - val_loss: 0.2057\n",
      "Epoch 22/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9700 - loss: 0.0780\n",
      "Epoch 22: val_accuracy did not improve from 0.97458\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9701 - loss: 0.0784 - val_accuracy: 0.9640 - val_loss: 0.1112\n",
      "Epoch 23/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9852 - loss: 0.0424\n",
      "Epoch 23: val_accuracy improved from 0.97458 to 0.98517, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9852 - loss: 0.0424 - val_accuracy: 0.9852 - val_loss: 0.0534\n",
      "Epoch 24/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9896 - loss: 0.0244\n",
      "Epoch 24: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9896 - loss: 0.0244 - val_accuracy: 0.9831 - val_loss: 0.0768\n",
      "Epoch 25/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9948 - loss: 0.0167\n",
      "Epoch 25: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9949 - loss: 0.0166 - val_accuracy: 0.9831 - val_loss: 0.0693\n",
      "Epoch 26/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9913 - loss: 0.0236\n",
      "Epoch 26: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9913 - loss: 0.0235 - val_accuracy: 0.9788 - val_loss: 0.0636\n",
      "Epoch 27/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9758 - loss: 0.0555\n",
      "Epoch 27: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9761 - loss: 0.0549 - val_accuracy: 0.9661 - val_loss: 0.0916\n",
      "Epoch 28/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9903 - loss: 0.0254\n",
      "Epoch 28: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9904 - loss: 0.0251 - val_accuracy: 0.9746 - val_loss: 0.0708\n",
      "Epoch 29/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9905 - loss: 0.0228\n",
      "Epoch 29: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9905 - loss: 0.0230 - val_accuracy: 0.9746 - val_loss: 0.0894\n",
      "Epoch 30/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9761 - loss: 0.0643\n",
      "Epoch 30: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9762 - loss: 0.0646 - val_accuracy: 0.9661 - val_loss: 0.1159\n",
      "Epoch 31/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9856 - loss: 0.0488\n",
      "Epoch 31: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9857 - loss: 0.0489 - val_accuracy: 0.9513 - val_loss: 0.1531\n",
      "Epoch 32/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9875 - loss: 0.0320\n",
      "Epoch 32: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9877 - loss: 0.0315 - val_accuracy: 0.9428 - val_loss: 0.1959\n",
      "Epoch 33/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9853 - loss: 0.0375\n",
      "Epoch 33: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9853 - loss: 0.0375 - val_accuracy: 0.9619 - val_loss: 0.1246\n",
      "Epoch 34/200\n",
      "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9940 - loss: 0.0155\n",
      "Epoch 34: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9942 - loss: 0.0152 - val_accuracy: 0.9831 - val_loss: 0.0525\n",
      "Epoch 35/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9808 - loss: 0.0581\n",
      "Epoch 35: val_accuracy improved from 0.98517 to 0.98729, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9808 - loss: 0.0580 - val_accuracy: 0.9873 - val_loss: 0.0380\n",
      "Epoch 36/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9978 - loss: 0.0082\n",
      "Epoch 36: val_accuracy did not improve from 0.98729\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9788 - val_loss: 0.0508\n",
      "Epoch 37/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9995 - loss: 0.0065\n",
      "Epoch 37: val_accuracy improved from 0.98729 to 0.99364, saving model to CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9994 - loss: 0.0066 - val_accuracy: 0.9936 - val_loss: 0.0224\n",
      "Epoch 38/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9834 - loss: 0.0421\n",
      "Epoch 38: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9836 - loss: 0.0415 - val_accuracy: 0.9809 - val_loss: 0.0576\n",
      "Epoch 39/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - loss: 0.0123\n",
      "Epoch 39: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9947 - loss: 0.0122 - val_accuracy: 0.9809 - val_loss: 0.0607\n",
      "Epoch 40/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9964 - loss: 0.0104\n",
      "Epoch 40: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.9809 - val_loss: 0.0655\n",
      "Epoch 41/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9984 - loss: 0.0050\n",
      "Epoch 41: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9788 - val_loss: 0.0595\n",
      "Epoch 42/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9966 - loss: 0.0102\n",
      "Epoch 42: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9873 - val_loss: 0.0255\n",
      "Epoch 43/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.0825e-04\n",
      "Epoch 43: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.0872e-04 - val_accuracy: 0.9936 - val_loss: 0.0203\n",
      "Epoch 44/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 4.2985e-04\n",
      "Epoch 44: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.2888e-04 - val_accuracy: 0.9936 - val_loss: 0.0213\n",
      "Epoch 45/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 3.6223e-04\n",
      "Epoch 45: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.6153e-04 - val_accuracy: 0.9936 - val_loss: 0.0217\n",
      "Epoch 46/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 3.0001e-04\n",
      "Epoch 46: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.9967e-04 - val_accuracy: 0.9936 - val_loss: 0.0223\n",
      "Epoch 47/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.5832e-04\n",
      "Epoch 47: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.5810e-04 - val_accuracy: 0.9936 - val_loss: 0.0228\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.2220e-04\n",
      "Epoch 48: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.2216e-04 - val_accuracy: 0.9936 - val_loss: 0.0233\n",
      "Epoch 49/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.9499e-04\n",
      "Epoch 49: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.9498e-04 - val_accuracy: 0.9936 - val_loss: 0.0238\n",
      "Epoch 50/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.7274e-04\n",
      "Epoch 50: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 1.7274e-04 - val_accuracy: 0.9936 - val_loss: 0.0241\n",
      "Epoch 51/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.5565e-04\n",
      "Epoch 51: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.5565e-04 - val_accuracy: 0.9936 - val_loss: 0.0244\n",
      "Epoch 52/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.4117e-04\n",
      "Epoch 52: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.4118e-04 - val_accuracy: 0.9936 - val_loss: 0.0246\n",
      "Epoch 53/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.2905e-04\n",
      "Epoch 53: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.2905e-04 - val_accuracy: 0.9936 - val_loss: 0.0249\n",
      "Epoch 54/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.1914e-04\n",
      "Epoch 54: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.1913e-04 - val_accuracy: 0.9936 - val_loss: 0.0252\n",
      "Epoch 55/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.0987e-04\n",
      "Epoch 55: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.0986e-04 - val_accuracy: 0.9936 - val_loss: 0.0253\n",
      "Epoch 56/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.0203e-04\n",
      "Epoch 56: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 1.0202e-04 - val_accuracy: 0.9936 - val_loss: 0.0254\n",
      "Epoch 57/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 9.5376e-05\n",
      "Epoch 57: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 9.5337e-05 - val_accuracy: 0.9936 - val_loss: 0.0256\n",
      "Epoch 58/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 8.9353e-05\n",
      "Epoch 58: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 8.9307e-05 - val_accuracy: 0.9936 - val_loss: 0.0258\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.3637e-05\n",
      "Epoch 59: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 8.3612e-05 - val_accuracy: 0.9936 - val_loss: 0.0259\n",
      "Epoch 60/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 7.8734e-05\n",
      "Epoch 60: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 7.8674e-05 - val_accuracy: 0.9936 - val_loss: 0.0260\n",
      "Epoch 61/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.4226e-05\n",
      "Epoch 61: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.4193e-05 - val_accuracy: 0.9936 - val_loss: 0.0261\n",
      "Epoch 62/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 7.0220e-05\n",
      "Epoch 62: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.0147e-05 - val_accuracy: 0.9936 - val_loss: 0.0263\n",
      "Epoch 63/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.6352e-05\n",
      "Epoch 63: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.6275e-05 - val_accuracy: 0.9936 - val_loss: 0.0264\n",
      "Epoch 64/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 6.2813e-05\n",
      "Epoch 64: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.2774e-05 - val_accuracy: 0.9936 - val_loss: 0.0265\n",
      "Epoch 65/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.9645e-05\n",
      "Epoch 65: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 5.9563e-05 - val_accuracy: 0.9936 - val_loss: 0.0266\n",
      "Epoch 66/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 5.6601e-05\n",
      "Epoch 66: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 5.6517e-05 - val_accuracy: 0.9936 - val_loss: 0.0267\n",
      "Epoch 67/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.3863e-05\n",
      "Epoch 67: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 5.3778e-05 - val_accuracy: 0.9915 - val_loss: 0.0268\n",
      "Epoch 68/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.1232e-05\n",
      "Epoch 68: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 5.1148e-05 - val_accuracy: 0.9915 - val_loss: 0.0269\n",
      "Epoch 69/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 4.8796e-05\n",
      "Epoch 69: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 4.8711e-05 - val_accuracy: 0.9915 - val_loss: 0.0270\n",
      "Epoch 70/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.6441e-05\n",
      "Epoch 70: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 4.6357e-05 - val_accuracy: 0.9915 - val_loss: 0.0272\n",
      "Epoch 71/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 4.4308e-05\n",
      "Epoch 71: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 4.4224e-05 - val_accuracy: 0.9915 - val_loss: 0.0272\n",
      "Epoch 72/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 4.2315e-05\n",
      "Epoch 72: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 4.2232e-05 - val_accuracy: 0.9915 - val_loss: 0.0273\n",
      "Epoch 73/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 4.0431e-05\n",
      "Epoch 73: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 4.0348e-05 - val_accuracy: 0.9915 - val_loss: 0.0274\n",
      "Epoch 74/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 3.8643e-05\n",
      "Epoch 74: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.8561e-05 - val_accuracy: 0.9915 - val_loss: 0.0275\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 3.6910e-05\n",
      "Epoch 75: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 3.6870e-05 - val_accuracy: 0.9915 - val_loss: 0.0276\n",
      "Epoch 76/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 3.5360e-05\n",
      "Epoch 76: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.5280e-05 - val_accuracy: 0.9915 - val_loss: 0.0277\n",
      "Epoch 77/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 3.3850e-05\n",
      "Epoch 77: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 3.3811e-05 - val_accuracy: 0.9915 - val_loss: 0.0278\n",
      "Epoch 78/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.2430e-05\n",
      "Epoch 78: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 3.2352e-05 - val_accuracy: 0.9915 - val_loss: 0.0278\n",
      "Epoch 79/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 3.1083e-05\n",
      "Epoch 79: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 3.1006e-05 - val_accuracy: 0.9915 - val_loss: 0.0279\n",
      "Epoch 80/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.9809e-05\n",
      "Epoch 80: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 2.9734e-05 - val_accuracy: 0.9915 - val_loss: 0.0280\n",
      "Epoch 81/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.8557e-05\n",
      "Epoch 81: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.8484e-05 - val_accuracy: 0.9915 - val_loss: 0.0281\n",
      "Epoch 82/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 2.7404e-05\n",
      "Epoch 82: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 2.7332e-05 - val_accuracy: 0.9915 - val_loss: 0.0282\n",
      "Epoch 83/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.6320e-05\n",
      "Epoch 83: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.6250e-05 - val_accuracy: 0.9915 - val_loss: 0.0282\n",
      "Epoch 84/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.5256e-05\n",
      "Epoch 84: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.5188e-05 - val_accuracy: 0.9915 - val_loss: 0.0283\n",
      "Epoch 85/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 2.4271e-05\n",
      "Epoch 85: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 2.4204e-05 - val_accuracy: 0.9915 - val_loss: 0.0284\n",
      "Epoch 86/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.3313e-05\n",
      "Epoch 86: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.3249e-05 - val_accuracy: 0.9915 - val_loss: 0.0285\n",
      "Epoch 87/200\n",
      "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 2.2421e-05\n",
      "Epoch 87: val_accuracy did not improve from 0.99364\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 2.2358e-05 - val_accuracy: 0.9915 - val_loss: 0.0286\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp5/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 243ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:53:52.927234: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:53:52.929548: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9946 - loss: 0.0200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9866 - loss: 0.0332\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation / 5 fold cross validation )\n",
    "kSplits = 5\n",
    "# kfold = KFold(n_splits=kSplits, random_state=42, shuffle=True)\n",
    "kfold = StratifiedKFold(n_splits=kSplits, random_state=42, shuffle=True) # splits training data into 5 folds - class balance(stratify)\n",
    "\n",
    "# File path name to save best models\n",
    "foldername = \"CNN2D_results/V4_2_NOL_exp5/\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint #Saves the model with the highest validation accuracy for each fold\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "pred_all_val = np.zeros([len(X_2D_train),10])\n",
    "y_2D_val = np.zeros([len(X_2D_train),10])\n",
    "kfold_test_len = []\n",
    "\n",
    "fl1 = 0\n",
    "k = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True) #Stops training if validation accuracy doesn’t improve for 50 epochs, restoring the best weights.\n",
    "\n",
    "# Train the model \n",
    "# for train, test in kfold.split(X_2D_train,y_2D_train):\n",
    "for fold, (train, test) in enumerate(kfold.split(X_2D_train, y_label_train)):   \n",
    "\n",
    "  # Define where to save the best model\n",
    "  checkpoint_filepath = foldername + \"best_model_\" + str(k) + \".h5\"\n",
    "    \n",
    "  # Create a ModelCheckpoint callback\n",
    "  checkpoint = ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_accuracy',  # Monitor validation accuracy\n",
    "      save_best_only=True,  # Save only the best model\n",
    "      mode='max',  # Maximize accuracy\n",
    "      verbose=1\n",
    "  )        \n",
    "\n",
    "#For each fold, trains a new CNN model on the training subset (X_2D_train[train], y_2D_train[train]) for up to 200 epochs.\n",
    "  Classification_2D = CNN_2D()\n",
    "  # history = Classification_2D.model.fit(X_2D_train[train], y_2D_train[train], verbose=1, epochs=50) #epochs=12\n",
    "  history = Classification_2D.model.fit(\n",
    "        X_2D_train[train], y_2D_train[train],\n",
    "        validation_data=(X_2D_train[test], y_2D_train[test]),  # Validation set for monitoring\n",
    "        epochs=200,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint, early_stop]  # Save the best model\n",
    "  )\n",
    "  \n",
    "  print(\"Best model saved at:\", checkpoint_filepath)\n",
    "  CNN_2D_best_model = load_model(checkpoint_filepath)\n",
    "  print(\"Best model loaded successfully!\")\n",
    "  \n",
    "  fl2 = fl1 + len(test)\n",
    "  pred_all_val[fl1:fl2,:] = CNN_2D_best_model.predict(X_2D_train[test])\n",
    "  y_2D_val[fl1:fl2,:] = y_2D_train[test]\n",
    "  kfold_test_len.append(fl2-fl1)\n",
    "  fl1 = fl2  \n",
    "\n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  train_loss, train_accuracy = CNN_2D_best_model.evaluate(X_2D_train[train], y_2D_train[train]) \n",
    "  accuracy_train.append(train_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  val_loss, val_accuracy = CNN_2D_best_model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  accuracy_val.append(val_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  test_loss, test_accuracy = CNN_2D_best_model.evaluate(X_2D_test, y_2D_test) \n",
    "  accuracy_test.append(test_accuracy)  \n",
    "  \n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  # kf_loss, kf_accuracy = Classification_2D.model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  # accuracy_2D.append(kf_accuracy)\n",
    "  \n",
    "  k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7705181d-c6cb-4412-a002-8937240306ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 2D train accuracy = 100.0\n",
      "CNN 2D validation accuracy = 98.7310528755188\n",
      "CNN 2D test accuracy = 98.57867956161499\n",
      "\u001b[1m 7/74\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 08:53:58.082304: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-10 08:53:58.082771: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Classification_2D.model.summary()\n",
    "\n",
    "CNN_2D_train_accuracy = np.average(accuracy_train)*100\n",
    "print('CNN 2D train accuracy =', CNN_2D_train_accuracy)\n",
    "# print(accuracy_train)\n",
    "\n",
    "CNN_2D_val_accuracy = np.average(accuracy_val)*100\n",
    "print('CNN 2D validation accuracy =', CNN_2D_val_accuracy)\n",
    "# print(accuracy_val)\n",
    "\n",
    "CNN_2D_test_accuracy = np.average(accuracy_test)*100\n",
    "print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "# print(accuracy_test)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test set\n",
    "# CNN_2D_test_loss, CNN_2D_test_accuracy = Classification_2D.model.evaluate(X_2D_test, y_2D_test)\n",
    "# CNN_2D_test_accuracy*=100\n",
    "# print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "  y_pred = np.argmax(Model.predict(X), axis=1)\n",
    "  ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "  return ConfusionMat\n",
    "\n",
    "# Plot results - CNN 2D\n",
    "plt.figure(5)\n",
    "plt.title('Confusion Matrix - CNN 2D Train') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_train, y_2D_train) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.title('Confusion Matrix - CNN 2D Test') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_test, y_2D_test) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7)\n",
    "plt.title('Train - Accuracy - CNN 2D')\n",
    "plt.bar(np.arange(1,kSplits+1),[i*100 for i in accuracy_val])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70,100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(8)\n",
    "plt.title('Train vs Test Accuracy - CNN 2D')\n",
    "plt.bar([1,2],[CNN_2D_train_accuracy,CNN_2D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.xticks([1,2],['Train', 'Test'])\n",
    "plt.ylim([70,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d304a-13a4-42ce-bd02-0c15bc3ecc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b387e8-173c-4018-8896-a0340889bd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
