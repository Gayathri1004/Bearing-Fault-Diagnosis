{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5ab9cc-9d31-4bd8-9339-c80842c4c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32209d77-1aef-4ca4-81d7-ea6457e51333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 1\n",
    "random.seed(SEED)            # Python random module\n",
    "np.random.seed(SEED)         # NumPy\n",
    "tf.random.set_seed(SEED)     # TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71899bcf-951f-483f-9b14-081df6aa4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce deterministic behavior for GPU operations\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic execution\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Deterministic cuDNN algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd1cd7b-5ae6-45e4-9888-9da0cae55811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control GPU memory allocation (prevents TensorFlow from using all GPU memory)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # Enable memory growth\n",
    "\n",
    "# Restrict parallelism (ensures consistent execution order)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0842921e-69f2-4b98-a50d-a8cbf80872d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import scipy.io #to load matlab files \n",
    "# import numpy as np\n",
    "from sklearn.model_selection import train_test_split #for data splitting #, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras import layers, models #build and train CNN model\n",
    "import matplotlib.pyplot as plt #for plotting confusion matrices and accuracy metrics\n",
    "import seaborn as sns \n",
    "# import pandas as pd\n",
    "\n",
    "from scipy import signal #for computing spectograms\n",
    "from skimage.transform import resize #for resizing data\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9d9640-93e2-47e2-98d4-06a74ec1a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Read CWRU Bearing Data (Load - 2HP)\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "def ImportData():\n",
    "  folder_path = 'CWRU_BearingData_Load_2HP' \n",
    "  # X99_normal = scipy.io.loadmat('content/drive/MyDrive/BearingData_CaseWestern/99.mat')['X099_DE_time'] \n",
    "  file_path1 = os.path.join(folder_path, '99.mat')\n",
    "  X99_normal = scipy.io.loadmat(file_path1)['X099_DE_time'] #vibration data extracted from X099_DE_time key (drive-end accelerometer data)\n",
    "\n",
    "    \n",
    "  # X111_InnerRace_007 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/111.mat')['X111_DE_time']\n",
    "  file_path2 = os.path.join(folder_path, '111.mat')\n",
    "  X111_InnerRace_007  = scipy.io.loadmat(file_path2)['X111_DE_time']\n",
    "\n",
    "  # X124_Ball_007 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/124.mat')['X124_DE_time']\n",
    "  file_path3 = os.path.join(folder_path, '124.mat')\n",
    "  X124_Ball_007 = scipy.io.loadmat(file_path3)['X124_DE_time']\n",
    "\n",
    "  # X137_Outer_007 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/137.mat')['X137_DE_time']\n",
    "  file_path4 = os.path.join(folder_path, '137.mat')\n",
    "  X137_Outer_007 = scipy.io.loadmat(file_path4)['X137_DE_time']\n",
    "    \n",
    "  # X176_InnerRace_014 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/176.mat')['X176_DE_time']\n",
    "  file_path5 = os.path.join(folder_path, '176.mat')\n",
    "  X176_InnerRace_014 = scipy.io.loadmat(file_path5)['X176_DE_time']\n",
    "\n",
    "  # X191_Ball_014 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/191.mat')['X191_DE_time']\n",
    "  file_path6 = os.path.join(folder_path, '191.mat')\n",
    "  X191_Ball_014 = scipy.io.loadmat(file_path6)['X191_DE_time']\n",
    "    \n",
    "  # X203_Outer_014 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/203.mat')['X203_DE_time']\n",
    "  file_path7 = os.path.join(folder_path, '203.mat')\n",
    "  X203_Outer_014  = scipy.io.loadmat(file_path7)['X203_DE_time']\n",
    "\n",
    "  #  X215_InnerRace_021 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/215.mat')['X215_DE_time']\n",
    "  file_path8 = os.path.join(folder_path, '215.mat')\n",
    "  X215_InnerRace_021  = scipy.io.loadmat(file_path8)['X215_DE_time']\n",
    "    \n",
    "  # X228_Ball_021 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/228.mat')['X228_DE_time']\n",
    "  file_path9 = os.path.join(folder_path, '228.mat')\n",
    "  X228_Ball_021  = scipy.io.loadmat(file_path9)['X228_DE_time']\n",
    "\n",
    "  # X240_Outer_021 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/240.mat')['X240_DE_time']\n",
    "  file_path10 = os.path.join(folder_path, '240.mat')\n",
    "  X240_Outer_021  = scipy.io.loadmat(file_path10)['X240_DE_time'] \n",
    "    \n",
    "  return [X99_normal,X111_InnerRace_007,X124_Ball_007,X137_Outer_007,X176_InnerRace_014,X191_Ball_014,X203_Outer_014,X215_InnerRace_021,X228_Ball_021,X240_Outer_021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6fbfd8-76a9-49e1-94e2-2924bd737533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data Processing and Feature Extraction\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "# def Sampling(Data, interval_length, samples_per_block):\n",
    "#     No_of_blocks = (round(len(Data)/interval_length) - round(samples_per_block/interval_length) - 1)\n",
    "#     SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "#     for i in range(No_of_blocks):\n",
    "#         SplitData[i,:] = Data[i*interval_length:(i*interval_length)+samples_per_block].T\n",
    "#     return SplitData\n",
    "\n",
    "#segments the time-series data into smaller blocks for processing\n",
    "#data: 1D numpy array of vibration data\n",
    "#interval length: step size (in samples) betweeen the start of consectuive blocks\n",
    "#samples_per_block: no. of samples in each block (fixed at 1600 in the code)\n",
    "#ignore_points: no. of points to skip at start and end of data(default is 0)\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    # Adjust data length to ignore the first and last 'ignore_points'\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    print(len(Data))\n",
    "    # Adjust the number of blocks\n",
    "    No_of_blocks = (round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1)\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block]) #splitdata matrix where each row is a block of samples_per_block samples\n",
    "    \n",
    "    for i in range(No_of_blocks):\n",
    "        # Skip the first 'ignore_points' and start sampling from that position\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx:(start_idx + samples_per_block)].T #.T transpose ensure the data is correctly oriented (since the input is a column vector)\n",
    "    \n",
    "    return SplitData #2D array of shape - no.ofblocks, samples_per_block)\n",
    "\n",
    "\n",
    "def DataPreparation(Data, interval_length, samples_per_block):\n",
    "  for count,i in enumerate(Data):\n",
    "    SplitData = Sampling(i, interval_length, samples_per_block) #for each dataset calls samplying to create blocks of 1600 samples\n",
    "    y = np.zeros([len(SplitData),10]) #y (one-hot encoded): Shape (No_of_blocks, 10), where the column corresponding to the class is set to 1 (e.g., for class 0, [1, 0, 0, ..., 0])\n",
    "    y[:,count] = 1\n",
    "    y1 = np.zeros([len(SplitData),1]) #y1 (integer labels): Shape (No_of_blocks, 1), where each element is the class index (0 to 9).\n",
    "    y1[:,0] = count \n",
    "    # Stack up and label the data   \n",
    "    if count==0:\n",
    "      X = SplitData\n",
    "      LabelPositional = y\n",
    "      Label = y1\n",
    "    else:\n",
    "      X = np.append(X, SplitData, axis=0)\n",
    "      LabelPositional = np.append(LabelPositional,y,axis=0)\n",
    "      Label = np.append(Label,y1,axis=0)\n",
    "  print(X)\n",
    "  return X, LabelPositional, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44975d7a-8b19-44e0-a88f-ca7bf2c4749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(ary):\n",
    "    ary = (ary - ary.min()) / np.abs(ary.max() - ary.min())\n",
    "    return ary\n",
    "\n",
    "def generate_spectrogram_image(data_y_vector, image_shape):\n",
    "    \"\"\"\n",
    "    Calculate the spectrogram of an array data_y_vector and resize it in \n",
    "    the image_shape resolution\n",
    "    \"\"\"\n",
    "    fs = 48000\n",
    "    # data_y_vector_len = np.shape(data_y_vector)[0]\n",
    "\n",
    "    f, t, sxx = signal.spectrogram(\n",
    "        data_y_vector,\n",
    "        fs)\n",
    "\n",
    "    sxx = min_max_norm(sxx)\n",
    "    sxx = resize(sxx, image_shape, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    return sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c91be0-79cd-438c-876c-9291efc88572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485063\n",
      "485643\n",
      "486804\n",
      "486804\n",
      "487964\n",
      "487384\n",
      "486804\n",
      "491446\n",
      "487384\n",
      "487964\n",
      "[[ 0.06425354  0.06300185 -0.00438092 ... -0.029832   -0.018984\n",
      "  -0.002712  ]\n",
      " [ 0.06571385  0.01606338 -0.05424    ...  0.01585477  0.02211323\n",
      "   0.07280677]\n",
      " [ 0.04672985 -0.00146031 -0.04819015 ... -0.10952308 -0.06884308\n",
      "   0.00146031]\n",
      " ...\n",
      " [ 0.13354667  0.09932533  0.06426933 ... -0.00584267  0.06844267\n",
      "   0.13354667]\n",
      " [ 0.13688533  0.11268     0.08430133 ...  0.20365867  0.13855467\n",
      "   0.06844267]\n",
      " [-0.686096   -0.74201867 -0.698616   ... -0.23370667 -0.33136267\n",
      "  -0.34221333]]\n",
      "Shape of Input Data = (15179, 1296)\n",
      "Shape of Label Y_CNN = (15179, 10)\n",
      "Shape of Label Y = (15179, 1)\n"
     ]
    }
   ],
   "source": [
    "Data = ImportData()\n",
    "interval_length = 320 #1600  #290 #200  \n",
    "samples_per_block = 1296 #1650-25*2\n",
    "\n",
    "\n",
    "# Y_CNN is of shape (n, 10) representing 10 classes as 10 columns. In each sample, for the class to which it belongs, \n",
    "# the corresponding column value is marked 1 and the rest as 0, facilitating Softmax implementation in CNN \n",
    "# Y is of shape (m, 1) where column values are between 0 and 9 representing the classes directly. - 1-hot encoding\n",
    "X, Y_CNN, Y = DataPreparation(Data, interval_length, samples_per_block) \n",
    "\n",
    "\n",
    "print('Shape of Input Data =', X.shape)\n",
    "print('Shape of Label Y_CNN =', Y_CNN.shape)\n",
    "print('Shape of Label Y =', Y.shape)\n",
    "\n",
    "# XX = {'X':X}\n",
    "# scipy.io.savemat('Data.mat', XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaee3ff-4250-4baf-bf15-23256e6d8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15179, 36, 36, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Training\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "## 2-Dimensional Convolutional Neural Network Classification\n",
    "\n",
    "# Reshape the data - 2 dimensional feed \n",
    "Input_2D = X.reshape([-1,36,36,1])\n",
    "\n",
    "# Input_2D = X_image.reshape([-1,96,96,1])\n",
    "print(Input_2D.shape)\n",
    "\n",
    "# Test-Train Split \n",
    "X_2D_train, X_2D_test, y_2D_train, y_2D_test, y_label_train, y_label_test = train_test_split(Input_2D, Y_CNN, Y, train_size=0.8, test_size=0.2, random_state=42, stratify=Y)\n",
    "#(ensuring class balance via stratify=Y)\n",
    "# X_2D_train, X_2D_test, y_2D_train, y_2D_test = train_test_split(Input_2D, Y_CNN, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define the CNN Classification model\n",
    "class CNN_2D():\n",
    "  def __init__(self):\n",
    "    self.model = self.CreateModel()\n",
    "\n",
    "  def CreateModel(self):\n",
    "    model = models.Sequential([\n",
    "        # layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding ='same',activation='relu'),\n",
    "        layers.Conv2D(filters=16, kernel_size=(3,3), padding='same',activation='relu', input_shape=(36,36,1)),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=32, kernel_size=(3,3), padding ='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=64, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100,activation='relu'),\n",
    "        layers.Dense(50,activation='relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Softmax()\n",
    "        ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf41e7c-a3e8-4875-ac08-918e90ad86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gayathri/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:08:36.211370: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 14:08:36.212443: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5221 - loss: 1.3004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:08:46.794896: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 14:08:46.795186: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83738, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.5233 - loss: 1.2972 - val_accuracy: 0.8374 - val_loss: 0.3604\n",
      "Epoch 2/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8560 - loss: 0.3464\n",
      "Epoch 2: val_accuracy did not improve from 0.83738\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.8560 - loss: 0.3463 - val_accuracy: 0.7637 - val_loss: 0.5688\n",
      "Epoch 3/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8601 - loss: 0.3260\n",
      "Epoch 3: val_accuracy did not improve from 0.83738\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8602 - loss: 0.3257 - val_accuracy: 0.8024 - val_loss: 0.4405\n",
      "Epoch 4/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8811 - loss: 0.2536\n",
      "Epoch 4: val_accuracy did not improve from 0.83738\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.8811 - loss: 0.2535 - val_accuracy: 0.7929 - val_loss: 0.4992\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8904 - loss: 0.2537\n",
      "Epoch 5: val_accuracy improved from 0.83738 to 0.88596, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.8905 - loss: 0.2535 - val_accuracy: 0.8860 - val_loss: 0.2393\n",
      "Epoch 6/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9120 - loss: 0.1914\n",
      "Epoch 6: val_accuracy improved from 0.88596 to 0.88925, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9121 - loss: 0.1913 - val_accuracy: 0.8893 - val_loss: 0.2468\n",
      "Epoch 7/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9083 - loss: 0.2124\n",
      "Epoch 7: val_accuracy improved from 0.88925 to 0.90737, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9084 - loss: 0.2123 - val_accuracy: 0.9074 - val_loss: 0.2068\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9330 - loss: 0.1622\n",
      "Epoch 8: val_accuracy improved from 0.90737 to 0.94195, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9330 - loss: 0.1621 - val_accuracy: 0.9420 - val_loss: 0.1514\n",
      "Epoch 9/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9409 - loss: 0.1509\n",
      "Epoch 9: val_accuracy improved from 0.94195 to 0.94977, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9410 - loss: 0.1508 - val_accuracy: 0.9498 - val_loss: 0.1179\n",
      "Epoch 10/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9523 - loss: 0.1221\n",
      "Epoch 10: val_accuracy improved from 0.94977 to 0.96418, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9524 - loss: 0.1218 - val_accuracy: 0.9642 - val_loss: 0.0912\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9645 - loss: 0.0882\n",
      "Epoch 11: val_accuracy improved from 0.96418 to 0.97242, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9645 - loss: 0.0881 - val_accuracy: 0.9724 - val_loss: 0.0735\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9661 - loss: 0.0878\n",
      "Epoch 12: val_accuracy improved from 0.97242 to 0.98106, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9661 - loss: 0.0876 - val_accuracy: 0.9811 - val_loss: 0.0549\n",
      "Epoch 13/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9688 - loss: 0.0915\n",
      "Epoch 13: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9689 - loss: 0.0913 - val_accuracy: 0.9716 - val_loss: 0.0682\n",
      "Epoch 14/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9764 - loss: 0.0719\n",
      "Epoch 14: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9764 - loss: 0.0717 - val_accuracy: 0.9741 - val_loss: 0.0663\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9853 - loss: 0.0465\n",
      "Epoch 15: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9853 - loss: 0.0464 - val_accuracy: 0.9807 - val_loss: 0.0582\n",
      "Epoch 16/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9799 - loss: 0.0586\n",
      "Epoch 16: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9799 - loss: 0.0586 - val_accuracy: 0.9485 - val_loss: 0.1559\n",
      "Epoch 17/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9697 - loss: 0.0903\n",
      "Epoch 17: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 0.9698 - loss: 0.0902 - val_accuracy: 0.9621 - val_loss: 0.1290\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9840 - loss: 0.0500\n",
      "Epoch 18: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9840 - loss: 0.0499 - val_accuracy: 0.9802 - val_loss: 0.0535\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9849 - loss: 0.0456\n",
      "Epoch 19: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9849 - loss: 0.0457 - val_accuracy: 0.9765 - val_loss: 0.0635\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9929 - loss: 0.0200\n",
      "Epoch 20: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9929 - loss: 0.0200 - val_accuracy: 0.9786 - val_loss: 0.0627\n",
      "Epoch 21/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9950 - loss: 0.0183\n",
      "Epoch 21: val_accuracy did not improve from 0.98106\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9950 - loss: 0.0183 - val_accuracy: 0.9699 - val_loss: 0.0882\n",
      "Epoch 22/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9895 - loss: 0.0273\n",
      "Epoch 22: val_accuracy improved from 0.98106 to 0.98436, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9895 - loss: 0.0273 - val_accuracy: 0.9844 - val_loss: 0.0481\n",
      "Epoch 23/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9948 - loss: 0.0196\n",
      "Epoch 23: val_accuracy did not improve from 0.98436\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9948 - loss: 0.0197 - val_accuracy: 0.9687 - val_loss: 0.0896\n",
      "Epoch 24/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9922 - loss: 0.0287\n",
      "Epoch 24: val_accuracy did not improve from 0.98436\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9922 - loss: 0.0286 - val_accuracy: 0.9774 - val_loss: 0.0773\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0377\n",
      "Epoch 25: val_accuracy did not improve from 0.98436\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9892 - loss: 0.0376 - val_accuracy: 0.9506 - val_loss: 0.1657\n",
      "Epoch 26/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9926 - loss: 0.0217\n",
      "Epoch 26: val_accuracy did not improve from 0.98436\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.9749 - val_loss: 0.0947\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0066\n",
      "Epoch 27: val_accuracy improved from 0.98436 to 0.99094, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.9909 - val_loss: 0.0299\n",
      "Epoch 28/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 7.2726e-04\n",
      "Epoch 28: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 7.4119e-04 - val_accuracy: 0.9864 - val_loss: 0.0433\n",
      "Epoch 29/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9923 - loss: 0.0222\n",
      "Epoch 29: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9923 - loss: 0.0223 - val_accuracy: 0.9720 - val_loss: 0.0986\n",
      "Epoch 30/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9913 - loss: 0.0228\n",
      "Epoch 30: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9914 - loss: 0.0228 - val_accuracy: 0.9802 - val_loss: 0.0652\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9915 - loss: 0.0300\n",
      "Epoch 31: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9915 - loss: 0.0299 - val_accuracy: 0.9831 - val_loss: 0.0510\n",
      "Epoch 32/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.1654e-04\n",
      "Epoch 32: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.4190e-04 - val_accuracy: 0.9720 - val_loss: 0.1058\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9866 - loss: 0.0481\n",
      "Epoch 33: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9867 - loss: 0.0480 - val_accuracy: 0.9889 - val_loss: 0.0368\n",
      "Epoch 34/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9993 - loss: 0.0022\n",
      "Epoch 34: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9905 - val_loss: 0.0332\n",
      "Epoch 35/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.2013e-04\n",
      "Epoch 35: val_accuracy improved from 0.99094 to 0.99135, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.1971e-04 - val_accuracy: 0.9914 - val_loss: 0.0319\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.2430e-05\n",
      "Epoch 36: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.2413e-05 - val_accuracy: 0.9914 - val_loss: 0.0322\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.5080e-05\n",
      "Epoch 37: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.5073e-05 - val_accuracy: 0.9914 - val_loss: 0.0330\n",
      "Epoch 38/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.9560e-05\n",
      "Epoch 38: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.9557e-05 - val_accuracy: 0.9914 - val_loss: 0.0337\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9644e-05\n",
      "Epoch 39: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.9643e-05 - val_accuracy: 0.9914 - val_loss: 0.0344\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.2802e-05\n",
      "Epoch 40: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.2802e-05 - val_accuracy: 0.9914 - val_loss: 0.0352\n",
      "Epoch 41/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7859e-05\n",
      "Epoch 41: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7861e-05 - val_accuracy: 0.9914 - val_loss: 0.0359\n",
      "Epoch 42/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4155e-05\n",
      "Epoch 42: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4157e-05 - val_accuracy: 0.9914 - val_loss: 0.0366\n",
      "Epoch 43/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1373e-05\n",
      "Epoch 43: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1374e-05 - val_accuracy: 0.9914 - val_loss: 0.0372\n",
      "Epoch 44/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.2197e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.2215e-06 - val_accuracy: 0.9909 - val_loss: 0.0379\n",
      "Epoch 45/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.5338e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.5349e-06 - val_accuracy: 0.9914 - val_loss: 0.0385\n",
      "Epoch 46/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.1784e-06\n",
      "Epoch 46: val_accuracy improved from 0.99135 to 0.99177, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.1789e-06 - val_accuracy: 0.9918 - val_loss: 0.0391\n",
      "Epoch 47/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.0747e-06\n",
      "Epoch 47: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.0756e-06 - val_accuracy: 0.9918 - val_loss: 0.0398\n",
      "Epoch 48/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.1881e-06\n",
      "Epoch 48: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.1885e-06 - val_accuracy: 0.9918 - val_loss: 0.0404\n",
      "Epoch 49/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.4647e-06\n",
      "Epoch 49: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.4655e-06 - val_accuracy: 0.9918 - val_loss: 0.0410\n",
      "Epoch 50/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8764e-06\n",
      "Epoch 50: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.8767e-06 - val_accuracy: 0.9918 - val_loss: 0.0416\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.3916e-06\n",
      "Epoch 51: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.3922e-06 - val_accuracy: 0.9918 - val_loss: 0.0422\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9932e-06\n",
      "Epoch 52: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9938e-06 - val_accuracy: 0.9918 - val_loss: 0.0428\n",
      "Epoch 53/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6619e-06\n",
      "Epoch 53: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6626e-06 - val_accuracy: 0.9918 - val_loss: 0.0434\n",
      "Epoch 54/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3888e-06\n",
      "Epoch 54: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3892e-06 - val_accuracy: 0.9918 - val_loss: 0.0440\n",
      "Epoch 55/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1621e-06\n",
      "Epoch 55: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1627e-06 - val_accuracy: 0.9918 - val_loss: 0.0446\n",
      "Epoch 56/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.7326e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.7359e-07 - val_accuracy: 0.9918 - val_loss: 0.0451\n",
      "Epoch 57/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.1452e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.1497e-07 - val_accuracy: 0.9918 - val_loss: 0.0457\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.8302e-07\n",
      "Epoch 58: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.8327e-07 - val_accuracy: 0.9918 - val_loss: 0.0463\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.7328e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.7350e-07 - val_accuracy: 0.9918 - val_loss: 0.0469\n",
      "Epoch 60/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.8159e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.8169e-07 - val_accuracy: 0.9918 - val_loss: 0.0475\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.0478e-07\n",
      "Epoch 61: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.0494e-07 - val_accuracy: 0.9918 - val_loss: 0.0480\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.3984e-07\n",
      "Epoch 62: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.3998e-07 - val_accuracy: 0.9918 - val_loss: 0.0486\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8570e-07\n",
      "Epoch 63: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.8583e-07 - val_accuracy: 0.9918 - val_loss: 0.0492\n",
      "Epoch 64/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.3998e-07\n",
      "Epoch 64: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.4009e-07 - val_accuracy: 0.9918 - val_loss: 0.0498\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0174e-07\n",
      "Epoch 65: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.0183e-07 - val_accuracy: 0.9918 - val_loss: 0.0504\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6997e-07\n",
      "Epoch 66: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7005e-07 - val_accuracy: 0.9918 - val_loss: 0.0510\n",
      "Epoch 67/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4331e-07\n",
      "Epoch 67: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.4342e-07 - val_accuracy: 0.9918 - val_loss: 0.0515\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2059e-07\n",
      "Epoch 68: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.2065e-07 - val_accuracy: 0.9914 - val_loss: 0.0521\n",
      "Epoch 69/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0187e-07\n",
      "Epoch 69: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0195e-07 - val_accuracy: 0.9914 - val_loss: 0.0527\n",
      "Epoch 70/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.5327e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.5394e-08 - val_accuracy: 0.9914 - val_loss: 0.0532\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.1892e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.1930e-08 - val_accuracy: 0.9914 - val_loss: 0.0538\n",
      "Epoch 72/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.0764e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.0797e-08 - val_accuracy: 0.9914 - val_loss: 0.0543\n",
      "Epoch 73/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.1319e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.1348e-08 - val_accuracy: 0.9918 - val_loss: 0.0548\n",
      "Epoch 74/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.3184e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.3221e-08 - val_accuracy: 0.9918 - val_loss: 0.0553\n",
      "Epoch 75/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.6431e-08\n",
      "Epoch 75: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.6463e-08 - val_accuracy: 0.9918 - val_loss: 0.0558\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.0700e-08\n",
      "Epoch 76: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.0718e-08 - val_accuracy: 0.9918 - val_loss: 0.0563\n",
      "Epoch 77/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5932e-08\n",
      "Epoch 77: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.5948e-08 - val_accuracy: 0.9918 - val_loss: 0.0569\n",
      "Epoch 78/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.1925e-08\n",
      "Epoch 78: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1940e-08 - val_accuracy: 0.9918 - val_loss: 0.0573\n",
      "Epoch 79/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8771e-08\n",
      "Epoch 79: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.8789e-08 - val_accuracy: 0.9918 - val_loss: 0.0579\n",
      "Epoch 80/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.5894e-08\n",
      "Epoch 80: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5904e-08 - val_accuracy: 0.9918 - val_loss: 0.0584\n",
      "Epoch 81/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3451e-08\n",
      "Epoch 81: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3464e-08 - val_accuracy: 0.9918 - val_loss: 0.0590\n",
      "Epoch 82/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1336e-08\n",
      "Epoch 82: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1344e-08 - val_accuracy: 0.9918 - val_loss: 0.0594\n",
      "Epoch 83/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.6743e-09\n",
      "Epoch 83: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.6805e-09 - val_accuracy: 0.9918 - val_loss: 0.0600\n",
      "Epoch 84/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.1421e-09\n",
      "Epoch 84: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.1480e-09 - val_accuracy: 0.9918 - val_loss: 0.0604\n",
      "Epoch 85/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.0203e-09\n",
      "Epoch 85: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.0255e-09 - val_accuracy: 0.9918 - val_loss: 0.0608\n",
      "Epoch 86/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.0814e-09\n",
      "Epoch 86: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.0852e-09 - val_accuracy: 0.9918 - val_loss: 0.0612\n",
      "Epoch 87/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.1845e-09\n",
      "Epoch 87: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.1877e-09 - val_accuracy: 0.9918 - val_loss: 0.0617\n",
      "Epoch 88/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.3992e-09\n",
      "Epoch 88: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.4038e-09 - val_accuracy: 0.9918 - val_loss: 0.0622\n",
      "Epoch 89/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.5993e-09\n",
      "Epoch 89: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.6024e-09 - val_accuracy: 0.9918 - val_loss: 0.0626\n",
      "Epoch 90/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.9514e-09\n",
      "Epoch 90: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.9536e-09 - val_accuracy: 0.9918 - val_loss: 0.0630\n",
      "Epoch 91/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.6249e-09\n",
      "Epoch 91: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.6266e-09 - val_accuracy: 0.9918 - val_loss: 0.0634\n",
      "Epoch 92/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.2763e-09\n",
      "Epoch 92: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2791e-09 - val_accuracy: 0.9918 - val_loss: 0.0638\n",
      "Epoch 93/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9933e-09\n",
      "Epoch 93: val_accuracy did not improve from 0.99177\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9962e-09 - val_accuracy: 0.9918 - val_loss: 0.0639\n",
      "Epoch 94/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7851e-09\n",
      "Epoch 94: val_accuracy improved from 0.99177 to 0.99218, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.7873e-09 - val_accuracy: 0.9922 - val_loss: 0.0642\n",
      "Epoch 95/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4784e-09\n",
      "Epoch 95: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4801e-09 - val_accuracy: 0.9918 - val_loss: 0.0648\n",
      "Epoch 96/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2088e-09\n",
      "Epoch 96: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2103e-09 - val_accuracy: 0.9922 - val_loss: 0.0650\n",
      "Epoch 97/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0635e-09\n",
      "Epoch 97: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0658e-09 - val_accuracy: 0.9922 - val_loss: 0.0651\n",
      "Epoch 98/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.3023e-10\n",
      "Epoch 98: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.3129e-10 - val_accuracy: 0.9922 - val_loss: 0.0652\n",
      "Epoch 99/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.2055e-10\n",
      "Epoch 99: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.2153e-10 - val_accuracy: 0.9922 - val_loss: 0.0655\n",
      "Epoch 100/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.6648e-10\n",
      "Epoch 100: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.6691e-10 - val_accuracy: 0.9922 - val_loss: 0.0655\n",
      "Epoch 101/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.2373e-10\n",
      "Epoch 101: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.2511e-10 - val_accuracy: 0.9922 - val_loss: 0.0655\n",
      "Epoch 102/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6078e-10\n",
      "Epoch 102: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.6138e-10 - val_accuracy: 0.9922 - val_loss: 0.0657\n",
      "Epoch 103/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.3533e-10\n",
      "Epoch 103: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.3663e-10 - val_accuracy: 0.9922 - val_loss: 0.0655\n",
      "Epoch 104/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.5644e-10\n",
      "Epoch 104: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.5692e-10 - val_accuracy: 0.9922 - val_loss: 0.0658\n",
      "Epoch 105/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9674e-10\n",
      "Epoch 105: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.9721e-10 - val_accuracy: 0.9922 - val_loss: 0.0656\n",
      "Epoch 106/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.0961e-10\n",
      "Epoch 106: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.1043e-10 - val_accuracy: 0.9922 - val_loss: 0.0654\n",
      "Epoch 107/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8110e-10\n",
      "Epoch 107: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8143e-10 - val_accuracy: 0.9918 - val_loss: 0.0653\n",
      "Epoch 108/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8252e-10\n",
      "Epoch 108: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8292e-10 - val_accuracy: 0.9918 - val_loss: 0.0653\n",
      "Epoch 109/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9706e-10\n",
      "Epoch 109: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.9745e-10 - val_accuracy: 0.9918 - val_loss: 0.0659\n",
      "Epoch 110/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5566e-10\n",
      "Epoch 110: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5600e-10 - val_accuracy: 0.9922 - val_loss: 0.0647\n",
      "Epoch 111/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4527e-10\n",
      "Epoch 111: val_accuracy did not improve from 0.99218\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4576e-10 - val_accuracy: 0.9922 - val_loss: 0.0640\n",
      "Epoch 112/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.6688e-10\n",
      "Epoch 112: val_accuracy improved from 0.99218 to 0.99259, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6739e-10 - val_accuracy: 0.9926 - val_loss: 0.0641\n",
      "Epoch 113/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8828e-10\n",
      "Epoch 113: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8842e-10 - val_accuracy: 0.9926 - val_loss: 0.0635\n",
      "Epoch 114/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.6665e-10\n",
      "Epoch 114: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6701e-10 - val_accuracy: 0.9926 - val_loss: 0.0646\n",
      "Epoch 115/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8466e-10\n",
      "Epoch 115: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8498e-10 - val_accuracy: 0.9926 - val_loss: 0.0626\n",
      "Epoch 116/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.7639e-10\n",
      "Epoch 116: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7668e-10 - val_accuracy: 0.9922 - val_loss: 0.0614\n",
      "Epoch 117/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8989e-10\n",
      "Epoch 117: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9049e-10 - val_accuracy: 0.9926 - val_loss: 0.0638\n",
      "Epoch 118/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.4993e-10\n",
      "Epoch 118: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4991e-10 - val_accuracy: 0.9922 - val_loss: 0.0618\n",
      "Epoch 119/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.5854e-10\n",
      "Epoch 119: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.5940e-10 - val_accuracy: 0.9926 - val_loss: 0.0626\n",
      "Epoch 120/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.8858e-11\n",
      "Epoch 120: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.9080e-11 - val_accuracy: 0.9926 - val_loss: 0.0643\n",
      "Epoch 121/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.0295e-10\n",
      "Epoch 121: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0349e-10 - val_accuracy: 0.9926 - val_loss: 0.0616\n",
      "Epoch 122/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9835 - loss: 0.0708\n",
      "Epoch 122: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9835 - loss: 0.0709 - val_accuracy: 0.9769 - val_loss: 0.0732\n",
      "Epoch 123/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9945 - loss: 0.0187\n",
      "Epoch 123: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9946 - loss: 0.0187 - val_accuracy: 0.9790 - val_loss: 0.0718\n",
      "Epoch 124/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9952 - loss: 0.0175\n",
      "Epoch 124: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9952 - loss: 0.0175 - val_accuracy: 0.9646 - val_loss: 0.1379\n",
      "Epoch 125/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9924 - loss: 0.0263\n",
      "Epoch 125: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 228ms/step - accuracy: 0.9924 - loss: 0.0263 - val_accuracy: 0.9782 - val_loss: 0.0640\n",
      "Epoch 126/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 0.9992 - loss: 0.0043\n",
      "Epoch 126: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 478ms/step - accuracy: 0.9992 - loss: 0.0043 - val_accuracy: 0.9893 - val_loss: 0.0339\n",
      "Epoch 127/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9977 - loss: 0.0072\n",
      "Epoch 127: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9881 - val_loss: 0.0426\n",
      "Epoch 128/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.2150e-04\n",
      "Epoch 128: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.2015e-04 - val_accuracy: 0.9909 - val_loss: 0.0352\n",
      "Epoch 129/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.9662e-05\n",
      "Epoch 129: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.9628e-05 - val_accuracy: 0.9901 - val_loss: 0.0364\n",
      "Epoch 130/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.8190e-05\n",
      "Epoch 130: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.8155e-05 - val_accuracy: 0.9901 - val_loss: 0.0376\n",
      "Epoch 131/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.2832e-05\n",
      "Epoch 131: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.2812e-05 - val_accuracy: 0.9901 - val_loss: 0.0385\n",
      "Epoch 132/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.4008e-05\n",
      "Epoch 132: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.3988e-05 - val_accuracy: 0.9905 - val_loss: 0.0393\n",
      "Epoch 133/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8196e-05\n",
      "Epoch 133: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.8186e-05 - val_accuracy: 0.9905 - val_loss: 0.0401\n",
      "Epoch 134/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4119e-05\n",
      "Epoch 134: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4109e-05 - val_accuracy: 0.9909 - val_loss: 0.0408\n",
      "Epoch 135/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.1109e-05\n",
      "Epoch 135: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1104e-05 - val_accuracy: 0.9909 - val_loss: 0.0416\n",
      "Epoch 136/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.8341e-06\n",
      "Epoch 136: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.8296e-06 - val_accuracy: 0.9909 - val_loss: 0.0423\n",
      "Epoch 137/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.9421e-06\n",
      "Epoch 137: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.9386e-06 - val_accuracy: 0.9914 - val_loss: 0.0431\n",
      "Epoch 138/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.1867e-06\n",
      "Epoch 138: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.1839e-06 - val_accuracy: 0.9914 - val_loss: 0.0438\n",
      "Epoch 139/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.9661e-06\n",
      "Epoch 139: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.9640e-06 - val_accuracy: 0.9918 - val_loss: 0.0446\n",
      "Epoch 140/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.1436e-06\n",
      "Epoch 140: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.1418e-06 - val_accuracy: 0.9922 - val_loss: 0.0455\n",
      "Epoch 141/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4583e-06\n",
      "Epoch 141: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4568e-06 - val_accuracy: 0.9922 - val_loss: 0.0468\n",
      "Epoch 142/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.8682e-06\n",
      "Epoch 142: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8677e-06 - val_accuracy: 0.9922 - val_loss: 0.0480\n",
      "Epoch 143/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4210e-06\n",
      "Epoch 143: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4206e-06 - val_accuracy: 0.9918 - val_loss: 0.0492\n",
      "Epoch 144/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1003e-06\n",
      "Epoch 144: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0998e-06 - val_accuracy: 0.9918 - val_loss: 0.0502\n",
      "Epoch 145/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.5842e-07\n",
      "Epoch 145: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.5810e-07 - val_accuracy: 0.9918 - val_loss: 0.0513\n",
      "Epoch 146/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.8674e-07\n",
      "Epoch 146: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.8652e-07 - val_accuracy: 0.9918 - val_loss: 0.0523\n",
      "Epoch 147/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.5747e-07\n",
      "Epoch 147: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.5731e-07 - val_accuracy: 0.9918 - val_loss: 0.0532\n",
      "Epoch 148/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.5946e-07\n",
      "Epoch 148: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.5934e-07 - val_accuracy: 0.9922 - val_loss: 0.0541\n",
      "Epoch 149/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.8150e-07\n",
      "Epoch 149: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.8140e-07 - val_accuracy: 0.9922 - val_loss: 0.0549\n",
      "Epoch 150/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.1976e-07\n",
      "Epoch 150: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.1964e-07 - val_accuracy: 0.9922 - val_loss: 0.0558\n",
      "Epoch 151/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.6908e-07\n",
      "Epoch 151: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.6899e-07 - val_accuracy: 0.9918 - val_loss: 0.0566\n",
      "Epoch 152/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.2657e-07\n",
      "Epoch 152: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.2652e-07 - val_accuracy: 0.9918 - val_loss: 0.0574\n",
      "Epoch 153/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9179e-07\n",
      "Epoch 153: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9175e-07 - val_accuracy: 0.9918 - val_loss: 0.0582\n",
      "Epoch 154/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6241e-07\n",
      "Epoch 154: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6235e-07 - val_accuracy: 0.9918 - val_loss: 0.0589\n",
      "Epoch 155/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3757e-07\n",
      "Epoch 155: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3754e-07 - val_accuracy: 0.9918 - val_loss: 0.0596\n",
      "Epoch 156/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1676e-07\n",
      "Epoch 156: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1673e-07 - val_accuracy: 0.9918 - val_loss: 0.0604\n",
      "Epoch 157/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.9462e-08\n",
      "Epoch 157: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.9429e-08 - val_accuracy: 0.9918 - val_loss: 0.0611\n",
      "Epoch 158/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.4377e-08\n",
      "Epoch 158: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.4360e-08 - val_accuracy: 0.9918 - val_loss: 0.0618\n",
      "Epoch 159/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.2002e-08\n",
      "Epoch 159: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.1980e-08 - val_accuracy: 0.9918 - val_loss: 0.0625\n",
      "Epoch 160/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.1392e-08\n",
      "Epoch 160: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.1380e-08 - val_accuracy: 0.9918 - val_loss: 0.0632\n",
      "Epoch 161/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.2264e-08\n",
      "Epoch 161: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.2252e-08 - val_accuracy: 0.9918 - val_loss: 0.0638\n",
      "Epoch 162/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4819e-08\n",
      "Epoch 162: val_accuracy did not improve from 0.99259\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.4804e-08 - val_accuracy: 0.9918 - val_loss: 0.0645\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m14/76\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:38:35.621542: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-04 14:38:35.622417: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8569e-10\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0478\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9919 - loss: 0.0617\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:38:41.172659: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 14:38:41.173005: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5031 - loss: 1.2959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:38:50.856476: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 14:38:50.856776: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85056, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.5050 - loss: 1.2911 - val_accuracy: 0.8506 - val_loss: 0.3511\n",
      "Epoch 2/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8441 - loss: 0.3597\n",
      "Epoch 2: val_accuracy improved from 0.85056 to 0.87196, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8441 - loss: 0.3596 - val_accuracy: 0.8720 - val_loss: 0.2884\n",
      "Epoch 3/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8731 - loss: 0.2855\n",
      "Epoch 3: val_accuracy improved from 0.87196 to 0.89090, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8731 - loss: 0.2854 - val_accuracy: 0.8909 - val_loss: 0.2369\n",
      "Epoch 4/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8797 - loss: 0.2631\n",
      "Epoch 4: val_accuracy improved from 0.89090 to 0.89708, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8797 - loss: 0.2631 - val_accuracy: 0.8971 - val_loss: 0.2377\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9034 - loss: 0.2172\n",
      "Epoch 5: val_accuracy improved from 0.89708 to 0.90613, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9034 - loss: 0.2173 - val_accuracy: 0.9061 - val_loss: 0.2193\n",
      "Epoch 6/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9106 - loss: 0.1985\n",
      "Epoch 6: val_accuracy improved from 0.90613 to 0.92837, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9107 - loss: 0.1985 - val_accuracy: 0.9284 - val_loss: 0.1574\n",
      "Epoch 7/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9293 - loss: 0.1636\n",
      "Epoch 7: val_accuracy did not improve from 0.92837\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9293 - loss: 0.1636 - val_accuracy: 0.9057 - val_loss: 0.2968\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9276 - loss: 0.1819\n",
      "Epoch 8: val_accuracy improved from 0.92837 to 0.93207, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9277 - loss: 0.1818 - val_accuracy: 0.9321 - val_loss: 0.1390\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9536 - loss: 0.1191\n",
      "Epoch 9: val_accuracy did not improve from 0.93207\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9536 - loss: 0.1190 - val_accuracy: 0.9300 - val_loss: 0.1640\n",
      "Epoch 10/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9618 - loss: 0.0972\n",
      "Epoch 10: val_accuracy improved from 0.93207 to 0.93495, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9618 - loss: 0.0972 - val_accuracy: 0.9350 - val_loss: 0.1700\n",
      "Epoch 11/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9678 - loss: 0.0754\n",
      "Epoch 11: val_accuracy improved from 0.93495 to 0.93536, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9679 - loss: 0.0753 - val_accuracy: 0.9354 - val_loss: 0.1645\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9704 - loss: 0.0731\n",
      "Epoch 12: val_accuracy improved from 0.93536 to 0.94072, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9704 - loss: 0.0730 - val_accuracy: 0.9407 - val_loss: 0.1577\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9783 - loss: 0.0547\n",
      "Epoch 13: val_accuracy improved from 0.94072 to 0.94195, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9783 - loss: 0.0547 - val_accuracy: 0.9420 - val_loss: 0.1562\n",
      "Epoch 14/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9813 - loss: 0.0511\n",
      "Epoch 14: val_accuracy improved from 0.94195 to 0.96624, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9813 - loss: 0.0513 - val_accuracy: 0.9662 - val_loss: 0.0866\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0437\n",
      "Epoch 15: val_accuracy did not improve from 0.96624\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0437 - val_accuracy: 0.9625 - val_loss: 0.1146\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9880 - loss: 0.0345\n",
      "Epoch 16: val_accuracy improved from 0.96624 to 0.97859, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9880 - loss: 0.0345 - val_accuracy: 0.9786 - val_loss: 0.0624\n",
      "Epoch 17/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9858 - loss: 0.0436\n",
      "Epoch 17: val_accuracy improved from 0.97859 to 0.98147, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9858 - loss: 0.0436 - val_accuracy: 0.9815 - val_loss: 0.0624\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9843 - loss: 0.0403\n",
      "Epoch 18: val_accuracy did not improve from 0.98147\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9843 - loss: 0.0403 - val_accuracy: 0.9699 - val_loss: 0.0916\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9843 - loss: 0.0403\n",
      "Epoch 19: val_accuracy improved from 0.98147 to 0.98806, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9844 - loss: 0.0402 - val_accuracy: 0.9881 - val_loss: 0.0396\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9824 - loss: 0.0594\n",
      "Epoch 20: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9824 - loss: 0.0594 - val_accuracy: 0.9765 - val_loss: 0.0737\n",
      "Epoch 21/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9948 - loss: 0.0179\n",
      "Epoch 21: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.0179 - val_accuracy: 0.9728 - val_loss: 0.0963\n",
      "Epoch 22/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9909 - loss: 0.0250\n",
      "Epoch 22: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9909 - loss: 0.0250 - val_accuracy: 0.9852 - val_loss: 0.0443\n",
      "Epoch 23/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9896 - loss: 0.0336\n",
      "Epoch 23: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9896 - loss: 0.0335 - val_accuracy: 0.9741 - val_loss: 0.0824\n",
      "Epoch 24/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9872 - loss: 0.0409\n",
      "Epoch 24: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9872 - loss: 0.0409 - val_accuracy: 0.9819 - val_loss: 0.0580\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9938 - loss: 0.0151\n",
      "Epoch 25: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9938 - loss: 0.0151 - val_accuracy: 0.9679 - val_loss: 0.0967\n",
      "Epoch 26/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9957 - loss: 0.0119\n",
      "Epoch 26: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 0.9823 - val_loss: 0.0629\n",
      "Epoch 27/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9958 - loss: 0.0107\n",
      "Epoch 27: val_accuracy improved from 0.98806 to 0.98888, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9958 - loss: 0.0107 - val_accuracy: 0.9889 - val_loss: 0.0400\n",
      "Epoch 28/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9963 - loss: 0.0144\n",
      "Epoch 28: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9963 - loss: 0.0144 - val_accuracy: 0.9753 - val_loss: 0.0844\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9952 - loss: 0.0154\n",
      "Epoch 29: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9952 - loss: 0.0153 - val_accuracy: 0.9502 - val_loss: 0.2101\n",
      "Epoch 30/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0057\n",
      "Epoch 30: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9835 - val_loss: 0.0646\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9942 - loss: 0.0169\n",
      "Epoch 31: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9942 - loss: 0.0169 - val_accuracy: 0.9835 - val_loss: 0.0554\n",
      "Epoch 32/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.2135e-04\n",
      "Epoch 32: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.2057e-04 - val_accuracy: 0.9860 - val_loss: 0.0565\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.7682e-05\n",
      "Epoch 33: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.7477e-05 - val_accuracy: 0.9864 - val_loss: 0.0580\n",
      "Epoch 34/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.7806e-05\n",
      "Epoch 34: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.7710e-05 - val_accuracy: 0.9864 - val_loss: 0.0602\n",
      "Epoch 35/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9618e-05\n",
      "Epoch 35: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9582e-05 - val_accuracy: 0.9872 - val_loss: 0.0612\n",
      "Epoch 36/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0695e-05\n",
      "Epoch 36: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0684e-05 - val_accuracy: 0.9872 - val_loss: 0.0616\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5523e-05\n",
      "Epoch 37: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5508e-05 - val_accuracy: 0.9868 - val_loss: 0.0621\n",
      "Epoch 38/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2039e-05\n",
      "Epoch 38: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2028e-05 - val_accuracy: 0.9868 - val_loss: 0.0624\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.5424e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.5344e-06 - val_accuracy: 0.9868 - val_loss: 0.0629\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.6619e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.6561e-06 - val_accuracy: 0.9868 - val_loss: 0.0635\n",
      "Epoch 41/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.1946e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.1903e-06 - val_accuracy: 0.9872 - val_loss: 0.0642\n",
      "Epoch 42/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.0777e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.0744e-06 - val_accuracy: 0.9872 - val_loss: 0.0649\n",
      "Epoch 43/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.2030e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.1992e-06 - val_accuracy: 0.9872 - val_loss: 0.0656\n",
      "Epoch 44/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.5054e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.5033e-06 - val_accuracy: 0.9872 - val_loss: 0.0663\n",
      "Epoch 45/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.9278e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9262e-06 - val_accuracy: 0.9868 - val_loss: 0.0670\n",
      "Epoch 46/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.4631e-06\n",
      "Epoch 46: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4619e-06 - val_accuracy: 0.9872 - val_loss: 0.0677\n",
      "Epoch 47/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0742e-06\n",
      "Epoch 47: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0731e-06 - val_accuracy: 0.9872 - val_loss: 0.0685\n",
      "Epoch 48/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.7559e-06\n",
      "Epoch 48: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7551e-06 - val_accuracy: 0.9872 - val_loss: 0.0693\n",
      "Epoch 49/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4877e-06\n",
      "Epoch 49: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4866e-06 - val_accuracy: 0.9872 - val_loss: 0.0700\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2650e-06\n",
      "Epoch 50: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2644e-06 - val_accuracy: 0.9876 - val_loss: 0.0707\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.0747e-06\n",
      "Epoch 51: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0741e-06 - val_accuracy: 0.9876 - val_loss: 0.0715\n",
      "Epoch 52/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.1422e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.1351e-07 - val_accuracy: 0.9872 - val_loss: 0.0723\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.7910e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.7868e-07 - val_accuracy: 0.9868 - val_loss: 0.0730\n",
      "Epoch 54/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.6315e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.6279e-07 - val_accuracy: 0.9868 - val_loss: 0.0737\n",
      "Epoch 55/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.6383e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.6351e-07 - val_accuracy: 0.9864 - val_loss: 0.0745\n",
      "Epoch 56/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.7879e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.7852e-07 - val_accuracy: 0.9864 - val_loss: 0.0752\n",
      "Epoch 57/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.0842e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.0818e-07 - val_accuracy: 0.9860 - val_loss: 0.0760\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.4497e-07\n",
      "Epoch 58: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.4476e-07 - val_accuracy: 0.9860 - val_loss: 0.0766\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9042e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9025e-07 - val_accuracy: 0.9856 - val_loss: 0.0773\n",
      "Epoch 60/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4570e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4555e-07 - val_accuracy: 0.9856 - val_loss: 0.0781\n",
      "Epoch 61/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0769e-07\n",
      "Epoch 61: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0751e-07 - val_accuracy: 0.9860 - val_loss: 0.0788\n",
      "Epoch 62/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7497e-07\n",
      "Epoch 62: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7481e-07 - val_accuracy: 0.9860 - val_loss: 0.0795\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4781e-07\n",
      "Epoch 63: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4772e-07 - val_accuracy: 0.9864 - val_loss: 0.0803\n",
      "Epoch 64/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2477e-07\n",
      "Epoch 64: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2470e-07 - val_accuracy: 0.9864 - val_loss: 0.0810\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0535e-07\n",
      "Epoch 65: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0529e-07 - val_accuracy: 0.9864 - val_loss: 0.0817\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.9449e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.9397e-08 - val_accuracy: 0.9864 - val_loss: 0.0824\n",
      "Epoch 67/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.6176e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.6111e-08 - val_accuracy: 0.9864 - val_loss: 0.0832\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.4772e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.4735e-08 - val_accuracy: 0.9864 - val_loss: 0.0840\n",
      "Epoch 69/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.5451e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.5418e-08 - val_accuracy: 0.9864 - val_loss: 0.0848\n",
      "Epoch 70/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.6957e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6930e-08 - val_accuracy: 0.9868 - val_loss: 0.0855\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0242e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.0219e-08 - val_accuracy: 0.9868 - val_loss: 0.0862\n",
      "Epoch 72/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.4386e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.4356e-08 - val_accuracy: 0.9868 - val_loss: 0.0869\n",
      "Epoch 73/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9278e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9261e-08 - val_accuracy: 0.9868 - val_loss: 0.0876\n",
      "Epoch 74/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.5203e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5187e-08 - val_accuracy: 0.9868 - val_loss: 0.0883\n",
      "Epoch 75/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1541e-08\n",
      "Epoch 75: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1529e-08 - val_accuracy: 0.9868 - val_loss: 0.0889\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8624e-08\n",
      "Epoch 76: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8613e-08 - val_accuracy: 0.9868 - val_loss: 0.0896\n",
      "Epoch 77/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5996e-08\n",
      "Epoch 77: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5986e-08 - val_accuracy: 0.9868 - val_loss: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n",
      "Best model loaded successfully!\n",
      "\u001b[1m14/76\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:50:51.427817: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-04 14:50:51.428652: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0034\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0393\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0396\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:50:56.656322: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 14:50:56.656608: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4881 - loss: 1.3582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:51:07.402412: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 14:51:07.402714: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.81103, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.4894 - loss: 1.3550 - val_accuracy: 0.8110 - val_loss: 0.4865\n",
      "Epoch 2/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8089 - loss: 0.4314\n",
      "Epoch 2: val_accuracy improved from 0.81103 to 0.84315, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8091 - loss: 0.4311 - val_accuracy: 0.8431 - val_loss: 0.3806\n",
      "Epoch 3/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8559 - loss: 0.3127\n",
      "Epoch 3: val_accuracy did not improve from 0.84315\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8560 - loss: 0.3125 - val_accuracy: 0.8275 - val_loss: 0.4066\n",
      "Epoch 4/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8752 - loss: 0.2614\n",
      "Epoch 4: val_accuracy improved from 0.84315 to 0.86291, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.8752 - loss: 0.2613 - val_accuracy: 0.8629 - val_loss: 0.3255\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8883 - loss: 0.2336\n",
      "Epoch 5: val_accuracy improved from 0.86291 to 0.88843, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8883 - loss: 0.2337 - val_accuracy: 0.8884 - val_loss: 0.2386\n",
      "Epoch 6/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9044 - loss: 0.2012\n",
      "Epoch 6: val_accuracy improved from 0.88843 to 0.91807, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9044 - loss: 0.2011 - val_accuracy: 0.9181 - val_loss: 0.1959\n",
      "Epoch 7/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9144 - loss: 0.1882\n",
      "Epoch 7: val_accuracy improved from 0.91807 to 0.91848, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9145 - loss: 0.1881 - val_accuracy: 0.9185 - val_loss: 0.2219\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9296 - loss: 0.1602\n",
      "Epoch 8: val_accuracy improved from 0.91848 to 0.95389, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9297 - loss: 0.1601 - val_accuracy: 0.9539 - val_loss: 0.1224\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9348 - loss: 0.1510\n",
      "Epoch 9: val_accuracy improved from 0.95389 to 0.96212, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9348 - loss: 0.1509 - val_accuracy: 0.9621 - val_loss: 0.1137\n",
      "Epoch 10/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9548 - loss: 0.1129\n",
      "Epoch 10: val_accuracy did not improve from 0.96212\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9549 - loss: 0.1128 - val_accuracy: 0.9555 - val_loss: 0.1176\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9597 - loss: 0.1080\n",
      "Epoch 11: val_accuracy did not improve from 0.96212\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9597 - loss: 0.1079 - val_accuracy: 0.9494 - val_loss: 0.1557\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9652 - loss: 0.0893\n",
      "Epoch 12: val_accuracy did not improve from 0.96212\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9652 - loss: 0.0893 - val_accuracy: 0.9551 - val_loss: 0.1115\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9821 - loss: 0.0484\n",
      "Epoch 13: val_accuracy improved from 0.96212 to 0.96995, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9822 - loss: 0.0484 - val_accuracy: 0.9699 - val_loss: 0.0762\n",
      "Epoch 14/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9886 - loss: 0.0373\n",
      "Epoch 14: val_accuracy improved from 0.96995 to 0.97736, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9886 - loss: 0.0373 - val_accuracy: 0.9774 - val_loss: 0.0754\n",
      "Epoch 15/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9864 - loss: 0.0430\n",
      "Epoch 15: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9865 - loss: 0.0429 - val_accuracy: 0.9741 - val_loss: 0.0797\n",
      "Epoch 16/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9886 - loss: 0.0335\n",
      "Epoch 16: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9886 - loss: 0.0336 - val_accuracy: 0.9592 - val_loss: 0.1269\n",
      "Epoch 17/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9791 - loss: 0.0680\n",
      "Epoch 17: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9791 - loss: 0.0679 - val_accuracy: 0.9732 - val_loss: 0.0735\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9872 - loss: 0.0360\n",
      "Epoch 18: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9872 - loss: 0.0359 - val_accuracy: 0.9720 - val_loss: 0.0878\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9947 - loss: 0.0171\n",
      "Epoch 19: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.9469 - val_loss: 0.1680\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9881 - loss: 0.0423\n",
      "Epoch 20: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9881 - loss: 0.0424 - val_accuracy: 0.9699 - val_loss: 0.0929\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9949 - loss: 0.0163\n",
      "Epoch 21: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.9535 - val_loss: 0.1434\n",
      "Epoch 22/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.0574\n",
      "Epoch 22: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9831 - loss: 0.0572 - val_accuracy: 0.9761 - val_loss: 0.0636\n",
      "Epoch 23/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9948 - loss: 0.0159\n",
      "Epoch 23: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9948 - loss: 0.0159 - val_accuracy: 0.9539 - val_loss: 0.1691\n",
      "Epoch 24/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9952 - loss: 0.0135\n",
      "Epoch 24: val_accuracy did not improve from 0.97736\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9952 - loss: 0.0135 - val_accuracy: 0.9695 - val_loss: 0.0980\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9960 - loss: 0.0135\n",
      "Epoch 25: val_accuracy improved from 0.97736 to 0.98518, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.9852 - val_loss: 0.0540\n",
      "Epoch 26/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9923 - loss: 0.0187\n",
      "Epoch 26: val_accuracy did not improve from 0.98518\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9924 - loss: 0.0187 - val_accuracy: 0.9827 - val_loss: 0.0696\n",
      "Epoch 27/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9978 - loss: 0.0076\n",
      "Epoch 27: val_accuracy did not improve from 0.98518\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9848 - val_loss: 0.0632\n",
      "Epoch 28/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.8036e-04\n",
      "Epoch 28: val_accuracy did not improve from 0.98518\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.7611e-04 - val_accuracy: 0.9815 - val_loss: 0.0804\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.0021e-04\n",
      "Epoch 29: val_accuracy improved from 0.98518 to 0.98559, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.9935e-04 - val_accuracy: 0.9856 - val_loss: 0.0637\n",
      "Epoch 30/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0513e-04\n",
      "Epoch 30: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0500e-04 - val_accuracy: 0.9852 - val_loss: 0.0650\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.0279e-05\n",
      "Epoch 31: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.0237e-05 - val_accuracy: 0.9844 - val_loss: 0.0668\n",
      "Epoch 32/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.0299e-05\n",
      "Epoch 32: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.0263e-05 - val_accuracy: 0.9844 - val_loss: 0.0688\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.8295e-05\n",
      "Epoch 33: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.8270e-05 - val_accuracy: 0.9848 - val_loss: 0.0704\n",
      "Epoch 34/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.9965e-05\n",
      "Epoch 34: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.9947e-05 - val_accuracy: 0.9848 - val_loss: 0.0719\n",
      "Epoch 35/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3909e-05\n",
      "Epoch 35: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.3901e-05 - val_accuracy: 0.9848 - val_loss: 0.0734\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9286e-05\n",
      "Epoch 36: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9275e-05 - val_accuracy: 0.9848 - val_loss: 0.0747\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5660e-05\n",
      "Epoch 37: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5651e-05 - val_accuracy: 0.9848 - val_loss: 0.0759\n",
      "Epoch 38/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2795e-05\n",
      "Epoch 38: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2784e-05 - val_accuracy: 0.9848 - val_loss: 0.0772\n",
      "Epoch 39/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0575e-05\n",
      "Epoch 39: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0566e-05 - val_accuracy: 0.9852 - val_loss: 0.0786\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.7706e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.7661e-06 - val_accuracy: 0.9852 - val_loss: 0.0799\n",
      "Epoch 41/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.2921e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.2865e-06 - val_accuracy: 0.9856 - val_loss: 0.0813\n",
      "Epoch 42/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.0615e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.0600e-06 - val_accuracy: 0.9856 - val_loss: 0.0827\n",
      "Epoch 43/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.0647e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.0608e-06 - val_accuracy: 0.9856 - val_loss: 0.0839\n",
      "Epoch 44/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.2392e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.2359e-06 - val_accuracy: 0.9856 - val_loss: 0.0853\n",
      "Epoch 45/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.5569e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.5541e-06 - val_accuracy: 0.9856 - val_loss: 0.0866\n",
      "Epoch 46/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9745e-06\n",
      "Epoch 46: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9730e-06 - val_accuracy: 0.9856 - val_loss: 0.0879\n",
      "Epoch 47/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.4906e-06\n",
      "Epoch 47: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.4893e-06 - val_accuracy: 0.9856 - val_loss: 0.0893\n",
      "Epoch 48/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0825e-06\n",
      "Epoch 48: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0820e-06 - val_accuracy: 0.9856 - val_loss: 0.0907\n",
      "Epoch 49/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7488e-06\n",
      "Epoch 49: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7478e-06 - val_accuracy: 0.9856 - val_loss: 0.0920\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.4633e-06\n",
      "Epoch 50: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4625e-06 - val_accuracy: 0.9856 - val_loss: 0.0934\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2293e-06\n",
      "Epoch 51: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2286e-06 - val_accuracy: 0.9856 - val_loss: 0.0948\n",
      "Epoch 52/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0309e-06\n",
      "Epoch 52: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0301e-06 - val_accuracy: 0.9856 - val_loss: 0.0962\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.6316e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.6269e-07 - val_accuracy: 0.9856 - val_loss: 0.0978\n",
      "Epoch 54/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.2533e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.2471e-07 - val_accuracy: 0.9856 - val_loss: 0.0992\n",
      "Epoch 55/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.0694e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.0659e-07 - val_accuracy: 0.9856 - val_loss: 0.1006\n",
      "Epoch 56/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.0956e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.0927e-07 - val_accuracy: 0.9856 - val_loss: 0.1022\n",
      "Epoch 57/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.2810e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.98559\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2798e-07 - val_accuracy: 0.9856 - val_loss: 0.1037\n",
      "Epoch 58/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.5936e-07\n",
      "Epoch 58: val_accuracy improved from 0.98559 to 0.98600, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.5926e-07 - val_accuracy: 0.9860 - val_loss: 0.1051\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.0382e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.0365e-07 - val_accuracy: 0.9860 - val_loss: 0.1065\n",
      "Epoch 60/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.5468e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.5454e-07 - val_accuracy: 0.9860 - val_loss: 0.1080\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.1459e-07\n",
      "Epoch 61: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.1447e-07 - val_accuracy: 0.9860 - val_loss: 0.1094\n",
      "Epoch 62/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.8115e-07\n",
      "Epoch 62: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8100e-07 - val_accuracy: 0.9860 - val_loss: 0.1107\n",
      "Epoch 63/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5313e-07\n",
      "Epoch 63: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5301e-07 - val_accuracy: 0.9860 - val_loss: 0.1122\n",
      "Epoch 64/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2952e-07\n",
      "Epoch 64: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2944e-07 - val_accuracy: 0.9860 - val_loss: 0.1136\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0919e-07\n",
      "Epoch 65: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0913e-07 - val_accuracy: 0.9860 - val_loss: 0.1150\n",
      "Epoch 66/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.2319e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.2292e-08 - val_accuracy: 0.9860 - val_loss: 0.1164\n",
      "Epoch 67/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.7797e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.7731e-08 - val_accuracy: 0.9860 - val_loss: 0.1177\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.6271e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.6232e-08 - val_accuracy: 0.9860 - val_loss: 0.1191\n",
      "Epoch 69/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.5863e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.5831e-08 - val_accuracy: 0.9860 - val_loss: 0.1204\n",
      "Epoch 70/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.7569e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.7527e-08 - val_accuracy: 0.9860 - val_loss: 0.1219\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.0293e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.0269e-08 - val_accuracy: 0.9860 - val_loss: 0.1231\n",
      "Epoch 72/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.3878e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.3858e-08 - val_accuracy: 0.9860 - val_loss: 0.1244\n",
      "Epoch 73/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8654e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.8638e-08 - val_accuracy: 0.9856 - val_loss: 0.1258\n",
      "Epoch 74/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.4543e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.4536e-08 - val_accuracy: 0.9856 - val_loss: 0.1270\n",
      "Epoch 75/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.0882e-08\n",
      "Epoch 75: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0871e-08 - val_accuracy: 0.9856 - val_loss: 0.1283\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7768e-08\n",
      "Epoch 76: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.7759e-08 - val_accuracy: 0.9856 - val_loss: 0.1296\n",
      "Epoch 77/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.5115e-08\n",
      "Epoch 77: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5106e-08 - val_accuracy: 0.9856 - val_loss: 0.1309\n",
      "Epoch 78/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2950e-08\n",
      "Epoch 78: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2942e-08 - val_accuracy: 0.9852 - val_loss: 0.1322\n",
      "Epoch 79/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0789e-08\n",
      "Epoch 79: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0783e-08 - val_accuracy: 0.9852 - val_loss: 0.1334\n",
      "Epoch 80/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.4069e-09\n",
      "Epoch 80: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.4017e-09 - val_accuracy: 0.9852 - val_loss: 0.1345\n",
      "Epoch 81/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.9665e-09\n",
      "Epoch 81: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.9629e-09 - val_accuracy: 0.9852 - val_loss: 0.1354\n",
      "Epoch 82/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.8625e-09\n",
      "Epoch 82: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.8593e-09 - val_accuracy: 0.9852 - val_loss: 0.1367\n",
      "Epoch 83/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.6881e-09\n",
      "Epoch 83: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.6861e-09 - val_accuracy: 0.9852 - val_loss: 0.1377\n",
      "Epoch 84/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.0894e-09\n",
      "Epoch 84: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.0870e-09 - val_accuracy: 0.9852 - val_loss: 0.1387\n",
      "Epoch 85/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.2273e-09\n",
      "Epoch 85: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.2257e-09 - val_accuracy: 0.9852 - val_loss: 0.1396\n",
      "Epoch 86/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.6478e-09\n",
      "Epoch 86: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.6460e-09 - val_accuracy: 0.9852 - val_loss: 0.1404\n",
      "Epoch 87/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.1204e-09\n",
      "Epoch 87: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.1188e-09 - val_accuracy: 0.9852 - val_loss: 0.1411\n",
      "Epoch 88/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.8473e-09\n",
      "Epoch 88: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.8466e-09 - val_accuracy: 0.9852 - val_loss: 0.1420\n",
      "Epoch 89/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 1.0000 - loss: 2.3409e-09\n",
      "Epoch 89: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 660ms/step - accuracy: 1.0000 - loss: 2.3407e-09 - val_accuracy: 0.9852 - val_loss: 0.1429\n",
      "Epoch 90/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.9913e-09\n",
      "Epoch 90: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9912e-09 - val_accuracy: 0.9852 - val_loss: 0.1440\n",
      "Epoch 91/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6228e-09\n",
      "Epoch 91: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6226e-09 - val_accuracy: 0.9856 - val_loss: 0.1442\n",
      "Epoch 92/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.5015e-09\n",
      "Epoch 92: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5010e-09 - val_accuracy: 0.9856 - val_loss: 0.1447\n",
      "Epoch 93/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.3223e-09\n",
      "Epoch 93: val_accuracy did not improve from 0.98600\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.3220e-09 - val_accuracy: 0.9860 - val_loss: 0.1449\n",
      "Epoch 94/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1612e-09\n",
      "Epoch 94: val_accuracy improved from 0.98600 to 0.98641, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1598e-09 - val_accuracy: 0.9864 - val_loss: 0.1446\n",
      "Epoch 95/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.0541e-09\n",
      "Epoch 95: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0529e-09 - val_accuracy: 0.9864 - val_loss: 0.1446\n",
      "Epoch 96/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.7640e-10\n",
      "Epoch 96: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.7646e-10 - val_accuracy: 0.9860 - val_loss: 0.1450\n",
      "Epoch 97/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.0430e-10\n",
      "Epoch 97: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.0438e-10 - val_accuracy: 0.9860 - val_loss: 0.1451\n",
      "Epoch 98/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.3770e-10\n",
      "Epoch 98: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.3785e-10 - val_accuracy: 0.9860 - val_loss: 0.1453\n",
      "Epoch 99/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.2493e-10\n",
      "Epoch 99: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.2470e-10 - val_accuracy: 0.9860 - val_loss: 0.1451\n",
      "Epoch 100/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.5301e-10\n",
      "Epoch 100: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.5294e-10 - val_accuracy: 0.9860 - val_loss: 0.1443\n",
      "Epoch 101/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2429e-10\n",
      "Epoch 101: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.2399e-10 - val_accuracy: 0.9860 - val_loss: 0.1445\n",
      "Epoch 102/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.6970e-10\n",
      "Epoch 102: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.6931e-10 - val_accuracy: 0.9860 - val_loss: 0.1446\n",
      "Epoch 103/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.4985e-10\n",
      "Epoch 103: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.5039e-10 - val_accuracy: 0.9860 - val_loss: 0.1436\n",
      "Epoch 104/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.1518e-10\n",
      "Epoch 104: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.1545e-10 - val_accuracy: 0.9860 - val_loss: 0.1444\n",
      "Epoch 105/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.0475e-10\n",
      "Epoch 105: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.0461e-10 - val_accuracy: 0.9860 - val_loss: 0.1456\n",
      "Epoch 106/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.2129e-10\n",
      "Epoch 106: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.2139e-10 - val_accuracy: 0.9860 - val_loss: 0.1440\n",
      "Epoch 107/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.2075e-10\n",
      "Epoch 107: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.2075e-10 - val_accuracy: 0.9864 - val_loss: 0.1456\n",
      "Epoch 108/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5603e-10\n",
      "Epoch 108: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5643e-10 - val_accuracy: 0.9864 - val_loss: 0.1462\n",
      "Epoch 109/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.2657e-10\n",
      "Epoch 109: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2652e-10 - val_accuracy: 0.9864 - val_loss: 0.1452\n",
      "Epoch 110/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5297e-10\n",
      "Epoch 110: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5325e-10 - val_accuracy: 0.9860 - val_loss: 0.1461\n",
      "Epoch 111/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8077e-10\n",
      "Epoch 111: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.8054e-10 - val_accuracy: 0.9860 - val_loss: 0.1473\n",
      "Epoch 112/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9898 - loss: 0.0761\n",
      "Epoch 112: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9897 - loss: 0.0769 - val_accuracy: 0.9564 - val_loss: 0.1201\n",
      "Epoch 113/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9938 - loss: 0.0195\n",
      "Epoch 113: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9938 - loss: 0.0194 - val_accuracy: 0.9807 - val_loss: 0.0676\n",
      "Epoch 114/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0064\n",
      "Epoch 114: val_accuracy did not improve from 0.98641\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9794 - val_loss: 0.0928\n",
      "Epoch 115/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 115: val_accuracy improved from 0.98641 to 0.98724, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9872 - val_loss: 0.0712\n",
      "Epoch 116/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.8925e-04\n",
      "Epoch 116: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8904e-04 - val_accuracy: 0.9864 - val_loss: 0.0731\n",
      "Epoch 117/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1738e-04\n",
      "Epoch 117: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1734e-04 - val_accuracy: 0.9868 - val_loss: 0.0758\n",
      "Epoch 118/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.5343e-05\n",
      "Epoch 118: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.5328e-05 - val_accuracy: 0.9868 - val_loss: 0.0782\n",
      "Epoch 119/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.5079e-05\n",
      "Epoch 119: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.5067e-05 - val_accuracy: 0.9868 - val_loss: 0.0805\n",
      "Epoch 120/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.0922e-05\n",
      "Epoch 120: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.0915e-05 - val_accuracy: 0.9868 - val_loss: 0.0826\n",
      "Epoch 121/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0568e-05\n",
      "Epoch 121: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.0564e-05 - val_accuracy: 0.9856 - val_loss: 0.0845\n",
      "Epoch 122/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.2698e-05\n",
      "Epoch 122: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.2696e-05 - val_accuracy: 0.9856 - val_loss: 0.0863\n",
      "Epoch 123/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.6673e-05\n",
      "Epoch 123: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.6671e-05 - val_accuracy: 0.9864 - val_loss: 0.0881\n",
      "Epoch 124/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1832e-05\n",
      "Epoch 124: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1831e-05 - val_accuracy: 0.9864 - val_loss: 0.0897\n",
      "Epoch 125/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7934e-05\n",
      "Epoch 125: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7932e-05 - val_accuracy: 0.9860 - val_loss: 0.0914\n",
      "Epoch 126/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4813e-05\n",
      "Epoch 126: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4811e-05 - val_accuracy: 0.9860 - val_loss: 0.0932\n",
      "Epoch 127/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2228e-05\n",
      "Epoch 127: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2227e-05 - val_accuracy: 0.9860 - val_loss: 0.0947\n",
      "Epoch 128/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0130e-05\n",
      "Epoch 128: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0129e-05 - val_accuracy: 0.9860 - val_loss: 0.0965\n",
      "Epoch 129/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.4166e-06\n",
      "Epoch 129: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.4156e-06 - val_accuracy: 0.9864 - val_loss: 0.0982\n",
      "Epoch 130/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.0048e-06\n",
      "Epoch 130: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.0039e-06 - val_accuracy: 0.9864 - val_loss: 0.1001\n",
      "Epoch 131/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.8355e-06\n",
      "Epoch 131: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.8347e-06 - val_accuracy: 0.9868 - val_loss: 0.1015\n",
      "Epoch 132/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.8618e-06\n",
      "Epoch 132: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.8610e-06 - val_accuracy: 0.9868 - val_loss: 0.1033\n",
      "Epoch 133/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0582e-06\n",
      "Epoch 133: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.0575e-06 - val_accuracy: 0.9868 - val_loss: 0.1052\n",
      "Epoch 134/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.3983e-06\n",
      "Epoch 134: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.3973e-06 - val_accuracy: 0.9868 - val_loss: 0.1070\n",
      "Epoch 135/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8451e-06\n",
      "Epoch 135: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.8445e-06 - val_accuracy: 0.9872 - val_loss: 0.1088\n",
      "Epoch 136/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3855e-06\n",
      "Epoch 136: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.3847e-06 - val_accuracy: 0.9872 - val_loss: 0.1107\n",
      "Epoch 137/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.0011e-06\n",
      "Epoch 137: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.0004e-06 - val_accuracy: 0.9872 - val_loss: 0.1122\n",
      "Epoch 138/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6731e-06\n",
      "Epoch 138: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6727e-06 - val_accuracy: 0.9872 - val_loss: 0.1141\n",
      "Epoch 139/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4070e-06\n",
      "Epoch 139: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4066e-06 - val_accuracy: 0.9872 - val_loss: 0.1159\n",
      "Epoch 140/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1814e-06\n",
      "Epoch 140: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1811e-06 - val_accuracy: 0.9872 - val_loss: 0.1175\n",
      "Epoch 141/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.9246e-07\n",
      "Epoch 141: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.9214e-07 - val_accuracy: 0.9872 - val_loss: 0.1194\n",
      "Epoch 142/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.3480e-07\n",
      "Epoch 142: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.3452e-07 - val_accuracy: 0.9872 - val_loss: 0.1213\n",
      "Epoch 143/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.0169e-07\n",
      "Epoch 143: val_accuracy did not improve from 0.98724\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.0145e-07 - val_accuracy: 0.9872 - val_loss: 0.1231\n",
      "Epoch 144/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.8873e-07\n",
      "Epoch 144: val_accuracy improved from 0.98724 to 0.98765, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.8851e-07 - val_accuracy: 0.9876 - val_loss: 0.1251\n",
      "Epoch 145/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.9530e-07\n",
      "Epoch 145: val_accuracy improved from 0.98765 to 0.98806, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.9512e-07 - val_accuracy: 0.9881 - val_loss: 0.1268\n",
      "Epoch 146/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.1718e-07\n",
      "Epoch 146: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.1702e-07 - val_accuracy: 0.9881 - val_loss: 0.1290\n",
      "Epoch 147/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.5163e-07\n",
      "Epoch 147: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.5143e-07 - val_accuracy: 0.9876 - val_loss: 0.1308\n",
      "Epoch 148/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.9562e-07\n",
      "Epoch 148: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9551e-07 - val_accuracy: 0.9876 - val_loss: 0.1326\n",
      "Epoch 149/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4916e-07\n",
      "Epoch 149: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4906e-07 - val_accuracy: 0.9868 - val_loss: 0.1345\n",
      "Epoch 150/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.1028e-07\n",
      "Epoch 150: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.1019e-07 - val_accuracy: 0.9868 - val_loss: 0.1362\n",
      "Epoch 151/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7705e-07\n",
      "Epoch 151: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7694e-07 - val_accuracy: 0.9868 - val_loss: 0.1378\n",
      "Epoch 152/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.4933e-07\n",
      "Epoch 152: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4927e-07 - val_accuracy: 0.9868 - val_loss: 0.1395\n",
      "Epoch 153/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2651e-07\n",
      "Epoch 153: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2646e-07 - val_accuracy: 0.9868 - val_loss: 0.1412\n",
      "Epoch 154/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0689e-07\n",
      "Epoch 154: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0684e-07 - val_accuracy: 0.9868 - val_loss: 0.1428\n",
      "Epoch 155/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.0290e-08\n",
      "Epoch 155: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.0227e-08 - val_accuracy: 0.9868 - val_loss: 0.1444\n",
      "Epoch 156/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.6478e-08\n",
      "Epoch 156: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.6442e-08 - val_accuracy: 0.9868 - val_loss: 0.1461\n",
      "Epoch 157/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.4332e-08\n",
      "Epoch 157: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.4301e-08 - val_accuracy: 0.9868 - val_loss: 0.1477\n",
      "Epoch 158/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.4749e-08\n",
      "Epoch 158: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.4722e-08 - val_accuracy: 0.9872 - val_loss: 0.1494\n",
      "Epoch 159/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.6526e-08\n",
      "Epoch 159: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6502e-08 - val_accuracy: 0.9872 - val_loss: 0.1510\n",
      "Epoch 160/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.9359e-08\n",
      "Epoch 160: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.9329e-08 - val_accuracy: 0.9868 - val_loss: 0.1526\n",
      "Epoch 161/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.3497e-08\n",
      "Epoch 161: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.3471e-08 - val_accuracy: 0.9868 - val_loss: 0.1542\n",
      "Epoch 162/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.8681e-08\n",
      "Epoch 162: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8666e-08 - val_accuracy: 0.9868 - val_loss: 0.1558\n",
      "Epoch 163/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4488e-08\n",
      "Epoch 163: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4474e-08 - val_accuracy: 0.9868 - val_loss: 0.1574\n",
      "Epoch 164/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0822e-08\n",
      "Epoch 164: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0806e-08 - val_accuracy: 0.9868 - val_loss: 0.1590\n",
      "Epoch 165/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7632e-08\n",
      "Epoch 165: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7623e-08 - val_accuracy: 0.9868 - val_loss: 0.1606\n",
      "Epoch 166/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4859e-08\n",
      "Epoch 166: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4852e-08 - val_accuracy: 0.9868 - val_loss: 0.1621\n",
      "Epoch 167/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2722e-08\n",
      "Epoch 167: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2713e-08 - val_accuracy: 0.9868 - val_loss: 0.1635\n",
      "Epoch 168/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1134e-08\n",
      "Epoch 168: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1128e-08 - val_accuracy: 0.9868 - val_loss: 0.1649\n",
      "Epoch 169/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.4355e-09\n",
      "Epoch 169: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.4304e-09 - val_accuracy: 0.9868 - val_loss: 0.1664\n",
      "Epoch 170/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.1151e-09\n",
      "Epoch 170: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.1089e-09 - val_accuracy: 0.9868 - val_loss: 0.1677\n",
      "Epoch 171/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.9404e-09\n",
      "Epoch 171: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.9367e-09 - val_accuracy: 0.9868 - val_loss: 0.1692\n",
      "Epoch 172/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.9999e-09\n",
      "Epoch 172: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.9965e-09 - val_accuracy: 0.9868 - val_loss: 0.1705\n",
      "Epoch 173/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.1111e-09\n",
      "Epoch 173: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.1083e-09 - val_accuracy: 0.9868 - val_loss: 0.1717\n",
      "Epoch 174/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.5134e-09\n",
      "Epoch 174: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.5091e-09 - val_accuracy: 0.9868 - val_loss: 0.1730\n",
      "Epoch 175/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.8776e-09\n",
      "Epoch 175: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.8746e-09 - val_accuracy: 0.9868 - val_loss: 0.1741\n",
      "Epoch 176/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.3273e-09\n",
      "Epoch 176: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.3251e-09 - val_accuracy: 0.9868 - val_loss: 0.1750\n",
      "Epoch 177/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.8515e-09\n",
      "Epoch 177: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8501e-09 - val_accuracy: 0.9868 - val_loss: 0.1760\n",
      "Epoch 178/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3763e-09\n",
      "Epoch 178: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.3754e-09 - val_accuracy: 0.9868 - val_loss: 0.1773\n",
      "Epoch 179/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1024e-09\n",
      "Epoch 179: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1015e-09 - val_accuracy: 0.9868 - val_loss: 0.1788\n",
      "Epoch 180/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7092e-09\n",
      "Epoch 180: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7088e-09 - val_accuracy: 0.9868 - val_loss: 0.1802\n",
      "Epoch 181/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5147e-09\n",
      "Epoch 181: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5142e-09 - val_accuracy: 0.9868 - val_loss: 0.1815\n",
      "Epoch 182/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3416e-09\n",
      "Epoch 182: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3405e-09 - val_accuracy: 0.9868 - val_loss: 0.1825\n",
      "Epoch 183/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1967e-09\n",
      "Epoch 183: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1956e-09 - val_accuracy: 0.9868 - val_loss: 0.1831\n",
      "Epoch 184/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.9447e-10\n",
      "Epoch 184: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.9414e-10 - val_accuracy: 0.9868 - val_loss: 0.1839\n",
      "Epoch 185/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.7444e-10\n",
      "Epoch 185: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.7451e-10 - val_accuracy: 0.9868 - val_loss: 0.1849\n",
      "Epoch 186/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.1147e-10\n",
      "Epoch 186: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.1165e-10 - val_accuracy: 0.9868 - val_loss: 0.1857\n",
      "Epoch 187/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 4.7590e-10\n",
      "Epoch 187: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.7617e-10 - val_accuracy: 0.9868 - val_loss: 0.1862\n",
      "Epoch 188/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.2474e-10\n",
      "Epoch 188: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.2504e-10 - val_accuracy: 0.9872 - val_loss: 0.1865\n",
      "Epoch 189/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.1960e-10\n",
      "Epoch 189: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.1970e-10 - val_accuracy: 0.9872 - val_loss: 0.1875\n",
      "Epoch 190/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.3451e-10\n",
      "Epoch 190: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.3433e-10 - val_accuracy: 0.9872 - val_loss: 0.1889\n",
      "Epoch 191/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.0739e-10\n",
      "Epoch 191: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.0747e-10 - val_accuracy: 0.9868 - val_loss: 0.1884\n",
      "Epoch 192/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 2.5976e-10\n",
      "Epoch 192: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 2.5958e-10 - val_accuracy: 0.9868 - val_loss: 0.1902\n",
      "Epoch 193/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8969e-10\n",
      "Epoch 193: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.8963e-10 - val_accuracy: 0.9872 - val_loss: 0.1910\n",
      "Epoch 194/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1408e-10\n",
      "Epoch 194: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1388e-10 - val_accuracy: 0.9872 - val_loss: 0.1922\n",
      "Epoch 195/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6173e-10\n",
      "Epoch 195: val_accuracy did not improve from 0.98806\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6172e-10 - val_accuracy: 0.9868 - val_loss: 0.1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n",
      "Best model loaded successfully!\n",
      "\u001b[1m 6/76\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:35:52.817054: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-04 15:35:52.818237: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2096e-07\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.1043\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0526\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:35:57.982874: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 15:35:57.983165: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4912 - loss: 1.3278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:36:07.483527: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 15:36:07.483801: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80560, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.4930 - loss: 1.3231 - val_accuracy: 0.8056 - val_loss: 0.4548\n",
      "Epoch 2/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8400 - loss: 0.3983\n",
      "Epoch 2: val_accuracy improved from 0.80560 to 0.82372, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8400 - loss: 0.3982 - val_accuracy: 0.8237 - val_loss: 0.3860\n",
      "Epoch 3/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8743 - loss: 0.2925\n",
      "Epoch 3: val_accuracy improved from 0.82372 to 0.88015, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8743 - loss: 0.2925 - val_accuracy: 0.8801 - val_loss: 0.2650\n",
      "Epoch 4/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8987 - loss: 0.2395\n",
      "Epoch 4: val_accuracy improved from 0.88015 to 0.88591, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8987 - loss: 0.2395 - val_accuracy: 0.8859 - val_loss: 0.2213\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9117 - loss: 0.1900\n",
      "Epoch 5: val_accuracy improved from 0.88591 to 0.91351, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9117 - loss: 0.1901 - val_accuracy: 0.9135 - val_loss: 0.1818\n",
      "Epoch 6/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9184 - loss: 0.1836\n",
      "Epoch 6: val_accuracy improved from 0.91351 to 0.92051, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9184 - loss: 0.1836 - val_accuracy: 0.9205 - val_loss: 0.1760\n",
      "Epoch 7/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9351 - loss: 0.1424\n",
      "Epoch 7: val_accuracy did not improve from 0.92051\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9350 - loss: 0.1426 - val_accuracy: 0.8999 - val_loss: 0.2633\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9405 - loss: 0.1386\n",
      "Epoch 8: val_accuracy improved from 0.92051 to 0.95593, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9405 - loss: 0.1385 - val_accuracy: 0.9559 - val_loss: 0.1120\n",
      "Epoch 9/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9665 - loss: 0.0859\n",
      "Epoch 9: val_accuracy improved from 0.95593 to 0.96993, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9665 - loss: 0.0860 - val_accuracy: 0.9699 - val_loss: 0.0863\n",
      "Epoch 10/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9693 - loss: 0.0856\n",
      "Epoch 10: val_accuracy did not improve from 0.96993\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9693 - loss: 0.0857 - val_accuracy: 0.9605 - val_loss: 0.1060\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9637 - loss: 0.0927\n",
      "Epoch 11: val_accuracy did not improve from 0.96993\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9637 - loss: 0.0927 - val_accuracy: 0.9230 - val_loss: 0.2543\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9701 - loss: 0.0818\n",
      "Epoch 12: val_accuracy did not improve from 0.96993\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9701 - loss: 0.0817 - val_accuracy: 0.9514 - val_loss: 0.1154\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9806 - loss: 0.0541\n",
      "Epoch 13: val_accuracy did not improve from 0.96993\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9806 - loss: 0.0540 - val_accuracy: 0.9452 - val_loss: 0.1426\n",
      "Epoch 14/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9809 - loss: 0.0473\n",
      "Epoch 14: val_accuracy did not improve from 0.96993\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9809 - loss: 0.0472 - val_accuracy: 0.9452 - val_loss: 0.1637\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9719 - loss: 0.0917\n",
      "Epoch 15: val_accuracy did not improve from 0.96993\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9720 - loss: 0.0914 - val_accuracy: 0.9592 - val_loss: 0.1223\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9895 - loss: 0.0284\n",
      "Epoch 16: val_accuracy improved from 0.96993 to 0.98476, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9895 - loss: 0.0284 - val_accuracy: 0.9848 - val_loss: 0.0495\n",
      "Epoch 17/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9953 - loss: 0.0157\n",
      "Epoch 17: val_accuracy improved from 0.98476 to 0.98929, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9953 - loss: 0.0157 - val_accuracy: 0.9893 - val_loss: 0.0404\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9945 - loss: 0.0172\n",
      "Epoch 18: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9944 - loss: 0.0173 - val_accuracy: 0.9778 - val_loss: 0.0629\n",
      "Epoch 19/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9934 - loss: 0.0190\n",
      "Epoch 19: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9934 - loss: 0.0191 - val_accuracy: 0.9782 - val_loss: 0.0635\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9916 - loss: 0.0212\n",
      "Epoch 20: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9916 - loss: 0.0213 - val_accuracy: 0.9086 - val_loss: 0.3291\n",
      "Epoch 21/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9790 - loss: 0.0602\n",
      "Epoch 21: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9791 - loss: 0.0602 - val_accuracy: 0.9786 - val_loss: 0.0863\n",
      "Epoch 22/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9937 - loss: 0.0198\n",
      "Epoch 22: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.9732 - val_loss: 0.0898\n",
      "Epoch 23/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9945 - loss: 0.0173\n",
      "Epoch 23: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9945 - loss: 0.0173 - val_accuracy: 0.9864 - val_loss: 0.0375\n",
      "Epoch 24/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9960 - loss: 0.0118\n",
      "Epoch 24: val_accuracy did not improve from 0.98929\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9960 - loss: 0.0118 - val_accuracy: 0.9872 - val_loss: 0.0400\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0074\n",
      "Epoch 25: val_accuracy improved from 0.98929 to 0.99053, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9970 - loss: 0.0074 - val_accuracy: 0.9905 - val_loss: 0.0399\n",
      "Epoch 26/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.5800e-04\n",
      "Epoch 26: val_accuracy improved from 0.99053 to 0.99094, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.5700e-04 - val_accuracy: 0.9909 - val_loss: 0.0395\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9997 - loss: 9.2415e-04\n",
      "Epoch 27: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9997 - loss: 9.2747e-04 - val_accuracy: 0.9897 - val_loss: 0.0462\n",
      "Epoch 28/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9970 - loss: 0.0118\n",
      "Epoch 28: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9969 - loss: 0.0120 - val_accuracy: 0.9671 - val_loss: 0.1132\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9908 - loss: 0.0272\n",
      "Epoch 29: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9908 - loss: 0.0272 - val_accuracy: 0.9786 - val_loss: 0.0696\n",
      "Epoch 30/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0268\n",
      "Epoch 30: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.9852 - val_loss: 0.0527\n",
      "Epoch 31/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9932 - loss: 0.0219\n",
      "Epoch 31: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9932 - loss: 0.0219 - val_accuracy: 0.9885 - val_loss: 0.0317\n",
      "Epoch 32/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 32: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9881 - val_loss: 0.0345\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2856e-04\n",
      "Epoch 33: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2836e-04 - val_accuracy: 0.9893 - val_loss: 0.0359\n",
      "Epoch 34/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.4238e-05\n",
      "Epoch 34: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.4145e-05 - val_accuracy: 0.9893 - val_loss: 0.0368\n",
      "Epoch 35/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.1942e-05\n",
      "Epoch 35: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.1852e-05 - val_accuracy: 0.9889 - val_loss: 0.0374\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.8754e-05\n",
      "Epoch 36: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.8712e-05 - val_accuracy: 0.9889 - val_loss: 0.0381\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8958e-05\n",
      "Epoch 37: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8917e-05 - val_accuracy: 0.9889 - val_loss: 0.0406\n",
      "Epoch 38/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7231e-05\n",
      "Epoch 38: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7201e-05 - val_accuracy: 0.9885 - val_loss: 0.0429\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.5137e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.5000e-06 - val_accuracy: 0.9889 - val_loss: 0.0442\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.8324e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.8234e-06 - val_accuracy: 0.9889 - val_loss: 0.0450\n",
      "Epoch 41/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.2195e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.2106e-06 - val_accuracy: 0.9885 - val_loss: 0.0457\n",
      "Epoch 42/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.1663e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.1596e-06 - val_accuracy: 0.9885 - val_loss: 0.0464\n",
      "Epoch 43/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.4096e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.4062e-06 - val_accuracy: 0.9881 - val_loss: 0.0469\n",
      "Epoch 44/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.7955e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.7930e-06 - val_accuracy: 0.9881 - val_loss: 0.0476\n",
      "Epoch 45/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3357e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3326e-06 - val_accuracy: 0.9876 - val_loss: 0.0483\n",
      "Epoch 46/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9486e-06\n",
      "Epoch 46: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9469e-06 - val_accuracy: 0.9881 - val_loss: 0.0488\n",
      "Epoch 47/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6421e-06\n",
      "Epoch 47: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6407e-06 - val_accuracy: 0.9881 - val_loss: 0.0494\n",
      "Epoch 48/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.3721e-06\n",
      "Epoch 48: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3710e-06 - val_accuracy: 0.9881 - val_loss: 0.0502\n",
      "Epoch 49/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.1334e-06\n",
      "Epoch 49: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1326e-06 - val_accuracy: 0.9881 - val_loss: 0.0510\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.4937e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.4873e-07 - val_accuracy: 0.9885 - val_loss: 0.0517\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.9159e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.9110e-07 - val_accuracy: 0.9889 - val_loss: 0.0524\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.6574e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.6537e-07 - val_accuracy: 0.9889 - val_loss: 0.0533\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.6583e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.6551e-07 - val_accuracy: 0.9893 - val_loss: 0.0540\n",
      "Epoch 54/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.7645e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.7620e-07 - val_accuracy: 0.9893 - val_loss: 0.0547\n",
      "Epoch 55/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0461e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.0431e-07 - val_accuracy: 0.9889 - val_loss: 0.0553\n",
      "Epoch 56/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.3988e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.3973e-07 - val_accuracy: 0.9889 - val_loss: 0.0559\n",
      "Epoch 57/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8894e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8882e-07 - val_accuracy: 0.9889 - val_loss: 0.0565\n",
      "Epoch 58/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4474e-07\n",
      "Epoch 58: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4459e-07 - val_accuracy: 0.9889 - val_loss: 0.0572\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.0845e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.0837e-07 - val_accuracy: 0.9889 - val_loss: 0.0577\n",
      "Epoch 60/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7730e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7720e-07 - val_accuracy: 0.9889 - val_loss: 0.0582\n",
      "Epoch 61/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.5156e-07\n",
      "Epoch 61: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5148e-07 - val_accuracy: 0.9889 - val_loss: 0.0588\n",
      "Epoch 62/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.2938e-07\n",
      "Epoch 62: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.2931e-07 - val_accuracy: 0.9889 - val_loss: 0.0594\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0991e-07\n",
      "Epoch 63: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0987e-07 - val_accuracy: 0.9889 - val_loss: 0.0600\n",
      "Epoch 64/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.4005e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.3955e-08 - val_accuracy: 0.9889 - val_loss: 0.0606\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.0495e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.0465e-08 - val_accuracy: 0.9889 - val_loss: 0.0611\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.9275e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.9250e-08 - val_accuracy: 0.9893 - val_loss: 0.0618\n",
      "Epoch 67/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.9730e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.9707e-08 - val_accuracy: 0.9897 - val_loss: 0.0623\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.1087e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.1068e-08 - val_accuracy: 0.9897 - val_loss: 0.0630\n",
      "Epoch 69/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.4198e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.4173e-08 - val_accuracy: 0.9897 - val_loss: 0.0636\n",
      "Epoch 70/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.7959e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.7944e-08 - val_accuracy: 0.9893 - val_loss: 0.0643\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2815e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.2801e-08 - val_accuracy: 0.9893 - val_loss: 0.0649\n",
      "Epoch 72/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8498e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8485e-08 - val_accuracy: 0.9893 - val_loss: 0.0655\n",
      "Epoch 73/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4552e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4535e-08 - val_accuracy: 0.9893 - val_loss: 0.0661\n",
      "Epoch 74/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1226e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1216e-08 - val_accuracy: 0.9897 - val_loss: 0.0667\n",
      "Epoch 75/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8179e-08\n",
      "Epoch 75: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8171e-08 - val_accuracy: 0.9897 - val_loss: 0.0672\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5679e-08\n",
      "Epoch 76: val_accuracy did not improve from 0.99094\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5672e-08 - val_accuracy: 0.9897 - val_loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n",
      "Best model loaded successfully!\n",
      "\u001b[1m15/76\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:47:56.470985: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-04 15:47:56.471928: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9121e-04\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0322\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0203\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:48:01.525640: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 15:48:01.525907: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5150 - loss: 1.2869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:48:11.056325: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-04 15:48:11.056631: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.84061, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.5162 - loss: 1.2837 - val_accuracy: 0.8406 - val_loss: 0.3526\n",
      "Epoch 2/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8334 - loss: 0.3725\n",
      "Epoch 2: val_accuracy improved from 0.84061 to 0.84185, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.8335 - loss: 0.3723 - val_accuracy: 0.8418 - val_loss: 0.3699\n",
      "Epoch 3/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8611 - loss: 0.2907\n",
      "Epoch 3: val_accuracy did not improve from 0.84185\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8612 - loss: 0.2906 - val_accuracy: 0.7722 - val_loss: 0.8246\n",
      "Epoch 4/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8803 - loss: 0.2500\n",
      "Epoch 4: val_accuracy did not improve from 0.84185\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8804 - loss: 0.2499 - val_accuracy: 0.8344 - val_loss: 0.4494\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8984 - loss: 0.2132\n",
      "Epoch 5: val_accuracy did not improve from 0.84185\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.8985 - loss: 0.2131 - val_accuracy: 0.8089 - val_loss: 0.5037\n",
      "Epoch 6/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9165 - loss: 0.1979\n",
      "Epoch 6: val_accuracy improved from 0.84185 to 0.93987, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9166 - loss: 0.1978 - val_accuracy: 0.9399 - val_loss: 0.1556\n",
      "Epoch 7/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9361 - loss: 0.1682\n",
      "Epoch 7: val_accuracy improved from 0.93987 to 0.94357, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9362 - loss: 0.1681 - val_accuracy: 0.9436 - val_loss: 0.1404\n",
      "Epoch 8/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9528 - loss: 0.1132\n",
      "Epoch 8: val_accuracy improved from 0.94357 to 0.94852, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9528 - loss: 0.1132 - val_accuracy: 0.9485 - val_loss: 0.1449\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9595 - loss: 0.1056\n",
      "Epoch 9: val_accuracy did not improve from 0.94852\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9595 - loss: 0.1056 - val_accuracy: 0.9473 - val_loss: 0.1589\n",
      "Epoch 10/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9642 - loss: 0.1030\n",
      "Epoch 10: val_accuracy did not improve from 0.94852\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9642 - loss: 0.1029 - val_accuracy: 0.9287 - val_loss: 0.1784\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9714 - loss: 0.0721\n",
      "Epoch 11: val_accuracy did not improve from 0.94852\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9714 - loss: 0.0721 - val_accuracy: 0.9432 - val_loss: 0.1429\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9757 - loss: 0.0711\n",
      "Epoch 12: val_accuracy did not improve from 0.94852\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9757 - loss: 0.0712 - val_accuracy: 0.9386 - val_loss: 0.1533\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9788 - loss: 0.0624\n",
      "Epoch 13: val_accuracy improved from 0.94852 to 0.97529, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9788 - loss: 0.0623 - val_accuracy: 0.9753 - val_loss: 0.0628\n",
      "Epoch 14/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9846 - loss: 0.0444\n",
      "Epoch 14: val_accuracy did not improve from 0.97529\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9846 - loss: 0.0444 - val_accuracy: 0.9419 - val_loss: 0.1708\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9744 - loss: 0.0668\n",
      "Epoch 15: val_accuracy improved from 0.97529 to 0.97858, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9744 - loss: 0.0667 - val_accuracy: 0.9786 - val_loss: 0.0564\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9832 - loss: 0.0502\n",
      "Epoch 16: val_accuracy did not improve from 0.97858\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9832 - loss: 0.0503 - val_accuracy: 0.9720 - val_loss: 0.0828\n",
      "Epoch 17/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9869 - loss: 0.0440\n",
      "Epoch 17: val_accuracy did not improve from 0.97858\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9869 - loss: 0.0439 - val_accuracy: 0.9629 - val_loss: 0.1109\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9940 - loss: 0.0160\n",
      "Epoch 18: val_accuracy did not improve from 0.97858\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9940 - loss: 0.0160 - val_accuracy: 0.9559 - val_loss: 0.1540\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9832 - loss: 0.0496\n",
      "Epoch 19: val_accuracy did not improve from 0.97858\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9832 - loss: 0.0496 - val_accuracy: 0.9320 - val_loss: 0.2834\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0315\n",
      "Epoch 20: val_accuracy improved from 0.97858 to 0.97941, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0314 - val_accuracy: 0.9794 - val_loss: 0.0646\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9918 - loss: 0.0273\n",
      "Epoch 21: val_accuracy improved from 0.97941 to 0.98847, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9918 - loss: 0.0273 - val_accuracy: 0.9885 - val_loss: 0.0424\n",
      "Epoch 22/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9964 - loss: 0.0101\n",
      "Epoch 22: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9964 - loss: 0.0101 - val_accuracy: 0.9419 - val_loss: 0.2324\n",
      "Epoch 23/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9917 - loss: 0.0200\n",
      "Epoch 23: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9917 - loss: 0.0201 - val_accuracy: 0.9773 - val_loss: 0.0781\n",
      "Epoch 24/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0358\n",
      "Epoch 24: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0357 - val_accuracy: 0.9584 - val_loss: 0.1647\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9707 - loss: 0.0947\n",
      "Epoch 25: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9708 - loss: 0.0943 - val_accuracy: 0.9794 - val_loss: 0.0664\n",
      "Epoch 26/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9967 - loss: 0.0069\n",
      "Epoch 26: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9967 - loss: 0.0069 - val_accuracy: 0.9724 - val_loss: 0.0944\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9886 - loss: 0.0306\n",
      "Epoch 27: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9886 - loss: 0.0305 - val_accuracy: 0.9757 - val_loss: 0.0950\n",
      "Epoch 28/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9952 - loss: 0.0133\n",
      "Epoch 28: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9952 - loss: 0.0133 - val_accuracy: 0.9852 - val_loss: 0.0562\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9964 - loss: 0.0127\n",
      "Epoch 29: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9964 - loss: 0.0127 - val_accuracy: 0.9802 - val_loss: 0.0837\n",
      "Epoch 30/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9918 - loss: 0.0236\n",
      "Epoch 30: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9918 - loss: 0.0236 - val_accuracy: 0.9798 - val_loss: 0.0834\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9939 - loss: 0.0224\n",
      "Epoch 31: val_accuracy did not improve from 0.98847\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9939 - loss: 0.0225 - val_accuracy: 0.9864 - val_loss: 0.0490\n",
      "Epoch 32/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 32: val_accuracy improved from 0.98847 to 0.98888, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9889 - val_loss: 0.0461\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0132\n",
      "Epoch 33: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9956 - loss: 0.0132 - val_accuracy: 0.9889 - val_loss: 0.0445\n",
      "Epoch 34/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.6221e-04\n",
      "Epoch 34: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6182e-04 - val_accuracy: 0.9881 - val_loss: 0.0478\n",
      "Epoch 35/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.0200e-04\n",
      "Epoch 35: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0199e-04 - val_accuracy: 0.9872 - val_loss: 0.0453\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.0233e-05\n",
      "Epoch 36: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.0242e-05 - val_accuracy: 0.9872 - val_loss: 0.0456\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.1030e-05\n",
      "Epoch 37: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.1041e-05 - val_accuracy: 0.9868 - val_loss: 0.0463\n",
      "Epoch 38/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.0258e-05\n",
      "Epoch 38: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.0266e-05 - val_accuracy: 0.9868 - val_loss: 0.0471\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3038e-05\n",
      "Epoch 39: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3044e-05 - val_accuracy: 0.9868 - val_loss: 0.0478\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.7942e-05\n",
      "Epoch 40: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7947e-05 - val_accuracy: 0.9868 - val_loss: 0.0485\n",
      "Epoch 41/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.4214e-05\n",
      "Epoch 41: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4220e-05 - val_accuracy: 0.9868 - val_loss: 0.0492\n",
      "Epoch 42/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1372e-05\n",
      "Epoch 42: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1377e-05 - val_accuracy: 0.9868 - val_loss: 0.0498\n",
      "Epoch 43/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.1817e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.1844e-06 - val_accuracy: 0.9868 - val_loss: 0.0504\n",
      "Epoch 44/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.4644e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.4679e-06 - val_accuracy: 0.9868 - val_loss: 0.0510\n",
      "Epoch 45/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.1014e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.1044e-06 - val_accuracy: 0.9868 - val_loss: 0.0516\n",
      "Epoch 46/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.0027e-06\n",
      "Epoch 46: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.0052e-06 - val_accuracy: 0.9872 - val_loss: 0.0522\n",
      "Epoch 47/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.1193e-06\n",
      "Epoch 47: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.1214e-06 - val_accuracy: 0.9872 - val_loss: 0.0528\n",
      "Epoch 48/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.4041e-06\n",
      "Epoch 48: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.4053e-06 - val_accuracy: 0.9872 - val_loss: 0.0534\n",
      "Epoch 49/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8239e-06\n",
      "Epoch 49: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8249e-06 - val_accuracy: 0.9872 - val_loss: 0.0540\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3475e-06\n",
      "Epoch 50: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3484e-06 - val_accuracy: 0.9876 - val_loss: 0.0546\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9574e-06\n",
      "Epoch 51: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9581e-06 - val_accuracy: 0.9876 - val_loss: 0.0552\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6353e-06\n",
      "Epoch 52: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6359e-06 - val_accuracy: 0.9876 - val_loss: 0.0557\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.3662e-06\n",
      "Epoch 53: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3668e-06 - val_accuracy: 0.9876 - val_loss: 0.0563\n",
      "Epoch 54/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1427e-06\n",
      "Epoch 54: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1434e-06 - val_accuracy: 0.9876 - val_loss: 0.0569\n",
      "Epoch 55/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.5524e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.5564e-07 - val_accuracy: 0.9876 - val_loss: 0.0574\n",
      "Epoch 56/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.9912e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.9962e-07 - val_accuracy: 0.9876 - val_loss: 0.0579\n",
      "Epoch 57/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.6957e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.6985e-07 - val_accuracy: 0.9876 - val_loss: 0.0585\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.6012e-07\n",
      "Epoch 58: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.6036e-07 - val_accuracy: 0.9876 - val_loss: 0.0590\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.6819e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6840e-07 - val_accuracy: 0.9876 - val_loss: 0.0595\n",
      "Epoch 60/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.9140e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.9168e-07 - val_accuracy: 0.9876 - val_loss: 0.0600\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2835e-07\n",
      "Epoch 61: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.2851e-07 - val_accuracy: 0.9876 - val_loss: 0.0605\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.7560e-07\n",
      "Epoch 62: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.7574e-07 - val_accuracy: 0.9876 - val_loss: 0.0610\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3132e-07\n",
      "Epoch 63: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3144e-07 - val_accuracy: 0.9876 - val_loss: 0.0615\n",
      "Epoch 64/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9447e-07\n",
      "Epoch 64: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9463e-07 - val_accuracy: 0.9876 - val_loss: 0.0619\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.6384e-07\n",
      "Epoch 65: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6392e-07 - val_accuracy: 0.9876 - val_loss: 0.0624\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.3793e-07\n",
      "Epoch 66: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3801e-07 - val_accuracy: 0.9881 - val_loss: 0.0628\n",
      "Epoch 67/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.1628e-07\n",
      "Epoch 67: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1634e-07 - val_accuracy: 0.9881 - val_loss: 0.0633\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.8008e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.8060e-08 - val_accuracy: 0.9881 - val_loss: 0.0638\n",
      "Epoch 69/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.2852e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.2895e-08 - val_accuracy: 0.9881 - val_loss: 0.0642\n",
      "Epoch 70/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.9938e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.9995e-08 - val_accuracy: 0.9885 - val_loss: 0.0646\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.9144e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.9175e-08 - val_accuracy: 0.9885 - val_loss: 0.0651\n",
      "Epoch 72/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.9976e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.0004e-08 - val_accuracy: 0.9885 - val_loss: 0.0655\n",
      "Epoch 73/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.2248e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.2270e-08 - val_accuracy: 0.9885 - val_loss: 0.0659\n",
      "Epoch 74/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.5861e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.5890e-08 - val_accuracy: 0.9885 - val_loss: 0.0663\n",
      "Epoch 75/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.0194e-08\n",
      "Epoch 75: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.0211e-08 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.5494e-08\n",
      "Epoch 76: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.5508e-08 - val_accuracy: 0.9885 - val_loss: 0.0670\n",
      "Epoch 77/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1705e-08\n",
      "Epoch 77: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1716e-08 - val_accuracy: 0.9885 - val_loss: 0.0675\n",
      "Epoch 78/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8360e-08\n",
      "Epoch 78: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8370e-08 - val_accuracy: 0.9885 - val_loss: 0.0679\n",
      "Epoch 79/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5752e-08\n",
      "Epoch 79: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5760e-08 - val_accuracy: 0.9885 - val_loss: 0.0682\n",
      "Epoch 80/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.3305e-08\n",
      "Epoch 80: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3312e-08 - val_accuracy: 0.9885 - val_loss: 0.0686\n",
      "Epoch 81/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1364e-08\n",
      "Epoch 81: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1370e-08 - val_accuracy: 0.9885 - val_loss: 0.0690\n",
      "Epoch 82/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.6863e-09\n",
      "Epoch 82: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.6914e-09 - val_accuracy: 0.9885 - val_loss: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n",
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:00:51.972013: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-04 16:00:51.973276: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.5796e-04\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0378\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0337\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation / 5 fold cross validation )\n",
    "kSplits = 5\n",
    "# kfold = KFold(n_splits=kSplits, random_state=42, shuffle=True)\n",
    "kfold = StratifiedKFold(n_splits=kSplits, random_state=42, shuffle=True) # splits training data into 5 folds - class balance(stratify)\n",
    "\n",
    "# File path name to save best models\n",
    "foldername = \"CNN2D_results/V4_2_NOL_exp4/\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint #Saves the model with the highest validation accuracy for each fold\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "pred_all_val = np.zeros([len(X_2D_train),10])\n",
    "y_2D_val = np.zeros([len(X_2D_train),10])\n",
    "kfold_test_len = []\n",
    "\n",
    "fl1 = 0\n",
    "k = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True) #Stops training if validation accuracy doesn’t improve for 50 epochs, restoring the best weights.\n",
    "\n",
    "# Train the model \n",
    "# for train, test in kfold.split(X_2D_train,y_2D_train):\n",
    "for fold, (train, test) in enumerate(kfold.split(X_2D_train, y_label_train)):   \n",
    "\n",
    "  # Define where to save the best model\n",
    "  checkpoint_filepath = foldername + \"best_model_\" + str(k) + \".h5\"\n",
    "    \n",
    "  # Create a ModelCheckpoint callback\n",
    "  checkpoint = ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_accuracy',  # Monitor validation accuracy\n",
    "      save_best_only=True,  # Save only the best model\n",
    "      mode='max',  # Maximize accuracy\n",
    "      verbose=1\n",
    "  )        \n",
    "\n",
    "#For each fold, trains a new CNN model on the training subset (X_2D_train[train], y_2D_train[train]) for up to 200 epochs.\n",
    "  Classification_2D = CNN_2D()\n",
    "  # history = Classification_2D.model.fit(X_2D_train[train], y_2D_train[train], verbose=1, epochs=50) #epochs=12\n",
    "  history = Classification_2D.model.fit(\n",
    "        X_2D_train[train], y_2D_train[train],\n",
    "        validation_data=(X_2D_train[test], y_2D_train[test]),  # Validation set for monitoring\n",
    "        epochs=200,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint, early_stop]  # Save the best model\n",
    "  )\n",
    "  \n",
    "  print(\"Best model saved at:\", checkpoint_filepath)\n",
    "  CNN_2D_best_model = load_model(checkpoint_filepath)\n",
    "  print(\"Best model loaded successfully!\")\n",
    "  \n",
    "  fl2 = fl1 + len(test)\n",
    "  pred_all_val[fl1:fl2,:] = CNN_2D_best_model.predict(X_2D_train[test])\n",
    "  y_2D_val[fl1:fl2,:] = y_2D_train[test]\n",
    "  kfold_test_len.append(fl2-fl1)\n",
    "  fl1 = fl2  \n",
    "\n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  train_loss, train_accuracy = CNN_2D_best_model.evaluate(X_2D_train[train], y_2D_train[train]) \n",
    "  accuracy_train.append(train_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  val_loss, val_accuracy = CNN_2D_best_model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  accuracy_val.append(val_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  test_loss, test_accuracy = CNN_2D_best_model.evaluate(X_2D_test, y_2D_test) \n",
    "  accuracy_test.append(test_accuracy)  \n",
    "  \n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  # kf_loss, kf_accuracy = Classification_2D.model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  # accuracy_2D.append(kf_accuracy)\n",
    "  \n",
    "  k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7705181d-c6cb-4412-a002-8937240306ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 2D train accuracy = 99.98147010803223\n",
      "CNN 2D validation accuracy = 98.98707151412964\n",
      "CNN 2D test accuracy = 99.00527000427246\n",
      "\u001b[1m 14/380\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 09:25:41.973738: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-05 09:25:41.974607: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Classification_2D.model.summary()\n",
    "\n",
    "CNN_2D_train_accuracy = np.average(accuracy_train)*100\n",
    "print('CNN 2D train accuracy =', CNN_2D_train_accuracy)\n",
    "# print(accuracy_train)\n",
    "\n",
    "CNN_2D_val_accuracy = np.average(accuracy_val)*100\n",
    "print('CNN 2D validation accuracy =', CNN_2D_val_accuracy)\n",
    "# print(accuracy_val)\n",
    "\n",
    "CNN_2D_test_accuracy = np.average(accuracy_test)*100\n",
    "print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "# print(accuracy_test)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test set\n",
    "# CNN_2D_test_loss, CNN_2D_test_accuracy = Classification_2D.model.evaluate(X_2D_test, y_2D_test)\n",
    "# CNN_2D_test_accuracy*=100\n",
    "# print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "  y_pred = np.argmax(Model.predict(X), axis=1)\n",
    "  ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "  return ConfusionMat\n",
    "\n",
    "# Plot results - CNN 2D\n",
    "plt.figure(5)\n",
    "plt.title('Confusion Matrix - CNN 2D Train') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_train, y_2D_train) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.title('Confusion Matrix - CNN 2D Test') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_test, y_2D_test) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7)\n",
    "plt.title('Train - Accuracy - CNN 2D')\n",
    "plt.bar(np.arange(1,kSplits+1),[i*100 for i in accuracy_val])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70,100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(8)\n",
    "plt.title('Train vs Test Accuracy - CNN 2D')\n",
    "plt.bar([1,2],[CNN_2D_train_accuracy,CNN_2D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.xticks([1,2],['Train', 'Test'])\n",
    "plt.ylim([70,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "923d304a-13a4-42ce-bd02-0c15bc3ecc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model summary for fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m115,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax_5 (\u001b[38;5;33mSoftmax\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,014</span> (851.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m218,014\u001b[0m (851.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,012</span> (851.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m218,012\u001b[0m (851.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: conv2d_20\n",
      "1: max_pooling2d_20\n",
      "2: conv2d_21\n",
      "3: max_pooling2d_21\n",
      "4: conv2d_22\n",
      "5: max_pooling2d_22\n",
      "6: conv2d_23\n",
      "7: max_pooling2d_23\n",
      "8: flatten_5\n",
      "9: dense_15\n",
      "10: dense_16\n",
      "11: dense_17\n",
      "12: softmax_5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_5 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m layer_name = \u001b[33m'\u001b[39m\u001b[33msequential_5\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# or whatever corresponds to Dense(100)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m intermediate_model = tf.keras.Model(inputs=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m, outputs=model.get_layer(layer_name).output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/ops/operation.py:276\u001b[39m, in \u001b[36mOperation.input\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[32m    269\u001b[39m \n\u001b[32m    270\u001b[39m \u001b[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_tensors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/ops/operation.py:307\u001b[39m, in \u001b[36mOperation._get_node_attribute_at_index\u001b[39m\u001b[34m(self, node_index, attr, attr_name)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inbound_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    308\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has never been called \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m     )\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes) > node_index:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at node \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the operation has only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inbound nodes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: The layer sequential_5 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# for i in range(1, 6):\n",
    "#     filepath = f\"CNN2D_results/V4_2_NOL_exp1/best_model_{i}.h5\"\n",
    "#     print(f\"\\nModel summary for fold {i}:\")\n",
    "#     model = load_model(filepath)\n",
    "#     model.summary()\n",
    "#     for i, layer in enumerate(model.layers):\n",
    "#         print(f\"{i}: {layer.name} — {layer.output_shape}\")\n",
    "\n",
    "\n",
    "filepath = f\"CNN2D_results/V4_2_NOL_exp1/best_model_1.h5\"\n",
    "print(f\"\\nModel summary for fold 1:\")\n",
    "model = load_model(filepath)\n",
    "model.summary()\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{i}: {layer.name}\")\n",
    "\n",
    "\n",
    "layer_name = 'dense'  # or whatever corresponds to Dense(100)\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b387e8-173c-4018-8896-a0340889bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sample training inputs (every 10th) and get intermediate outputs\n",
    "x_sampled = X_2D_train[::10]\n",
    "y_sampled = y_2D_train[::10]\n",
    "\n",
    "intermediate_outputs = intermediate_model.predict(x_sampled)\n",
    "\n",
    "# Step 2: Reduce dimensionality using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "x_embedded = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30).fit_transform(intermediate_outputs)\n",
    "\n",
    "# Step 3: Decode one-hot labels (if needed)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "if y_sampled.shape[1] > 1:\n",
    "    y_label = enc.inverse_transform(y_sampled)\n",
    "else:\n",
    "    y_label = y_sampled.flatten()\n",
    "\n",
    "# Step 4: Plot the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=x_embedded[:, 0], y=x_embedded[:, 1], hue=y_label, style=y_label,\n",
    "                palette=\"bright\", edgecolor='black')\n",
    "plt.title(\"t-SNE of Intermediate CNN Layer Output (Fold 1)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
