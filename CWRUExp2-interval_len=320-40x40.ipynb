{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a5ab9cc-9d31-4bd8-9339-c80842c4c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32209d77-1aef-4ca4-81d7-ea6457e51333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 1\n",
    "random.seed(SEED)            # Python random module\n",
    "np.random.seed(SEED)         # NumPy\n",
    "tf.random.set_seed(SEED)     # TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71899bcf-951f-483f-9b14-081df6aa4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce deterministic behavior for GPU operations\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic execution\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Deterministic cuDNN algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbd1cd7b-5ae6-45e4-9888-9da0cae55811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control GPU memory allocation (prevents TensorFlow from using all GPU memory)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # Enable memory growth\n",
    "\n",
    "# Restrict parallelism (ensures consistent execution order)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0842921e-69f2-4b98-a50d-a8cbf80872d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import scipy.io #to load matlab files \n",
    "# import numpy as np\n",
    "from sklearn.model_selection import train_test_split #for data splitting #, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras import layers, models #build and train CNN model\n",
    "import matplotlib.pyplot as plt #for plotting confusion matrices and accuracy metrics\n",
    "import seaborn as sns \n",
    "# import pandas as pd\n",
    "\n",
    "from scipy import signal #for computing spectograms\n",
    "from skimage.transform import resize #for resizing data\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d9d9640-93e2-47e2-98d4-06a74ec1a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Read CWRU Bearing Data (Load - 2HP)\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "def ImportData():\n",
    "  folder_path = 'CWRU_BearingData_Load_2HP' \n",
    "  # X99_normal = scipy.io.loadmat('content/drive/MyDrive/BearingData_CaseWestern/99.mat')['X099_DE_time'] \n",
    "  file_path1 = os.path.join(folder_path, '99.mat')\n",
    "  X99_normal = scipy.io.loadmat(file_path1)['X099_DE_time'] #vibration data extracted from X099_DE_time key (drive-end accelerometer data)\n",
    "\n",
    "    \n",
    "  # X111_InnerRace_007 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/111.mat')['X111_DE_time']\n",
    "  file_path2 = os.path.join(folder_path, '111.mat')\n",
    "  X111_InnerRace_007  = scipy.io.loadmat(file_path2)['X111_DE_time']\n",
    "\n",
    "  # X124_Ball_007 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/124.mat')['X124_DE_time']\n",
    "  file_path3 = os.path.join(folder_path, '124.mat')\n",
    "  X124_Ball_007 = scipy.io.loadmat(file_path3)['X124_DE_time']\n",
    "\n",
    "  # X137_Outer_007 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/137.mat')['X137_DE_time']\n",
    "  file_path4 = os.path.join(folder_path, '137.mat')\n",
    "  X137_Outer_007 = scipy.io.loadmat(file_path4)['X137_DE_time']\n",
    "    \n",
    "  # X176_InnerRace_014 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/176.mat')['X176_DE_time']\n",
    "  file_path5 = os.path.join(folder_path, '176.mat')\n",
    "  X176_InnerRace_014 = scipy.io.loadmat(file_path5)['X176_DE_time']\n",
    "\n",
    "  # X191_Ball_014 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/191.mat')['X191_DE_time']\n",
    "  file_path6 = os.path.join(folder_path, '191.mat')\n",
    "  X191_Ball_014 = scipy.io.loadmat(file_path6)['X191_DE_time']\n",
    "    \n",
    "  # X203_Outer_014 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/203.mat')['X203_DE_time']\n",
    "  file_path7 = os.path.join(folder_path, '203.mat')\n",
    "  X203_Outer_014  = scipy.io.loadmat(file_path7)['X203_DE_time']\n",
    "\n",
    "  #  X215_InnerRace_021 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/215.mat')['X215_DE_time']\n",
    "  file_path8 = os.path.join(folder_path, '215.mat')\n",
    "  X215_InnerRace_021  = scipy.io.loadmat(file_path8)['X215_DE_time']\n",
    "    \n",
    "  # X228_Ball_021 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/228.mat')['X228_DE_time']\n",
    "  file_path9 = os.path.join(folder_path, '228.mat')\n",
    "  X228_Ball_021  = scipy.io.loadmat(file_path9)['X228_DE_time']\n",
    "\n",
    "  # X240_Outer_021 = scipy.io.loadmat('/content/drive/MyDrive/BearingData_CaseWestern/240.mat')['X240_DE_time']\n",
    "  file_path10 = os.path.join(folder_path, '240.mat')\n",
    "  X240_Outer_021  = scipy.io.loadmat(file_path10)['X240_DE_time'] \n",
    "    \n",
    "  return [X99_normal,X111_InnerRace_007,X124_Ball_007,X137_Outer_007,X176_InnerRace_014,X191_Ball_014,X203_Outer_014,X215_InnerRace_021,X228_Ball_021,X240_Outer_021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f6fbfd8-76a9-49e1-94e2-2924bd737533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data Processing and Feature Extraction\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "# def Sampling(Data, interval_length, samples_per_block):\n",
    "#     No_of_blocks = (round(len(Data)/interval_length) - round(samples_per_block/interval_length) - 1)\n",
    "#     SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "#     for i in range(No_of_blocks):\n",
    "#         SplitData[i,:] = Data[i*interval_length:(i*interval_length)+samples_per_block].T\n",
    "#     return SplitData\n",
    "\n",
    "#segments the time-series data into smaller blocks for processing\n",
    "#data: 1D numpy array of vibration data\n",
    "#interval length: step size (in samples) betweeen the start of consectuive blocks\n",
    "#samples_per_block: no. of samples in each block (fixed at 1600 in the code)\n",
    "#ignore_points: no. of points to skip at start and end of data(default is 0)\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    # Adjust data length to ignore the first and last 'ignore_points'\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    print(len(Data))\n",
    "    # Adjust the number of blocks\n",
    "    No_of_blocks = (round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1)\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block]) #splitdata matrix where each row is a block of samples_per_block samples\n",
    "    \n",
    "    for i in range(No_of_blocks):\n",
    "        # Skip the first 'ignore_points' and start sampling from that position\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx:(start_idx + samples_per_block)].T #.T transpose ensure the data is correctly oriented (since the input is a column vector)\n",
    "    \n",
    "    return SplitData #2D array of shape - no.ofblocks, samples_per_block)\n",
    "\n",
    "\n",
    "def DataPreparation(Data, interval_length, samples_per_block):\n",
    "  for count,i in enumerate(Data):\n",
    "    SplitData = Sampling(i, interval_length, samples_per_block) #for each dataset calls samplying to create blocks of 1600 samples\n",
    "    y = np.zeros([len(SplitData),10]) #y (one-hot encoded): Shape (No_of_blocks, 10), where the column corresponding to the class is set to 1 (e.g., for class 0, [1, 0, 0, ..., 0])\n",
    "    y[:,count] = 1\n",
    "    y1 = np.zeros([len(SplitData),1]) #y1 (integer labels): Shape (No_of_blocks, 1), where each element is the class index (0 to 9).\n",
    "    y1[:,0] = count \n",
    "    # Stack up and label the data   \n",
    "    if count==0:\n",
    "      X = SplitData\n",
    "      LabelPositional = y\n",
    "      Label = y1\n",
    "    else:\n",
    "      X = np.append(X, SplitData, axis=0)\n",
    "      LabelPositional = np.append(LabelPositional,y,axis=0)\n",
    "      Label = np.append(Label,y1,axis=0)\n",
    "  print(X)\n",
    "  return X, LabelPositional, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44975d7a-8b19-44e0-a88f-ca7bf2c4749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(ary):\n",
    "    ary = (ary - ary.min()) / np.abs(ary.max() - ary.min())\n",
    "    return ary\n",
    "\n",
    "def generate_spectrogram_image(data_y_vector, image_shape):\n",
    "    \"\"\"\n",
    "    Calculate the spectrogram of an array data_y_vector and resize it in \n",
    "    the image_shape resolution\n",
    "    \"\"\"\n",
    "    fs = 48000\n",
    "    # data_y_vector_len = np.shape(data_y_vector)[0]\n",
    "\n",
    "    f, t, sxx = signal.spectrogram(\n",
    "        data_y_vector,\n",
    "        fs)\n",
    "\n",
    "    sxx = min_max_norm(sxx)\n",
    "    sxx = resize(sxx, image_shape, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    return sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3c91be0-79cd-438c-876c-9291efc88572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485063\n",
      "485643\n",
      "486804\n",
      "486804\n",
      "487964\n",
      "487384\n",
      "486804\n",
      "491446\n",
      "487384\n",
      "487964\n",
      "[[ 0.06425354  0.06300185 -0.00438092 ...  0.01460308  0.06404492\n",
      "   0.09804923]\n",
      " [ 0.06571385  0.01606338 -0.05424    ...  0.02732862  0.062376\n",
      "   0.05465723]\n",
      " [ 0.04672985 -0.00146031 -0.04819015 ... -0.10994031 -0.04026277\n",
      "  -0.01731508]\n",
      " ...\n",
      " [-0.20032    -0.20198933 -0.13187733 ... -0.18696533 -0.16609867\n",
      "  -0.11434933]\n",
      " [ 0.13354667  0.09932533  0.06426933 ...  0.20866667  0.177784\n",
      "   0.16609867]\n",
      " [ 0.13688533  0.11268     0.08430133 ... -0.17611467 -0.29714133\n",
      "  -0.38394667]]\n",
      "Shape of Input Data = (15169, 1600)\n",
      "Shape of Label Y_CNN = (15169, 10)\n",
      "Shape of Label Y = (15169, 1)\n"
     ]
    }
   ],
   "source": [
    "Data = ImportData()\n",
    "interval_length = 320 #1600  #290 #200  \n",
    "samples_per_block = 1600 #1296 #1650-25*2\n",
    "\n",
    "\n",
    "# Y_CNN is of shape (n, 10) representing 10 classes as 10 columns. In each sample, for the class to which it belongs, \n",
    "# the corresponding column value is marked 1 and the rest as 0, facilitating Softmax implementation in CNN \n",
    "# Y is of shape (m, 1) where column values are between 0 and 9 representing the classes directly. - 1-hot encoding\n",
    "X, Y_CNN, Y = DataPreparation(Data, interval_length, samples_per_block) \n",
    "\n",
    "\n",
    "print('Shape of Input Data =', X.shape)\n",
    "print('Shape of Label Y_CNN =', Y_CNN.shape)\n",
    "print('Shape of Label Y =', Y.shape)\n",
    "\n",
    "# XX = {'X':X}\n",
    "# scipy.io.savemat('Data.mat', XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaaee3ff-4250-4baf-bf15-23256e6d8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15169, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Training\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "## 2-Dimensional Convolutional Neural Network Classification\n",
    "\n",
    "# Reshape the data - 2 dimensional feed \n",
    "Input_2D = X.reshape([-1,40,40,1])\n",
    "\n",
    "# Input_2D = X_image.reshape([-1,96,96,1])\n",
    "print(Input_2D.shape)\n",
    "\n",
    "# Test-Train Split \n",
    "X_2D_train, X_2D_test, y_2D_train, y_2D_test, y_label_train, y_label_test = train_test_split(Input_2D, Y_CNN, Y, train_size=0.8, test_size=0.2, random_state=42, stratify=Y)\n",
    "#(ensuring class balance via stratify=Y)\n",
    "# X_2D_train, X_2D_test, y_2D_train, y_2D_test = train_test_split(Input_2D, Y_CNN, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define the CNN Classification model\n",
    "class CNN_2D():\n",
    "  def __init__(self):\n",
    "    self.model = self.CreateModel()\n",
    "\n",
    "  def CreateModel(self):\n",
    "    model = models.Sequential([\n",
    "        # layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding ='same',activation='relu'),\n",
    "        layers.Conv2D(filters=16, kernel_size=(3,3), padding='same',activation='relu', input_shape=(40,40,1)),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=32, kernel_size=(3,3), padding ='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=64, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3,3),padding ='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100,activation='relu'),\n",
    "        layers.Dense(50,activation='relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Softmax()\n",
    "        ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecf41e7c-a3e8-4875-ac08-918e90ad86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gayathri/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:21:24.239599: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 17:21:24.240764: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5019 - loss: 1.3269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:21:36.800465: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 17:21:36.800898: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88628, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.5032 - loss: 1.3234 - val_accuracy: 0.8863 - val_loss: 0.2893\n",
      "Epoch 2/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8485 - loss: 0.3751\n",
      "Epoch 2: val_accuracy improved from 0.88628 to 0.89493, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.8485 - loss: 0.3749 - val_accuracy: 0.8949 - val_loss: 0.2397\n",
      "Epoch 3/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8836 - loss: 0.2623\n",
      "Epoch 3: val_accuracy improved from 0.89493 to 0.92501, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.8836 - loss: 0.2622 - val_accuracy: 0.9250 - val_loss: 0.1792\n",
      "Epoch 4/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9003 - loss: 0.2270\n",
      "Epoch 4: val_accuracy improved from 0.92501 to 0.94561, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9004 - loss: 0.2269 - val_accuracy: 0.9456 - val_loss: 0.1264\n",
      "Epoch 5/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9373 - loss: 0.1518\n",
      "Epoch 5: val_accuracy did not improve from 0.94561\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9373 - loss: 0.1517 - val_accuracy: 0.9431 - val_loss: 0.1364\n",
      "Epoch 6/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9633 - loss: 0.0976\n",
      "Epoch 6: val_accuracy improved from 0.94561 to 0.97281, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.9634 - loss: 0.0975 - val_accuracy: 0.9728 - val_loss: 0.0669\n",
      "Epoch 7/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9743 - loss: 0.0705\n",
      "Epoch 7: val_accuracy improved from 0.97281 to 0.98888, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9743 - loss: 0.0705 - val_accuracy: 0.9889 - val_loss: 0.0343\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9794 - loss: 0.0540\n",
      "Epoch 8: val_accuracy improved from 0.98888 to 0.99135, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.9794 - loss: 0.0540 - val_accuracy: 0.9913 - val_loss: 0.0271\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9794 - loss: 0.0670\n",
      "Epoch 9: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9794 - loss: 0.0669 - val_accuracy: 0.9819 - val_loss: 0.0454\n",
      "Epoch 10/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9906 - loss: 0.0264\n",
      "Epoch 10: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9906 - loss: 0.0264 - val_accuracy: 0.9901 - val_loss: 0.0274\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9924 - loss: 0.0215\n",
      "Epoch 11: val_accuracy did not improve from 0.99135\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9924 - loss: 0.0216 - val_accuracy: 0.9897 - val_loss: 0.0324\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9855 - loss: 0.0474\n",
      "Epoch 12: val_accuracy improved from 0.99135 to 0.99629, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9855 - loss: 0.0473 - val_accuracy: 0.9963 - val_loss: 0.0172\n",
      "Epoch 13/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9895 - loss: 0.0302\n",
      "Epoch 13: val_accuracy improved from 0.99629 to 0.99670, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9895 - loss: 0.0302 - val_accuracy: 0.9967 - val_loss: 0.0114\n",
      "Epoch 14/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9928 - loss: 0.0199\n",
      "Epoch 14: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9928 - loss: 0.0199 - val_accuracy: 0.9922 - val_loss: 0.0236\n",
      "Epoch 15/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9791 - loss: 0.0801\n",
      "Epoch 15: val_accuracy improved from 0.99670 to 0.99753, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9793 - loss: 0.0797 - val_accuracy: 0.9975 - val_loss: 0.0113\n",
      "Epoch 16/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9922 - loss: 0.0266\n",
      "Epoch 16: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.9922 - loss: 0.0266 - val_accuracy: 0.9967 - val_loss: 0.0117\n",
      "Epoch 17/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9954 - loss: 0.0132\n",
      "Epoch 17: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.9954 - loss: 0.0132 - val_accuracy: 0.9971 - val_loss: 0.0098\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9945 - loss: 0.0138\n",
      "Epoch 18: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9945 - loss: 0.0138 - val_accuracy: 0.9975 - val_loss: 0.0104\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9929 - loss: 0.0196\n",
      "Epoch 19: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.9929 - loss: 0.0195 - val_accuracy: 0.9971 - val_loss: 0.0118\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.7923e-04\n",
      "Epoch 20: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.8164e-04 - val_accuracy: 0.9967 - val_loss: 0.0106\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 21: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9975 - val_loss: 0.0081\n",
      "Epoch 22/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4632e-04\n",
      "Epoch 22: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4657e-04 - val_accuracy: 0.9971 - val_loss: 0.0078\n",
      "Epoch 23/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.6883e-05\n",
      "Epoch 23: val_accuracy improved from 0.99753 to 0.99794, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.6879e-05 - val_accuracy: 0.9979 - val_loss: 0.0080\n",
      "Epoch 24/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.8055e-05\n",
      "Epoch 24: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8048e-05 - val_accuracy: 0.9979 - val_loss: 0.0084\n",
      "Epoch 25/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.7903e-05\n",
      "Epoch 25: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.7906e-05 - val_accuracy: 0.9979 - val_loss: 0.0086\n",
      "Epoch 26/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.2087e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.2089e-05 - val_accuracy: 0.9979 - val_loss: 0.0089\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.7663e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.7667e-05 - val_accuracy: 0.9979 - val_loss: 0.0092\n",
      "Epoch 28/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.4356e-05\n",
      "Epoch 28: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4359e-05 - val_accuracy: 0.9979 - val_loss: 0.0093\n",
      "Epoch 29/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1765e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.1766e-05 - val_accuracy: 0.9979 - val_loss: 0.0095\n",
      "Epoch 30/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.7102e-06\n",
      "Epoch 30: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.7107e-06 - val_accuracy: 0.9979 - val_loss: 0.0096\n",
      "Epoch 31/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.0608e-06\n",
      "Epoch 31: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.0612e-06 - val_accuracy: 0.9979 - val_loss: 0.0097\n",
      "Epoch 32/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.7364e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.7366e-06 - val_accuracy: 0.9979 - val_loss: 0.0098\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.6449e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.6450e-06 - val_accuracy: 0.9979 - val_loss: 0.0099\n",
      "Epoch 34/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.7525e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.7524e-06 - val_accuracy: 0.9979 - val_loss: 0.0100\n",
      "Epoch 35/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.0009e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.0008e-06 - val_accuracy: 0.9979 - val_loss: 0.0101\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.3823e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 3.3821e-06 - val_accuracy: 0.9979 - val_loss: 0.0102\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.8599e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.8597e-06 - val_accuracy: 0.9979 - val_loss: 0.0103\n",
      "Epoch 38/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.4244e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 2.4242e-06 - val_accuracy: 0.9979 - val_loss: 0.0104\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.0492e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.0490e-06 - val_accuracy: 0.9979 - val_loss: 0.0105\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7327e-06\n",
      "Epoch 40: val_accuracy improved from 0.99794 to 0.99835, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.7325e-06 - val_accuracy: 0.9984 - val_loss: 0.0106\n",
      "Epoch 41/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.4647e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4646e-06 - val_accuracy: 0.9984 - val_loss: 0.0107\n",
      "Epoch 42/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2375e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2373e-06 - val_accuracy: 0.9984 - val_loss: 0.0109\n",
      "Epoch 43/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0478e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0477e-06 - val_accuracy: 0.9984 - val_loss: 0.0110\n",
      "Epoch 44/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.8536e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.8516e-07 - val_accuracy: 0.9984 - val_loss: 0.0111\n",
      "Epoch 45/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.4798e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.4780e-07 - val_accuracy: 0.9984 - val_loss: 0.0112\n",
      "Epoch 46/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.2977e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.2969e-07 - val_accuracy: 0.9984 - val_loss: 0.0113\n",
      "Epoch 47/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.2972e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.2964e-07 - val_accuracy: 0.9984 - val_loss: 0.0114\n",
      "Epoch 48/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.4678e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4658e-07 - val_accuracy: 0.9984 - val_loss: 0.0115\n",
      "Epoch 49/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.7543e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7531e-07 - val_accuracy: 0.9984 - val_loss: 0.0116\n",
      "Epoch 50/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.1627e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.1622e-07 - val_accuracy: 0.9984 - val_loss: 0.0117\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.6467e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.6458e-07 - val_accuracy: 0.9984 - val_loss: 0.0118\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2145e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2138e-07 - val_accuracy: 0.9984 - val_loss: 0.0119\n",
      "Epoch 53/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8597e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8594e-07 - val_accuracy: 0.9984 - val_loss: 0.0120\n",
      "Epoch 54/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5614e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5612e-07 - val_accuracy: 0.9984 - val_loss: 0.0121\n",
      "Epoch 55/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3117e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3115e-07 - val_accuracy: 0.9984 - val_loss: 0.0122\n",
      "Epoch 56/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1107e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1103e-07 - val_accuracy: 0.9984 - val_loss: 0.0123\n",
      "Epoch 57/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.3516e-08\n",
      "Epoch 57: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.3480e-08 - val_accuracy: 0.9984 - val_loss: 0.0124\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.8546e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.8516e-08 - val_accuracy: 0.9984 - val_loss: 0.0125\n",
      "Epoch 59/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.6202e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.6190e-08 - val_accuracy: 0.9984 - val_loss: 0.0126\n",
      "Epoch 60/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.6042e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.6030e-08 - val_accuracy: 0.9984 - val_loss: 0.0127\n",
      "Epoch 61/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.7121e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.7112e-08 - val_accuracy: 0.9984 - val_loss: 0.0128\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.9915e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.9900e-08 - val_accuracy: 0.9984 - val_loss: 0.0129\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.3365e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.3352e-08 - val_accuracy: 0.9984 - val_loss: 0.0130\n",
      "Epoch 64/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.8317e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.8312e-08 - val_accuracy: 0.9984 - val_loss: 0.0131\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4009e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4000e-08 - val_accuracy: 0.9984 - val_loss: 0.0133\n",
      "Epoch 66/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0263e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0253e-08 - val_accuracy: 0.9984 - val_loss: 0.0134\n",
      "Epoch 67/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.7204e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7201e-08 - val_accuracy: 0.9984 - val_loss: 0.0135\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4755e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4748e-08 - val_accuracy: 0.9984 - val_loss: 0.0136\n",
      "Epoch 69/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2497e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2494e-08 - val_accuracy: 0.9984 - val_loss: 0.0136\n",
      "Epoch 70/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0597e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0592e-08 - val_accuracy: 0.9984 - val_loss: 0.0138\n",
      "Epoch 71/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.9419e-09\n",
      "Epoch 71: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.9361e-09 - val_accuracy: 0.9984 - val_loss: 0.0139\n",
      "Epoch 72/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.6532e-09\n",
      "Epoch 72: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.6502e-09 - val_accuracy: 0.9984 - val_loss: 0.0140\n",
      "Epoch 73/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.4207e-09\n",
      "Epoch 73: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.4187e-09 - val_accuracy: 0.9984 - val_loss: 0.0141\n",
      "Epoch 74/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.4211e-09\n",
      "Epoch 74: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.4197e-09 - val_accuracy: 0.9984 - val_loss: 0.0142\n",
      "Epoch 75/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7083e-09\n",
      "Epoch 75: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.7068e-09 - val_accuracy: 0.9984 - val_loss: 0.0143\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.0313e-09\n",
      "Epoch 76: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0299e-09 - val_accuracy: 0.9984 - val_loss: 0.0145\n",
      "Epoch 77/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.4048e-09\n",
      "Epoch 77: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4041e-09 - val_accuracy: 0.9984 - val_loss: 0.0145\n",
      "Epoch 78/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.8901e-09\n",
      "Epoch 78: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8894e-09 - val_accuracy: 0.9984 - val_loss: 0.0146\n",
      "Epoch 79/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.5372e-09\n",
      "Epoch 79: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.5366e-09 - val_accuracy: 0.9984 - val_loss: 0.0146\n",
      "Epoch 80/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0326e-09\n",
      "Epoch 80: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0327e-09 - val_accuracy: 0.9984 - val_loss: 0.0148\n",
      "Epoch 81/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7293e-09\n",
      "Epoch 81: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7294e-09 - val_accuracy: 0.9984 - val_loss: 0.0148\n",
      "Epoch 82/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6034e-09\n",
      "Epoch 82: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6034e-09 - val_accuracy: 0.9979 - val_loss: 0.0149\n",
      "Epoch 83/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3756e-09\n",
      "Epoch 83: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3755e-09 - val_accuracy: 0.9984 - val_loss: 0.0150\n",
      "Epoch 84/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1096e-09\n",
      "Epoch 84: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1097e-09 - val_accuracy: 0.9979 - val_loss: 0.0150\n",
      "Epoch 85/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.9669e-10\n",
      "Epoch 85: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.9673e-10 - val_accuracy: 0.9979 - val_loss: 0.0150\n",
      "Epoch 86/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.4419e-10\n",
      "Epoch 86: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.4416e-10 - val_accuracy: 0.9979 - val_loss: 0.0151\n",
      "Epoch 87/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.7972e-10\n",
      "Epoch 87: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 7.7951e-10 - val_accuracy: 0.9984 - val_loss: 0.0153\n",
      "Epoch 88/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.2533e-10\n",
      "Epoch 88: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.2472e-10 - val_accuracy: 0.9984 - val_loss: 0.0153\n",
      "Epoch 89/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.0480e-10\n",
      "Epoch 89: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.0462e-10 - val_accuracy: 0.9984 - val_loss: 0.0155\n",
      "Epoch 90/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.9580e-10\n",
      "Epoch 90: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.9593e-10 - val_accuracy: 0.9979 - val_loss: 0.0155\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m 6/76\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:40:59.616890: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-05 17:40:59.617269: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.4059e-06\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0062\n",
      "\u001b[1m10/95\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:41:05.861312: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 17:41:05.861845: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0069\n",
      "Epoch 1/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4707 - loss: 1.3384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:41:21.434726: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 17:41:21.435067: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76102, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4718 - loss: 1.3355 - val_accuracy: 0.7610 - val_loss: 0.6185\n",
      "Epoch 2/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8217 - loss: 0.4061\n",
      "Epoch 2: val_accuracy improved from 0.76102 to 0.83024, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.8218 - loss: 0.4058 - val_accuracy: 0.8302 - val_loss: 0.3680\n",
      "Epoch 3/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8784 - loss: 0.2373\n",
      "Epoch 3: val_accuracy improved from 0.83024 to 0.87763, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.8785 - loss: 0.2372 - val_accuracy: 0.8776 - val_loss: 0.2523\n",
      "Epoch 4/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9053 - loss: 0.2006\n",
      "Epoch 4: val_accuracy improved from 0.87763 to 0.91883, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.9054 - loss: 0.2005 - val_accuracy: 0.9188 - val_loss: 0.1682\n",
      "Epoch 5/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9263 - loss: 0.1621\n",
      "Epoch 5: val_accuracy improved from 0.91883 to 0.95880, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9263 - loss: 0.1621 - val_accuracy: 0.9588 - val_loss: 0.1136\n",
      "Epoch 6/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9583 - loss: 0.0985\n",
      "Epoch 6: val_accuracy improved from 0.95880 to 0.96457, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9584 - loss: 0.0985 - val_accuracy: 0.9646 - val_loss: 0.0859\n",
      "Epoch 7/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9713 - loss: 0.0775\n",
      "Epoch 7: val_accuracy improved from 0.96457 to 0.97487, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9713 - loss: 0.0775 - val_accuracy: 0.9749 - val_loss: 0.0630\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9806 - loss: 0.0495\n",
      "Epoch 8: val_accuracy did not improve from 0.97487\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9806 - loss: 0.0495 - val_accuracy: 0.9600 - val_loss: 0.1013\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9853 - loss: 0.0380\n",
      "Epoch 9: val_accuracy improved from 0.97487 to 0.98105, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9853 - loss: 0.0379 - val_accuracy: 0.9810 - val_loss: 0.0469\n",
      "Epoch 10/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9876 - loss: 0.0346\n",
      "Epoch 10: val_accuracy improved from 0.98105 to 0.98764, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9876 - loss: 0.0346 - val_accuracy: 0.9876 - val_loss: 0.0320\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9880 - loss: 0.0321\n",
      "Epoch 11: val_accuracy did not improve from 0.98764\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9880 - loss: 0.0321 - val_accuracy: 0.9782 - val_loss: 0.0609\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9874 - loss: 0.0298\n",
      "Epoch 12: val_accuracy did not improve from 0.98764\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9874 - loss: 0.0298 - val_accuracy: 0.9864 - val_loss: 0.0324\n",
      "Epoch 13/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9734 - loss: 0.0727\n",
      "Epoch 13: val_accuracy improved from 0.98764 to 0.98888, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9734 - loss: 0.0725 - val_accuracy: 0.9889 - val_loss: 0.0289\n",
      "Epoch 14/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9917 - loss: 0.0262\n",
      "Epoch 14: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9917 - loss: 0.0262 - val_accuracy: 0.9683 - val_loss: 0.0921\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9932 - loss: 0.0189\n",
      "Epoch 15: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9933 - loss: 0.0188 - val_accuracy: 0.9860 - val_loss: 0.0366\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0041\n",
      "Epoch 16: val_accuracy did not improve from 0.98888\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.9852 - val_loss: 0.0464\n",
      "Epoch 17/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9948 - loss: 0.0159\n",
      "Epoch 17: val_accuracy improved from 0.98888 to 0.99135, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.0159 - val_accuracy: 0.9913 - val_loss: 0.0226\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9994 - loss: 0.0032\n",
      "Epoch 18: val_accuracy improved from 0.99135 to 0.99835, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9984 - val_loss: 0.0078\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.8008e-04\n",
      "Epoch 19: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.7980e-04 - val_accuracy: 0.9967 - val_loss: 0.0089\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9964 - loss: 0.0132\n",
      "Epoch 20: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9964 - loss: 0.0134 - val_accuracy: 0.9868 - val_loss: 0.0329\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0076\n",
      "Epoch 21: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.9934 - val_loss: 0.0184\n",
      "Epoch 22/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9966 - loss: 0.0116\n",
      "Epoch 22: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9963 - val_loss: 0.0122\n",
      "Epoch 23/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9909 - loss: 0.0291\n",
      "Epoch 23: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9909 - loss: 0.0291 - val_accuracy: 0.9926 - val_loss: 0.0217\n",
      "Epoch 24/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9909 - loss: 0.0281\n",
      "Epoch 24: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9909 - loss: 0.0280 - val_accuracy: 0.9955 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9847 - loss: 0.0649\n",
      "Epoch 25: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9847 - loss: 0.0648 - val_accuracy: 0.9975 - val_loss: 0.0072\n",
      "Epoch 26/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9981 - loss: 0.0058\n",
      "Epoch 26: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9934 - val_loss: 0.0207\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9981 - loss: 0.0073\n",
      "Epoch 27: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9981 - loss: 0.0073 - val_accuracy: 0.9955 - val_loss: 0.0097\n",
      "Epoch 28/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.6963e-04\n",
      "Epoch 28: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.6893e-04 - val_accuracy: 0.9975 - val_loss: 0.0063\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.0645e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.0554e-05 - val_accuracy: 0.9979 - val_loss: 0.0068\n",
      "Epoch 30/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.2911e-05\n",
      "Epoch 30: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.2867e-05 - val_accuracy: 0.9979 - val_loss: 0.0069\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.9645e-05\n",
      "Epoch 31: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.9619e-05 - val_accuracy: 0.9979 - val_loss: 0.0070\n",
      "Epoch 32/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0987e-05\n",
      "Epoch 32: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.0958e-05 - val_accuracy: 0.9979 - val_loss: 0.0072\n",
      "Epoch 33/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4150e-05\n",
      "Epoch 33: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.4144e-05 - val_accuracy: 0.9975 - val_loss: 0.0075\n",
      "Epoch 34/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.1413e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.1337e-06 - val_accuracy: 0.9975 - val_loss: 0.0080\n",
      "Epoch 35/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.0908e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.0865e-06 - val_accuracy: 0.9975 - val_loss: 0.0083\n",
      "Epoch 36/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.2331e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.2319e-06 - val_accuracy: 0.9975 - val_loss: 0.0087\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.1434e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1418e-06 - val_accuracy: 0.9979 - val_loss: 0.0091\n",
      "Epoch 38/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.4401e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.4383e-06 - val_accuracy: 0.9979 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.9386e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9373e-06 - val_accuracy: 0.9979 - val_loss: 0.0097\n",
      "Epoch 40/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5508e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5505e-06 - val_accuracy: 0.9979 - val_loss: 0.0100\n",
      "Epoch 41/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.2562e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2554e-06 - val_accuracy: 0.9979 - val_loss: 0.0102\n",
      "Epoch 42/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0297e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0292e-06 - val_accuracy: 0.9979 - val_loss: 0.0105\n",
      "Epoch 43/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.4683e-07\n",
      "Epoch 43: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.4649e-07 - val_accuracy: 0.9979 - val_loss: 0.0108\n",
      "Epoch 44/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.0926e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.0897e-07 - val_accuracy: 0.9979 - val_loss: 0.0111\n",
      "Epoch 45/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.0028e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.0004e-07 - val_accuracy: 0.9979 - val_loss: 0.0114\n",
      "Epoch 46/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.1505e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.1485e-07 - val_accuracy: 0.9979 - val_loss: 0.0116\n",
      "Epoch 47/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.4526e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.4518e-07 - val_accuracy: 0.9979 - val_loss: 0.0119\n",
      "Epoch 48/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.8224e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.8205e-07 - val_accuracy: 0.9979 - val_loss: 0.0121\n",
      "Epoch 49/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.2912e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.2907e-07 - val_accuracy: 0.9979 - val_loss: 0.0123\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.8206e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.8199e-07 - val_accuracy: 0.9979 - val_loss: 0.0125\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.4334e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.4328e-07 - val_accuracy: 0.9979 - val_loss: 0.0127\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.0899e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0896e-07 - val_accuracy: 0.9979 - val_loss: 0.0129\n",
      "Epoch 53/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.7943e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.7941e-07 - val_accuracy: 0.9975 - val_loss: 0.0131\n",
      "Epoch 54/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5507e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5505e-07 - val_accuracy: 0.9975 - val_loss: 0.0133\n",
      "Epoch 55/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3328e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3328e-07 - val_accuracy: 0.9975 - val_loss: 0.0135\n",
      "Epoch 56/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.1602e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1602e-07 - val_accuracy: 0.9975 - val_loss: 0.0138\n",
      "Epoch 57/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0003e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0004e-07 - val_accuracy: 0.9975 - val_loss: 0.0139\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.6508e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.6512e-08 - val_accuracy: 0.9975 - val_loss: 0.0141\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.4726e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.4732e-08 - val_accuracy: 0.9975 - val_loss: 0.0142\n",
      "Epoch 60/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.4493e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4500e-08 - val_accuracy: 0.9975 - val_loss: 0.0145\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.5602e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.5606e-08 - val_accuracy: 0.9975 - val_loss: 0.0147\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.7914e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.7919e-08 - val_accuracy: 0.9975 - val_loss: 0.0149\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.1381e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.1386e-08 - val_accuracy: 0.9975 - val_loss: 0.0150\n",
      "Epoch 64/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.5666e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.5675e-08 - val_accuracy: 0.9975 - val_loss: 0.0153\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.0926e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.0930e-08 - val_accuracy: 0.9975 - val_loss: 0.0155\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.6740e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.6743e-08 - val_accuracy: 0.9975 - val_loss: 0.0157\n",
      "Epoch 67/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.2757e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.2761e-08 - val_accuracy: 0.9975 - val_loss: 0.0158\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.9796e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.9800e-08 - val_accuracy: 0.9975 - val_loss: 0.0162\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m11/76\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:54:04.526880: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-05 17:54:04.529226: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1372e-04\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0076\n",
      "\u001b[1m19/95\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0013    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:54:10.069005: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 17:54:10.069301: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0041\n",
      "Epoch 1/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4918 - loss: 1.3351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 17:54:21.912148: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 17:54:21.912414: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86815, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - accuracy: 0.4937 - loss: 1.3302 - val_accuracy: 0.8681 - val_loss: 0.3461\n",
      "Epoch 2/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8744 - loss: 0.3027\n",
      "Epoch 2: val_accuracy improved from 0.86815 to 0.91306, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.8744 - loss: 0.3026 - val_accuracy: 0.9131 - val_loss: 0.2066\n",
      "Epoch 3/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9004 - loss: 0.2384\n",
      "Epoch 3: val_accuracy did not improve from 0.91306\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9004 - loss: 0.2383 - val_accuracy: 0.8912 - val_loss: 0.2368\n",
      "Epoch 4/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9351 - loss: 0.1580\n",
      "Epoch 4: val_accuracy improved from 0.91306 to 0.94561, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9352 - loss: 0.1579 - val_accuracy: 0.9456 - val_loss: 0.1480\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9534 - loss: 0.1118\n",
      "Epoch 5: val_accuracy improved from 0.94561 to 0.98146, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9535 - loss: 0.1116 - val_accuracy: 0.9815 - val_loss: 0.0589\n",
      "Epoch 6/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9705 - loss: 0.0806\n",
      "Epoch 6: val_accuracy did not improve from 0.98146\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9705 - loss: 0.0806 - val_accuracy: 0.9650 - val_loss: 0.0898\n",
      "Epoch 7/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9775 - loss: 0.0637\n",
      "Epoch 7: val_accuracy did not improve from 0.98146\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9775 - loss: 0.0637 - val_accuracy: 0.9687 - val_loss: 0.0844\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9795 - loss: 0.0620\n",
      "Epoch 8: val_accuracy did not improve from 0.98146\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9795 - loss: 0.0622 - val_accuracy: 0.9769 - val_loss: 0.0658\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9787 - loss: 0.0583\n",
      "Epoch 9: val_accuracy did not improve from 0.98146\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9787 - loss: 0.0582 - val_accuracy: 0.9683 - val_loss: 0.0819\n",
      "Epoch 10/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9910 - loss: 0.0296\n",
      "Epoch 10: val_accuracy did not improve from 0.98146\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.0296 - val_accuracy: 0.9757 - val_loss: 0.0621\n",
      "Epoch 11/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9791 - loss: 0.0617\n",
      "Epoch 11: val_accuracy did not improve from 0.98146\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9792 - loss: 0.0615 - val_accuracy: 0.9588 - val_loss: 0.1096\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9881 - loss: 0.0387\n",
      "Epoch 12: val_accuracy improved from 0.98146 to 0.99506, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9881 - loss: 0.0387 - val_accuracy: 0.9951 - val_loss: 0.0169\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9898 - loss: 0.0291\n",
      "Epoch 13: val_accuracy improved from 0.99506 to 0.99670, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9898 - loss: 0.0291 - val_accuracy: 0.9967 - val_loss: 0.0149\n",
      "Epoch 14/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9822 - loss: 0.0544\n",
      "Epoch 14: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9822 - loss: 0.0545 - val_accuracy: 0.9757 - val_loss: 0.0698\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9944 - loss: 0.0181\n",
      "Epoch 15: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9944 - loss: 0.0181 - val_accuracy: 0.9934 - val_loss: 0.0173\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0066\n",
      "Epoch 16: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9959 - val_loss: 0.0116\n",
      "Epoch 17/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9900 - loss: 0.0328\n",
      "Epoch 17: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9900 - loss: 0.0329 - val_accuracy: 0.9938 - val_loss: 0.0163\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9951 - loss: 0.0148\n",
      "Epoch 18: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9951 - loss: 0.0148 - val_accuracy: 0.9955 - val_loss: 0.0123\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0050\n",
      "Epoch 19: val_accuracy did not improve from 0.99670\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.9930 - val_loss: 0.0231\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9910 - loss: 0.0280\n",
      "Epoch 20: val_accuracy improved from 0.99670 to 0.99712, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9910 - loss: 0.0280 - val_accuracy: 0.9971 - val_loss: 0.0081\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 21: val_accuracy did not improve from 0.99712\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9967 - val_loss: 0.0074\n",
      "Epoch 22/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9928 - loss: 0.0309\n",
      "Epoch 22: val_accuracy did not improve from 0.99712\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9928 - loss: 0.0311 - val_accuracy: 0.9959 - val_loss: 0.0140\n",
      "Epoch 23/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9960 - loss: 0.0097\n",
      "Epoch 23: val_accuracy did not improve from 0.99712\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9960 - loss: 0.0096 - val_accuracy: 0.9955 - val_loss: 0.0108\n",
      "Epoch 24/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0020\n",
      "Epoch 24: val_accuracy improved from 0.99712 to 0.99753, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9975 - val_loss: 0.0056\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9843 - loss: 0.0480\n",
      "Epoch 25: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9843 - loss: 0.0479 - val_accuracy: 0.9967 - val_loss: 0.0085\n",
      "Epoch 26/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9985 - loss: 0.0037\n",
      "Epoch 26: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9955 - val_loss: 0.0093\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.9471e-04\n",
      "Epoch 27: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.9452e-04 - val_accuracy: 0.9959 - val_loss: 0.0093\n",
      "Epoch 28/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1913e-04\n",
      "Epoch 28: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1897e-04 - val_accuracy: 0.9959 - val_loss: 0.0092\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.0795e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.0725e-05 - val_accuracy: 0.9959 - val_loss: 0.0090\n",
      "Epoch 30/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.7995e-05\n",
      "Epoch 30: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.7927e-05 - val_accuracy: 0.9955 - val_loss: 0.0088\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.3214e-05\n",
      "Epoch 31: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.3182e-05 - val_accuracy: 0.9955 - val_loss: 0.0086\n",
      "Epoch 32/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.2983e-05\n",
      "Epoch 32: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.2960e-05 - val_accuracy: 0.9955 - val_loss: 0.0085\n",
      "Epoch 33/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.5653e-05\n",
      "Epoch 33: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.5628e-05 - val_accuracy: 0.9955 - val_loss: 0.0084\n",
      "Epoch 34/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.0260e-05\n",
      "Epoch 34: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0241e-05 - val_accuracy: 0.9959 - val_loss: 0.0082\n",
      "Epoch 35/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6153e-05\n",
      "Epoch 35: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6143e-05 - val_accuracy: 0.9959 - val_loss: 0.0081\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3030e-05\n",
      "Epoch 36: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3023e-05 - val_accuracy: 0.9963 - val_loss: 0.0080\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0569e-05\n",
      "Epoch 37: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0564e-05 - val_accuracy: 0.9963 - val_loss: 0.0079\n",
      "Epoch 38/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.6012e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.5943e-06 - val_accuracy: 0.9963 - val_loss: 0.0078\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.0743e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.0705e-06 - val_accuracy: 0.9963 - val_loss: 0.0077\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.8121e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.8091e-06 - val_accuracy: 0.9963 - val_loss: 0.0076\n",
      "Epoch 41/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.8017e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7993e-06 - val_accuracy: 0.9963 - val_loss: 0.0076\n",
      "Epoch 42/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.9766e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.9736e-06 - val_accuracy: 0.9963 - val_loss: 0.0075\n",
      "Epoch 43/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.2947e-06\n",
      "Epoch 43: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.2931e-06 - val_accuracy: 0.9967 - val_loss: 0.0074\n",
      "Epoch 44/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.7409e-06\n",
      "Epoch 44: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.7397e-06 - val_accuracy: 0.9967 - val_loss: 0.0074\n",
      "Epoch 45/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2830e-06\n",
      "Epoch 45: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.2820e-06 - val_accuracy: 0.9967 - val_loss: 0.0073\n",
      "Epoch 46/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9015e-06\n",
      "Epoch 46: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.9002e-06 - val_accuracy: 0.9967 - val_loss: 0.0072\n",
      "Epoch 47/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5888e-06\n",
      "Epoch 47: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5877e-06 - val_accuracy: 0.9967 - val_loss: 0.0072\n",
      "Epoch 48/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3233e-06\n",
      "Epoch 48: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3230e-06 - val_accuracy: 0.9967 - val_loss: 0.0071\n",
      "Epoch 49/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1095e-06\n",
      "Epoch 49: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.1087e-06 - val_accuracy: 0.9967 - val_loss: 0.0071\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.2711e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.2670e-07 - val_accuracy: 0.9967 - val_loss: 0.0070\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.7996e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.7962e-07 - val_accuracy: 0.9967 - val_loss: 0.0070\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.5452e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.5423e-07 - val_accuracy: 0.9967 - val_loss: 0.0069\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.5101e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.5076e-07 - val_accuracy: 0.9967 - val_loss: 0.0069\n",
      "Epoch 54/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.6229e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.6199e-07 - val_accuracy: 0.9967 - val_loss: 0.0068\n",
      "Epoch 55/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.8953e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.8935e-07 - val_accuracy: 0.9971 - val_loss: 0.0068\n",
      "Epoch 56/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.2711e-07\n",
      "Epoch 56: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.2689e-07 - val_accuracy: 0.9971 - val_loss: 0.0067\n",
      "Epoch 57/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.7528e-07\n",
      "Epoch 57: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.7515e-07 - val_accuracy: 0.9971 - val_loss: 0.0067\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.3204e-07\n",
      "Epoch 58: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.3193e-07 - val_accuracy: 0.9971 - val_loss: 0.0067\n",
      "Epoch 59/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9505e-07\n",
      "Epoch 59: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.9492e-07 - val_accuracy: 0.9975 - val_loss: 0.0066\n",
      "Epoch 60/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6358e-07\n",
      "Epoch 60: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6351e-07 - val_accuracy: 0.9975 - val_loss: 0.0066\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3817e-07\n",
      "Epoch 61: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3811e-07 - val_accuracy: 0.9971 - val_loss: 0.0067\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1574e-07\n",
      "Epoch 62: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1568e-07 - val_accuracy: 0.9975 - val_loss: 0.0066\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.7105e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.7065e-08 - val_accuracy: 0.9975 - val_loss: 0.0066\n",
      "Epoch 64/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.1861e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.1828e-08 - val_accuracy: 0.9975 - val_loss: 0.0067\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.9125e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.9096e-08 - val_accuracy: 0.9975 - val_loss: 0.0067\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.8327e-08\n",
      "Epoch 66: val_accuracy improved from 0.99753 to 0.99794, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.8304e-08 - val_accuracy: 0.9979 - val_loss: 0.0067\n",
      "Epoch 67/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.9712e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.9680e-08 - val_accuracy: 0.9979 - val_loss: 0.0067\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.1832e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.1814e-08 - val_accuracy: 0.9979 - val_loss: 0.0067\n",
      "Epoch 69/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.5459e-08\n",
      "Epoch 69: val_accuracy improved from 0.99794 to 0.99835, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.5444e-08 - val_accuracy: 0.9984 - val_loss: 0.0068\n",
      "Epoch 70/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.0072e-08\n",
      "Epoch 70: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.0060e-08 - val_accuracy: 0.9984 - val_loss: 0.0068\n",
      "Epoch 71/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.5585e-08\n",
      "Epoch 71: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5570e-08 - val_accuracy: 0.9984 - val_loss: 0.0068\n",
      "Epoch 72/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1504e-08\n",
      "Epoch 72: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1500e-08 - val_accuracy: 0.9984 - val_loss: 0.0069\n",
      "Epoch 73/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.8081e-08\n",
      "Epoch 73: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8071e-08 - val_accuracy: 0.9984 - val_loss: 0.0069\n",
      "Epoch 74/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5490e-08\n",
      "Epoch 74: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5481e-08 - val_accuracy: 0.9984 - val_loss: 0.0069\n",
      "Epoch 75/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3334e-08\n",
      "Epoch 75: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3328e-08 - val_accuracy: 0.9984 - val_loss: 0.0070\n",
      "Epoch 76/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1167e-08\n",
      "Epoch 76: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.1163e-08 - val_accuracy: 0.9984 - val_loss: 0.0071\n",
      "Epoch 77/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.5908e-09\n",
      "Epoch 77: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.5891e-09 - val_accuracy: 0.9984 - val_loss: 0.0071\n",
      "Epoch 78/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.1469e-09\n",
      "Epoch 78: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.1442e-09 - val_accuracy: 0.9984 - val_loss: 0.0072\n",
      "Epoch 79/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.9922e-09\n",
      "Epoch 79: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.9880e-09 - val_accuracy: 0.9984 - val_loss: 0.0072\n",
      "Epoch 80/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.9464e-09\n",
      "Epoch 80: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.9440e-09 - val_accuracy: 0.9984 - val_loss: 0.0072\n",
      "Epoch 81/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.0082e-09\n",
      "Epoch 81: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.0060e-09 - val_accuracy: 0.9984 - val_loss: 0.0074\n",
      "Epoch 82/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.2229e-09\n",
      "Epoch 82: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.2209e-09 - val_accuracy: 0.9984 - val_loss: 0.0074\n",
      "Epoch 83/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.7203e-09\n",
      "Epoch 83: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.7188e-09 - val_accuracy: 0.9984 - val_loss: 0.0075\n",
      "Epoch 84/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.1929e-09\n",
      "Epoch 84: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.1919e-09 - val_accuracy: 0.9984 - val_loss: 0.0075\n",
      "Epoch 85/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.8464e-09\n",
      "Epoch 85: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.8445e-09 - val_accuracy: 0.9984 - val_loss: 0.0075\n",
      "Epoch 86/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.4981e-09\n",
      "Epoch 86: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.4964e-09 - val_accuracy: 0.9984 - val_loss: 0.0077\n",
      "Epoch 87/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1329e-09\n",
      "Epoch 87: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.1317e-09 - val_accuracy: 0.9984 - val_loss: 0.0078\n",
      "Epoch 88/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7496e-09\n",
      "Epoch 88: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.7485e-09 - val_accuracy: 0.9984 - val_loss: 0.0078\n",
      "Epoch 89/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3870e-09\n",
      "Epoch 89: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3870e-09 - val_accuracy: 0.9984 - val_loss: 0.0078\n",
      "Epoch 90/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1368e-09\n",
      "Epoch 90: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1373e-09 - val_accuracy: 0.9984 - val_loss: 0.0080\n",
      "Epoch 91/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0470e-09\n",
      "Epoch 91: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0469e-09 - val_accuracy: 0.9984 - val_loss: 0.0080\n",
      "Epoch 92/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.3266e-10\n",
      "Epoch 92: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.3284e-10 - val_accuracy: 0.9984 - val_loss: 0.0081\n",
      "Epoch 93/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.8860e-10\n",
      "Epoch 93: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.8860e-10 - val_accuracy: 0.9984 - val_loss: 0.0081\n",
      "Epoch 94/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.4183e-10\n",
      "Epoch 94: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.4242e-10 - val_accuracy: 0.9984 - val_loss: 0.0080\n",
      "Epoch 95/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.8000e-10\n",
      "Epoch 95: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.8039e-10 - val_accuracy: 0.9984 - val_loss: 0.0083\n",
      "Epoch 96/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.4956e-10\n",
      "Epoch 96: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.4961e-10 - val_accuracy: 0.9984 - val_loss: 0.0080\n",
      "Epoch 97/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.0446e-10\n",
      "Epoch 97: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.0435e-10 - val_accuracy: 0.9984 - val_loss: 0.0083\n",
      "Epoch 98/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.6434e-10\n",
      "Epoch 98: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.6462e-10 - val_accuracy: 0.9984 - val_loss: 0.0081\n",
      "Epoch 99/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.1748e-10\n",
      "Epoch 99: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.1757e-10 - val_accuracy: 0.9984 - val_loss: 0.0082\n",
      "Epoch 100/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.1728e-10\n",
      "Epoch 100: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.1722e-10 - val_accuracy: 0.9984 - val_loss: 0.0082\n",
      "Epoch 101/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.7185e-10\n",
      "Epoch 101: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.7168e-10 - val_accuracy: 0.9984 - val_loss: 0.0082\n",
      "Epoch 102/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.7996e-10\n",
      "Epoch 102: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8024e-10 - val_accuracy: 0.9984 - val_loss: 0.0083\n",
      "Epoch 103/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.5569e-10\n",
      "Epoch 103: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.5546e-10 - val_accuracy: 0.9984 - val_loss: 0.0092\n",
      "Epoch 104/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6680e-10\n",
      "Epoch 104: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6685e-10 - val_accuracy: 0.9984 - val_loss: 0.0086\n",
      "Epoch 105/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.3881e-10\n",
      "Epoch 105: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.3811e-10 - val_accuracy: 0.9984 - val_loss: 0.0087\n",
      "Epoch 106/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6224e-10\n",
      "Epoch 106: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6230e-10 - val_accuracy: 0.9984 - val_loss: 0.0085\n",
      "Epoch 107/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.3458e-11\n",
      "Epoch 107: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.3483e-11 - val_accuracy: 0.9984 - val_loss: 0.0088\n",
      "Epoch 108/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0061\n",
      "Epoch 108: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0066 - val_accuracy: 0.8570 - val_loss: 0.4056\n",
      "Epoch 109/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9656 - loss: 0.1271\n",
      "Epoch 109: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9658 - loss: 0.1264 - val_accuracy: 0.9926 - val_loss: 0.0234\n",
      "Epoch 110/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9981 - loss: 0.0058\n",
      "Epoch 110: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9946 - val_loss: 0.0131\n",
      "Epoch 111/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9945 - loss: 0.0155\n",
      "Epoch 111: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9945 - loss: 0.0155 - val_accuracy: 0.9926 - val_loss: 0.0192\n",
      "Epoch 112/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.5834e-04\n",
      "Epoch 112: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5776e-04 - val_accuracy: 0.9938 - val_loss: 0.0146\n",
      "Epoch 113/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.1353e-05\n",
      "Epoch 113: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.1142e-05 - val_accuracy: 0.9951 - val_loss: 0.0143\n",
      "Epoch 114/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.9481e-05\n",
      "Epoch 114: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.9357e-05 - val_accuracy: 0.9951 - val_loss: 0.0139\n",
      "Epoch 115/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.3052e-05\n",
      "Epoch 115: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.2999e-05 - val_accuracy: 0.9951 - val_loss: 0.0136\n",
      "Epoch 116/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.3158e-05\n",
      "Epoch 116: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3105e-05 - val_accuracy: 0.9951 - val_loss: 0.0134\n",
      "Epoch 117/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6893e-05\n",
      "Epoch 117: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6869e-05 - val_accuracy: 0.9951 - val_loss: 0.0132\n",
      "Epoch 118/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2793e-05\n",
      "Epoch 118: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2767e-05 - val_accuracy: 0.9951 - val_loss: 0.0131\n",
      "Epoch 119/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.9371e-06\n",
      "Epoch 119: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.9173e-06 - val_accuracy: 0.9955 - val_loss: 0.0129\n",
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m11/76\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:15:29.916120: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-05 18:15:29.917066: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5098e-08\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0117\n",
      "\u001b[1m18/95\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:15:35.286259: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 18:15:35.286517: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0055\n",
      "Epoch 1/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4683 - loss: 1.3729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:15:47.982023: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 18:15:47.982286: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79604, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.4697 - loss: 1.3695 - val_accuracy: 0.7960 - val_loss: 0.5149\n",
      "Epoch 2/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8609 - loss: 0.3166\n",
      "Epoch 2: val_accuracy improved from 0.79604 to 0.87186, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.8611 - loss: 0.3161 - val_accuracy: 0.8719 - val_loss: 0.3127\n",
      "Epoch 3/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9174 - loss: 0.1976\n",
      "Epoch 3: val_accuracy did not improve from 0.87186\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9174 - loss: 0.1976 - val_accuracy: 0.8611 - val_loss: 0.3689\n",
      "Epoch 4/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9333 - loss: 0.1721\n",
      "Epoch 4: val_accuracy improved from 0.87186 to 0.92954, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9334 - loss: 0.1719 - val_accuracy: 0.9295 - val_loss: 0.1885\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9640 - loss: 0.0958\n",
      "Epoch 5: val_accuracy improved from 0.92954 to 0.95797, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9640 - loss: 0.0958 - val_accuracy: 0.9580 - val_loss: 0.1112\n",
      "Epoch 6/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9806 - loss: 0.0551\n",
      "Epoch 6: val_accuracy improved from 0.95797 to 0.98517, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9805 - loss: 0.0552 - val_accuracy: 0.9852 - val_loss: 0.0380\n",
      "Epoch 7/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9827 - loss: 0.0476\n",
      "Epoch 7: val_accuracy did not improve from 0.98517\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9826 - loss: 0.0478 - val_accuracy: 0.9798 - val_loss: 0.0705\n",
      "Epoch 8/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9874 - loss: 0.0378\n",
      "Epoch 8: val_accuracy improved from 0.98517 to 0.99052, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9874 - loss: 0.0378 - val_accuracy: 0.9905 - val_loss: 0.0333\n",
      "Epoch 9/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9922 - loss: 0.0232\n",
      "Epoch 9: val_accuracy did not improve from 0.99052\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9922 - loss: 0.0232 - val_accuracy: 0.9815 - val_loss: 0.0893\n",
      "Epoch 10/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9776 - loss: 0.0669\n",
      "Epoch 10: val_accuracy did not improve from 0.99052\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9776 - loss: 0.0670 - val_accuracy: 0.9901 - val_loss: 0.0251\n",
      "Epoch 11/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9906 - loss: 0.0251\n",
      "Epoch 11: val_accuracy improved from 0.99052 to 0.99464, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9906 - loss: 0.0251 - val_accuracy: 0.9946 - val_loss: 0.0155\n",
      "Epoch 12/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9964 - loss: 0.0113\n",
      "Epoch 12: val_accuracy did not improve from 0.99464\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9934 - val_loss: 0.0203\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9937 - loss: 0.0201\n",
      "Epoch 13: val_accuracy did not improve from 0.99464\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9937 - loss: 0.0201 - val_accuracy: 0.9934 - val_loss: 0.0182\n",
      "Epoch 14/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9907 - loss: 0.0398\n",
      "Epoch 14: val_accuracy did not improve from 0.99464\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9907 - loss: 0.0400 - val_accuracy: 0.9918 - val_loss: 0.0259\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9967 - loss: 0.0112\n",
      "Epoch 15: val_accuracy did not improve from 0.99464\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9967 - loss: 0.0112 - val_accuracy: 0.9918 - val_loss: 0.0232\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9962 - loss: 0.0101\n",
      "Epoch 16: val_accuracy improved from 0.99464 to 0.99794, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9962 - loss: 0.0101 - val_accuracy: 0.9979 - val_loss: 0.0054\n",
      "Epoch 17/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9965 - loss: 0.0097\n",
      "Epoch 17: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9965 - loss: 0.0097 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
      "Epoch 18/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 18: val_accuracy did not improve from 0.99794\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9971 - val_loss: 0.0055\n",
      "Epoch 19/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 4.5532e-04\n",
      "Epoch 19: val_accuracy improved from 0.99794 to 0.99835, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9999 - loss: 4.5602e-04 - val_accuracy: 0.9984 - val_loss: 0.0041\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.3380e-04\n",
      "Epoch 20: val_accuracy improved from 0.99835 to 0.99876, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3366e-04 - val_accuracy: 0.9988 - val_loss: 0.0045\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4264e-04\n",
      "Epoch 21: val_accuracy improved from 0.99876 to 0.99918, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.4240e-04 - val_accuracy: 0.9992 - val_loss: 0.0030\n",
      "Epoch 22/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.8821e-05\n",
      "Epoch 22: val_accuracy did not improve from 0.99918\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.8701e-05 - val_accuracy: 0.9992 - val_loss: 0.0025\n",
      "Epoch 23/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.1875e-05\n",
      "Epoch 23: val_accuracy did not improve from 0.99918\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.1766e-05 - val_accuracy: 0.9992 - val_loss: 0.0022\n",
      "Epoch 24/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.5129e-05\n",
      "Epoch 24: val_accuracy did not improve from 0.99918\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.5080e-05 - val_accuracy: 0.9992 - val_loss: 0.0020\n",
      "Epoch 25/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.4165e-05\n",
      "Epoch 25: val_accuracy improved from 0.99918 to 0.99959, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.4148e-05 - val_accuracy: 0.9996 - val_loss: 0.0020\n",
      "Epoch 26/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.6324e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.6286e-05 - val_accuracy: 0.9996 - val_loss: 0.0019\n",
      "Epoch 27/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.0784e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0755e-05 - val_accuracy: 0.9996 - val_loss: 0.0018\n",
      "Epoch 28/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6416e-05\n",
      "Epoch 28: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6394e-05 - val_accuracy: 0.9996 - val_loss: 0.0018\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3170e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3159e-05 - val_accuracy: 0.9996 - val_loss: 0.0018\n",
      "Epoch 30/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0644e-05\n",
      "Epoch 30: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0631e-05 - val_accuracy: 0.9996 - val_loss: 0.0017\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.6848e-06\n",
      "Epoch 31: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.6782e-06 - val_accuracy: 0.9996 - val_loss: 0.0017\n",
      "Epoch 32/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.1650e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.1571e-06 - val_accuracy: 0.9996 - val_loss: 0.0017\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.8884e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.8843e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.8719e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.8686e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.0300e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.0261e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 36/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.3483e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.3462e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.7869e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.7852e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.3101e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.3081e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 39/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9224e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.9213e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 40/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6041e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6032e-06 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3355e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3344e-06 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 42/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1132e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1123e-06 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.2552e-07\n",
      "Epoch 43: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.2478e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.7265e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.7224e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.4495e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.4445e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 46/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.3818e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.3777e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 47/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.4938e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4915e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 48/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.7581e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.7553e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 49/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1513e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.1497e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.6463e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.6450e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.2158e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.2147e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 52/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.8549e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8541e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5520e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5513e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 54/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3038e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3032e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 55/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0956e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0951e-07 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Epoch 56/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.2063e-08\n",
      "Epoch 56: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.2005e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 57/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.7486e-08\n",
      "Epoch 57: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.7470e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.5039e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.5012e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 59/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.4899e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.4878e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 60/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.6472e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.6454e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.9055e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.9041e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.2951e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.2939e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.7737e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.7727e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 64/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.3655e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3647e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9874e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.9868e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 66/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.6928e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6920e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 67/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4407e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4402e-08 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 68/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2256e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2253e-08 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 69/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0308e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0306e-08 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 70/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.7769e-09\n",
      "Epoch 70: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.7734e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.4530e-09\n",
      "Epoch 71: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.4513e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 72/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.3875e-09\n",
      "Epoch 72: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.3854e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 73/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.4431e-09\n",
      "Epoch 73: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.4411e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 74/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.5896e-09\n",
      "Epoch 74: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.5890e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 75/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.0719e-09\n",
      "Epoch 75: val_accuracy did not improve from 0.99959\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.0706e-09 - val_accuracy: 0.9996 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_4.h5\n",
      "Best model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:29:17.662945: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-05 18:29:17.663963: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.1111e-05\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0015\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:29:23.630498: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 18:29:23.630833: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5238 - loss: 1.2454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:29:34.612174: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 18:29:34.612790: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88422, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.5257 - loss: 1.2404 - val_accuracy: 0.8842 - val_loss: 0.2710\n",
      "Epoch 2/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8673 - loss: 0.3043\n",
      "Epoch 2: val_accuracy improved from 0.88422 to 0.91842, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.8674 - loss: 0.3040 - val_accuracy: 0.9184 - val_loss: 0.1804\n",
      "Epoch 3/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9135 - loss: 0.1920\n",
      "Epoch 3: val_accuracy improved from 0.91842 to 0.95097, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9135 - loss: 0.1919 - val_accuracy: 0.9510 - val_loss: 0.1239\n",
      "Epoch 4/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9345 - loss: 0.1601\n",
      "Epoch 4: val_accuracy improved from 0.95097 to 0.97239, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9345 - loss: 0.1600 - val_accuracy: 0.9724 - val_loss: 0.0808\n",
      "Epoch 5/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9656 - loss: 0.0936\n",
      "Epoch 5: val_accuracy did not improve from 0.97239\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9656 - loss: 0.0936 - val_accuracy: 0.9687 - val_loss: 0.0727\n",
      "Epoch 6/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9753 - loss: 0.0668\n",
      "Epoch 6: val_accuracy did not improve from 0.97239\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9753 - loss: 0.0668 - val_accuracy: 0.9604 - val_loss: 0.0989\n",
      "Epoch 7/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9691 - loss: 0.0800\n",
      "Epoch 7: val_accuracy improved from 0.97239 to 0.98105, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9692 - loss: 0.0799 - val_accuracy: 0.9810 - val_loss: 0.0477\n",
      "Epoch 8/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9885 - loss: 0.0401\n",
      "Epoch 8: val_accuracy improved from 0.98105 to 0.98681, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9884 - loss: 0.0401 - val_accuracy: 0.9868 - val_loss: 0.0373\n",
      "Epoch 9/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9906 - loss: 0.0271\n",
      "Epoch 9: val_accuracy improved from 0.98681 to 0.98846, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9906 - loss: 0.0271 - val_accuracy: 0.9885 - val_loss: 0.0368\n",
      "Epoch 10/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9871 - loss: 0.0404\n",
      "Epoch 10: val_accuracy improved from 0.98846 to 0.99258, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9872 - loss: 0.0403 - val_accuracy: 0.9926 - val_loss: 0.0209\n",
      "Epoch 11/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9883 - loss: 0.0318\n",
      "Epoch 11: val_accuracy improved from 0.99258 to 0.99341, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9884 - loss: 0.0318 - val_accuracy: 0.9934 - val_loss: 0.0186\n",
      "Epoch 12/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9923 - loss: 0.0239\n",
      "Epoch 12: val_accuracy did not improve from 0.99341\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9923 - loss: 0.0241 - val_accuracy: 0.9860 - val_loss: 0.0414\n",
      "Epoch 13/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9964 - loss: 0.0109\n",
      "Epoch 13: val_accuracy improved from 0.99341 to 0.99629, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.9963 - val_loss: 0.0114\n",
      "Epoch 14/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9953 - loss: 0.0132\n",
      "Epoch 14: val_accuracy did not improve from 0.99629\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.9953 - loss: 0.0134 - val_accuracy: 0.9221 - val_loss: 0.3281\n",
      "Epoch 15/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9860 - loss: 0.0602\n",
      "Epoch 15: val_accuracy did not improve from 0.99629\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9860 - loss: 0.0601 - val_accuracy: 0.9959 - val_loss: 0.0139\n",
      "Epoch 16/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9984 - loss: 0.0048\n",
      "Epoch 16: val_accuracy did not improve from 0.99629\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9938 - val_loss: 0.0142\n",
      "Epoch 17/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9863 - loss: 0.0389\n",
      "Epoch 17: val_accuracy did not improve from 0.99629\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9863 - loss: 0.0388 - val_accuracy: 0.9963 - val_loss: 0.0134\n",
      "Epoch 18/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9981 - loss: 0.0059\n",
      "Epoch 18: val_accuracy did not improve from 0.99629\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9930 - val_loss: 0.0204\n",
      "Epoch 19/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9951 - loss: 0.0159\n",
      "Epoch 19: val_accuracy did not improve from 0.99629\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9951 - loss: 0.0159 - val_accuracy: 0.9901 - val_loss: 0.0264\n",
      "Epoch 20/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0044\n",
      "Epoch 20: val_accuracy improved from 0.99629 to 0.99753, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9975 - val_loss: 0.0072\n",
      "Epoch 21/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 6.0507e-04\n",
      "Epoch 21: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 6.0596e-04 - val_accuracy: 0.9951 - val_loss: 0.0186\n",
      "Epoch 22/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.7666e-04\n",
      "Epoch 22: val_accuracy did not improve from 0.99753\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.7488e-04 - val_accuracy: 0.9975 - val_loss: 0.0078\n",
      "Epoch 23/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.0784e-05\n",
      "Epoch 23: val_accuracy improved from 0.99753 to 0.99794, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.0791e-05 - val_accuracy: 0.9979 - val_loss: 0.0087\n",
      "Epoch 24/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.7829e-05\n",
      "Epoch 24: val_accuracy improved from 0.99794 to 0.99835, saving model to CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.7733e-05 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 25/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.5120e-05\n",
      "Epoch 25: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.5104e-05 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 26/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.5522e-05\n",
      "Epoch 26: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5511e-05 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 27/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.8935e-05\n",
      "Epoch 27: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.8933e-05 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 28/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.4390e-05\n",
      "Epoch 28: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4390e-05 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 29/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1334e-05\n",
      "Epoch 29: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1335e-05 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 30/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.2900e-06\n",
      "Epoch 30: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.2890e-06 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 31/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.3775e-06\n",
      "Epoch 31: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.3777e-06 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 32/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.0237e-06\n",
      "Epoch 32: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.0239e-06 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 33/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.0168e-06\n",
      "Epoch 33: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.0168e-06 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 34/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.1496e-06\n",
      "Epoch 34: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.1497e-06 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 35/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.4703e-06\n",
      "Epoch 35: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.4703e-06 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 36/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9056e-06\n",
      "Epoch 36: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.9056e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 37/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.4553e-06\n",
      "Epoch 37: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4553e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 38/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0558e-06\n",
      "Epoch 38: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0558e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 39/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.7259e-06\n",
      "Epoch 39: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.7258e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 40/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.4563e-06\n",
      "Epoch 40: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4562e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 41/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.2213e-06\n",
      "Epoch 41: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2212e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 42/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0326e-06\n",
      "Epoch 42: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0325e-06 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 43/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.6661e-07\n",
      "Epoch 43: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.6653e-07 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 44/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.3074e-07\n",
      "Epoch 44: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.3063e-07 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 45/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.1702e-07\n",
      "Epoch 45: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.1693e-07 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 46/200\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.2225e-07\n",
      "Epoch 46: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.2222e-07 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 47/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.3880e-07\n",
      "Epoch 47: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.3872e-07 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 48/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.7089e-07\n",
      "Epoch 48: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.7082e-07 - val_accuracy: 0.9984 - val_loss: 0.0058\n",
      "Epoch 49/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.1200e-07\n",
      "Epoch 49: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1194e-07 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 50/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.6314e-07\n",
      "Epoch 50: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.6311e-07 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 51/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2218e-07\n",
      "Epoch 51: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.2215e-07 - val_accuracy: 0.9984 - val_loss: 0.0057\n",
      "Epoch 52/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.8800e-07\n",
      "Epoch 52: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.8797e-07 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 53/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5895e-07\n",
      "Epoch 53: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5892e-07 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 54/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3462e-07\n",
      "Epoch 54: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3460e-07 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 55/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1420e-07\n",
      "Epoch 55: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1417e-07 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 56/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.6098e-08\n",
      "Epoch 56: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.6084e-08 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 57/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.1545e-08\n",
      "Epoch 57: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.1527e-08 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 58/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.8920e-08\n",
      "Epoch 58: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.8910e-08 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 59/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.8726e-08\n",
      "Epoch 59: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.8711e-08 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 60/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.9731e-08\n",
      "Epoch 60: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.9723e-08 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 61/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.2325e-08\n",
      "Epoch 61: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.2317e-08 - val_accuracy: 0.9984 - val_loss: 0.0056\n",
      "Epoch 62/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.5869e-08\n",
      "Epoch 62: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.5862e-08 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 63/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.0236e-08\n",
      "Epoch 63: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.0230e-08 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 64/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.5671e-08\n",
      "Epoch 64: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.5667e-08 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 65/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2055e-08\n",
      "Epoch 65: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.2051e-08 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 66/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.8612e-08\n",
      "Epoch 66: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.8610e-08 - val_accuracy: 0.9984 - val_loss: 0.0055\n",
      "Epoch 67/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5820e-08\n",
      "Epoch 67: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5817e-08 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 68/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3411e-08\n",
      "Epoch 68: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3408e-08 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 69/200\n",
      "\u001b[1m302/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1482e-08\n",
      "Epoch 69: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.1480e-08 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 70/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.6350e-09\n",
      "Epoch 70: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.6343e-09 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 71/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.3821e-09\n",
      "Epoch 71: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.3810e-09 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 72/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.2186e-09\n",
      "Epoch 72: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.2177e-09 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 73/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.3546e-09\n",
      "Epoch 73: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.3529e-09 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
      "Epoch 74/200\n",
      "\u001b[1m303/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.4147e-09\n",
      "Epoch 74: val_accuracy did not improve from 0.99835\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.4131e-09 - val_accuracy: 0.9984 - val_loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: CNN2D_results/V4_2_NOL_exp2/best_model_5.h5\n",
      "Best model loaded successfully!\n",
      "\u001b[1m11/76\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:43:13.412458: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-06-05 18:43:13.413621: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0140e-05\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0111\n",
      "\u001b[1m19/95\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:43:18.457939: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-06-05 18:43:18.458202: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0074\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation / 5 fold cross validation )\n",
    "kSplits = 5\n",
    "# kfold = KFold(n_splits=kSplits, random_state=42, shuffle=True)\n",
    "kfold = StratifiedKFold(n_splits=kSplits, random_state=42, shuffle=True) # splits training data into 5 folds - class balance(stratify)\n",
    "\n",
    "# File path name to save best models\n",
    "foldername = \"CNN2D_results/V4_2_NOL_exp2/\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint #Saves the model with the highest validation accuracy for each fold\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "pred_all_val = np.zeros([len(X_2D_train),10])\n",
    "y_2D_val = np.zeros([len(X_2D_train),10])\n",
    "kfold_test_len = []\n",
    "\n",
    "fl1 = 0\n",
    "k = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True) #Stops training if validation accuracy doesn’t improve for 50 epochs, restoring the best weights.\n",
    "\n",
    "# Train the model \n",
    "# for train, test in kfold.split(X_2D_train,y_2D_train):\n",
    "for fold, (train, test) in enumerate(kfold.split(X_2D_train, y_label_train)):   \n",
    "\n",
    "  # Define where to save the best model\n",
    "  checkpoint_filepath = foldername + \"best_model_\" + str(k) + \".h5\"\n",
    "    \n",
    "  # Create a ModelCheckpoint callback\n",
    "  checkpoint = ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_accuracy',  # Monitor validation accuracy\n",
    "      save_best_only=True,  # Save only the best model\n",
    "      mode='max',  # Maximize accuracy\n",
    "      verbose=1\n",
    "  )        \n",
    "\n",
    "#For each fold, trains a new CNN model on the training subset (X_2D_train[train], y_2D_train[train]) for up to 200 epochs.\n",
    "  Classification_2D = CNN_2D()\n",
    "  # history = Classification_2D.model.fit(X_2D_train[train], y_2D_train[train], verbose=1, epochs=50) #epochs=12\n",
    "  history = Classification_2D.model.fit(\n",
    "        X_2D_train[train], y_2D_train[train],\n",
    "        validation_data=(X_2D_train[test], y_2D_train[test]),  # Validation set for monitoring\n",
    "        epochs=200,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint, early_stop]  # Save the best model\n",
    "  )\n",
    "  \n",
    "  print(\"Best model saved at:\", checkpoint_filepath)\n",
    "  CNN_2D_best_model = load_model(checkpoint_filepath)\n",
    "  print(\"Best model loaded successfully!\")\n",
    "  \n",
    "  fl2 = fl1 + len(test)\n",
    "  pred_all_val[fl1:fl2,:] = CNN_2D_best_model.predict(X_2D_train[test])\n",
    "  y_2D_val[fl1:fl2,:] = y_2D_train[test]\n",
    "  kfold_test_len.append(fl2-fl1)\n",
    "  fl1 = fl2  \n",
    "\n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  train_loss, train_accuracy = CNN_2D_best_model.evaluate(X_2D_train[train], y_2D_train[train]) \n",
    "  accuracy_train.append(train_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  val_loss, val_accuracy = CNN_2D_best_model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  accuracy_val.append(val_accuracy)\n",
    "  \n",
    "  # Evaluate the accuracy of the model on the validation set \n",
    "  test_loss, test_accuracy = CNN_2D_best_model.evaluate(X_2D_test, y_2D_test) \n",
    "  accuracy_test.append(test_accuracy)  \n",
    "  \n",
    "  # Evaluate the accuracy of the model on the training set \n",
    "  # kf_loss, kf_accuracy = Classification_2D.model.evaluate(X_2D_train[test], y_2D_train[test]) \n",
    "  # accuracy_2D.append(kf_accuracy)\n",
    "  \n",
    "  k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7705181d-c6cb-4412-a002-8937240306ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 2D train accuracy = 100.0\n",
      "CNN 2D validation accuracy = 99.85990881919861\n",
      "CNN 2D test accuracy = 99.81542587280273\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiclass Classification CNN Model Evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Classification_2D.model.summary()\n",
    "\n",
    "CNN_2D_train_accuracy = np.average(accuracy_train)*100\n",
    "print('CNN 2D train accuracy =', CNN_2D_train_accuracy)\n",
    "# print(accuracy_train)\n",
    "\n",
    "CNN_2D_val_accuracy = np.average(accuracy_val)*100\n",
    "print('CNN 2D validation accuracy =', CNN_2D_val_accuracy)\n",
    "# print(accuracy_val)\n",
    "\n",
    "CNN_2D_test_accuracy = np.average(accuracy_test)*100\n",
    "print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "# print(accuracy_test)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test set\n",
    "# CNN_2D_test_loss, CNN_2D_test_accuracy = Classification_2D.model.evaluate(X_2D_test, y_2D_test)\n",
    "# CNN_2D_test_accuracy*=100\n",
    "# print('CNN 2D test accuracy =', CNN_2D_test_accuracy)\n",
    "\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "  y_pred = np.argmax(Model.predict(X), axis=1)\n",
    "  ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "  return ConfusionMat\n",
    "\n",
    "# Plot results - CNN 2D\n",
    "plt.figure(5)\n",
    "plt.title('Confusion Matrix - CNN 2D Train') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_train, y_2D_train) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.title('Confusion Matrix - CNN 2D Test') \n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_test, y_2D_test) , annot=True, fmt='d',annot_kws={\"fontsize\":8},cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7)\n",
    "plt.title('Train - Accuracy - CNN 2D')\n",
    "plt.bar(np.arange(1,kSplits+1),[i*100 for i in accuracy_val])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70,100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(8)\n",
    "plt.title('Train vs Test Accuracy - CNN 2D')\n",
    "plt.bar([1,2],[CNN_2D_train_accuracy,CNN_2D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.xticks([1,2],['Train', 'Test'])\n",
    "plt.ylim([70,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "923d304a-13a4-42ce-bd02-0c15bc3ecc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model summary for fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m115,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,014</span> (851.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m218,014\u001b[0m (851.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,012</span> (851.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m218,012\u001b[0m (851.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: conv2d\n",
      "1: max_pooling2d\n",
      "2: conv2d_1\n",
      "3: max_pooling2d_1\n",
      "4: conv2d_2\n",
      "5: max_pooling2d_2\n",
      "6: conv2d_3\n",
      "7: max_pooling2d_3\n",
      "8: flatten\n",
      "9: dense\n",
      "10: dense_1\n",
      "11: dense_2\n",
      "12: softmax\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m layer_name = \u001b[33m'\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# or whatever corresponds to Dense(100)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m intermediate_model = tf.keras.Model(inputs=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m, outputs=model.get_layer(layer_name).output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/ops/operation.py:276\u001b[39m, in \u001b[36mOperation.input\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[32m    269\u001b[39m \n\u001b[32m    270\u001b[39m \u001b[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_tensors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyenvs/tf-env/lib/python3.11/site-packages/keras/src/ops/operation.py:307\u001b[39m, in \u001b[36mOperation._get_node_attribute_at_index\u001b[39m\u001b[34m(self, node_index, attr, attr_name)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inbound_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    308\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has never been called \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m     )\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes) > node_index:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at node \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the operation has only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inbound nodes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# for i in range(1, 6):\n",
    "#     filepath = f\"CNN2D_results/V4_2_NOL_exp1/best_model_{i}.h5\"\n",
    "#     print(f\"\\nModel summary for fold {i}:\")\n",
    "#     model = load_model(filepath)\n",
    "#     model.summary()\n",
    "#     for i, layer in enumerate(model.layers):\n",
    "#         print(f\"{i}: {layer.name} — {layer.output_shape}\")\n",
    "\n",
    "\n",
    "filepath = f\"CNN2D_results/V4_2_NOL_exp1/best_model_1.h5\"\n",
    "print(f\"\\nModel summary for fold 1:\")\n",
    "model = load_model(filepath)\n",
    "model.summary()\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{i}: {layer.name}\")\n",
    "\n",
    "\n",
    "layer_name = 'dense'  # or whatever corresponds to Dense(100)\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b387e8-173c-4018-8896-a0340889bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sample training inputs (every 10th) and get intermediate outputs\n",
    "x_sampled = X_2D_train[::10]\n",
    "y_sampled = y_2D_train[::10]\n",
    "\n",
    "intermediate_outputs = intermediate_model.predict(x_sampled)\n",
    "\n",
    "# Step 2: Reduce dimensionality using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "x_embedded = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30).fit_transform(intermediate_outputs)\n",
    "\n",
    "# Step 3: Decode one-hot labels (if needed)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "if y_sampled.shape[1] > 1:\n",
    "    y_label = enc.inverse_transform(y_sampled)\n",
    "else:\n",
    "    y_label = y_sampled.flatten()\n",
    "\n",
    "# Step 4: Plot the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=x_embedded[:, 0], y=x_embedded[:, 1], hue=y_label, style=y_label,\n",
    "                palette=\"bright\", edgecolor='black')\n",
    "plt.title(\"t-SNE of Intermediate CNN Layer Output (Fold 1)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
