{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Bearing Fault Diagnosis with Spectrogram and Scalogram Inputs\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) for fault diagnosis of rolling element bearings using the Case Western Reserve University (CWRU) dataset. The methodology is based on Verstraete et al. (2017), which uses time-frequency image representations (spectrograms via STFT and scalograms via Morlet wavelet transform) as inputs to a CNN. The CNN architecture features double convolutional layers before pooling to enhance feature expressivity.\n",
    "\n",
    "**Created**: August 13, 2024  \n",
    "**Modified**: June 2025 to incorporate spectrogram and scalogram inputs  \n",
    "**Author**: YLiu\n",
    "\n",
    "## Overview\n",
    "- **Dataset**: CWRU Bearing Data (2HP load, various fault types and sizes)\n",
    "- **Input**: 96x96 pixel spectrogram or scalogram images\n",
    "- **Model**: CNN with three stages of double conv layers (32, 64, 128 filters), max pooling, and two dense layers\n",
    "- **Training**: 5-fold stratified cross-validation with early stopping\n",
    "- **Evaluation**: Accuracy, confusion matrices, and fold-wise performance plots\n",
    "\n",
    "## Requirements\n",
    "- Python libraries: tensorflow, numpy, scipy, scikit-learn, matplotlib, seaborn, pywt, skimage\n",
    "- CWRU dataset files in 'CWRU_BearingData_Load_2HP' folder\n",
    "\n",
    "Run cells sequentially to load data, preprocess, train the model, and evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Reproducibility\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 1\n",
    "random.seed(SEED)            # Python random module\n",
    "np.random.seed(SEED)         # NumPy\n",
    "tf.random.set_seed(SEED)     # TensorFlow\n",
    "\n",
    "# Enforce deterministic behavior for GPU operations\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic execution\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Deterministic cuDNN algorithms\n",
    "\n",
    "# Control GPU memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # Enable memory growth\n",
    "\n",
    "# Restrict parallelism\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Import additional libraries\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from skimage.transform import resize\n",
    "import pywt  # For wavelet transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CWRU Bearing Data\n",
    "\n",
    "The `ImportData` function loads the CWRU dataset files (.mat) containing vibration signals for normal and fault conditions (inner race, ball, outer race) at various fault sizes under a 2HP load. The data is stored in a list for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportData():\n",
    "    folder_path = 'CWRU_BearingData_Load_2HP'\n",
    "    file_paths = [\n",
    "        os.path.join(folder_path, '99.mat'),\n",
    "        os.path.join(folder_path, '111.mat'),\n",
    "        os.path.join(folder_path, '124.mat'),\n",
    "        os.path.join(folder_path, '137.mat'),\n",
    "        os.path.join(folder_path, '176.mat'),\n",
    "        os.path.join(folder_path, '191.mat'),\n",
    "        os.path.join(folder_path, '203.mat'),\n",
    "        os.path.join(folder_path, '215.mat'),\n",
    "        os.path.join(folder_path, '228.mat'),\n",
    "        os.path.join(folder_path, '240.mat')\n",
    "    ]\n",
    "    data_keys = [\n",
    "        'X099_DE_time', 'X111_DE_time', 'X124_DE_time', 'X137_DE_time',\n",
    "        'X176_DE_time', 'X191_DE_time', 'X203_DE_time', 'X215_DE_time',\n",
    "        'X228_DE_time', 'X240_DE_time'\n",
    "    ]\n",
    "    data = [scipy.io.loadmat(fp)[key] for fp, key in zip(file_paths, data_keys)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Frequency Image Generation\n",
    "\n",
    "The following functions generate spectrogram and scalogram images from vibration signal segments, as per Verstraete et al. (2017):\n",
    "- **Spectrogram**: Uses Short-Time Fourier Transform (STFT) with a Hann window, 256-point segments, and 128-point overlap. Images are normalized and resized to 96x96 pixels.\n",
    "- **Scalogram**: Uses Continuous Wavelet Transform (CWT) with the Morlet wavelet, scales 1 to 128. Magnitude is normalized and resized to 96x96 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(ary):\n",
    "    ary = (ary - ary.min()) / np.abs(ary.max() - ary.min())\n",
    "    return ary\n",
    "\n",
    "def generate_spectrogram_image(data_y_vector, image_shape=(96, 96)):\n",
    "    \"\"\"\n",
    "    Calculate the spectrogram of an array data_y_vector and resize it to image_shape.\n",
    "    \"\"\"\n",
    "    fs = 48000\n",
    "    f, t, sxx = signal.spectrogram(\n",
    "        data_y_vector,\n",
    "        fs,\n",
    "        nperseg=256,\n",
    "        noverlap=128,\n",
    "        window='hann'\n",
    "    )\n",
    "    sxx = min_max_norm(sxx)\n",
    "    sxx = resize(sxx, image_shape, mode='constant', anti_aliasing=True)\n",
    "    return sxx\n",
    "\n",
    "def generate_scalogram_image(data_y_vector, image_shape=(96, 96)):\n",
    "    \"\"\"\n",
    "    Calculate the scalogram using Morlet wavelet and resize it to image_shape.\n",
    "    \"\"\"\n",
    "    fs = 48000\n",
    "    scales = np.arange(1, 128)  # Adjust scales for Morlet wavelet\n",
    "    coef, freqs = pywt.cwt(\n",
    "        data_y_vector,\n",
    "        scales,\n",
    "        'morl',\n",
    "        sampling_period=1/fs\n",
    "    )\n",
    "    coef = np.abs(coef)  # Use magnitude\n",
    "    coef = min_max_norm(coef)\n",
    "    coef = resize(coef, image_shape, mode='constant', anti_aliasing=True)\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The `Sampling` function segments the vibration signals into blocks, and `DataPreparation` generates spectrogram or scalogram images for each segment. Labels are created in one-hot encoded format (`Y_CNN`) for CNN training and as integers (`Y`) for stratification. The output is a 4D array of images and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    No_of_blocks = (round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1)\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "    for i in range(No_of_blocks):\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx:(start_idx + samples_per_block)].T\n",
    "    return SplitData\n",
    "\n",
    "def DataPreparation(Data, interval_length, samples_per_block, image_type='spectrogram'):\n",
    "    \"\"\"\n",
    "    Prepare data by generating spectrogram or scalogram images.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    LabelPositional = []\n",
    "    Label = []\n",
    "    for count, data in enumerate(Data):\n",
    "        SplitData = Sampling(data, interval_length, samples_per_block)\n",
    "        images = []\n",
    "        for segment in SplitData:\n",
    "            if image_type == 'spectrogram':\n",
    "                img = generate_spectrogram_image(segment)\n",
    "            elif image_type == 'scalogram':\n",
    "                img = generate_scalogram_image(segment)\n",
    "            images.append(img)\n",
    "        images = np.array(images)\n",
    "        y = np.zeros([len(SplitData), 10])\n",
    "        y[:, count] = 1\n",
    "        y1 = np.zeros([len(SplitData), 1])\n",
    "        y1[:, 0] = count\n",
    "        X.append(images)\n",
    "        LabelPositional.append(y)\n",
    "        Label.append(y1)\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    LabelPositional = np.concatenate(LabelPositional, axis=0)\n",
    "    Label = np.concatenate(Label, axis=0)\n",
    "    return X, LabelPositional, Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Definition\n",
    "\n",
    "The `CNN_2D` class defines the CNN architecture as per Verstraete et al. (2017):\n",
    "- Three stages, each with two convolutional layers (32, 64, 128 filters, 3x3 kernels) followed by 2x2 max pooling.\n",
    "- Two dense layers (100 units each) with dropout (0.5) before the second dense layer.\n",
    "- Output layer with 10 units (softmax) for 10-class classification.\n",
    "- Compiled with Adam optimizer and categorical crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2D():\n",
    "    def __init__(self):\n",
    "        self.model = self.CreateModel()\n",
    "\n",
    "    def CreateModel(self):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(40, 40, 1)),\n",
    "            layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "            layers.MaxPool2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "            layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "            layers.MaxPool2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            layers.MaxPool2D((2, 2), padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(100, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(96, activation='relu'),\n",
    "            layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "This section executes the pipeline:\n",
    "- Loads and preprocesses data to generate 96x96 images (spectrogram or scalogram).\n",
    "- Splits data into training (80%) and test (20%) sets with stratification.\n",
    "- Performs 5-fold cross-validation with early stopping and model checkpointing.\n",
    "- Saves the best model for each fold.\n",
    "\n",
    "**Parameters**:\n",
    "- `image_type`: Set to 'scalogram' or 'spectrogram' to choose input type.\n",
    "- `image_shape`: 96x96 pixels for high accuracy (per Verstraete et al.).\n",
    "- `kSplits`: 5 for cross-validation.\n",
    "- `foldername`: Directory to save model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "interval_length = 320\n",
    "samples_per_block = 1600\n",
    "image_type = 'scalogram'  # Change to 'spectrogram' to use spectrograms\n",
    "image_shape = (40, 40)\n",
    "kSplits = 5\n",
    "foldername = \"CNN2D_results/Scalogram_Spectrogram/\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint #Saves the model with the highest validation accuracy for each fold\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "# Load and prepare data\n",
    "Data = ImportData()\n",
    "X, Y_CNN, Y = DataPreparation(Data, interval_length, samples_per_block, image_type=image_type)\n",
    "Input_2D = X.reshape([-1, image_shape[0], image_shape[1], 1])\n",
    "print(f\"Shape of Input Data: {Input_2D.shape}\")\n",
    "\n",
    "# Train-test split\n",
    "X_2D_train, X_2D_test, y_2D_train, y_2D_test, y_label_train, y_label_test = train_test_split(\n",
    "    Input_2D, Y_CNN, Y, train_size=0.8, test_size=0.2, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "# K-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=kSplits, random_state=42, shuffle=True)\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "pred_all_val = np.zeros([len(X_2D_train), 10])\n",
    "y_2D_val = np.zeros([len(X_2D_train), 10])\n",
    "kfold_test_len = []\n",
    "fl1 = 0\n",
    "k = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "for fold, (train, test) in enumerate(kfold.split(X_2D_train, y_label_train)):\n",
    "    checkpoint_filepath = foldername + f\"best_model_{k}.h5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    Classification_2D = CNN_2D()\n",
    "    history = Classification_2D.model.fit(\n",
    "        X_2D_train[train], y_2D_train[train],\n",
    "        validation_data=(X_2D_train[test], y_2D_train[test]),\n",
    "        epochs=200,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint, early_stop]\n",
    "    )\n",
    "    print(f\"Best model saved at: {checkpoint_filepath}\")\n",
    "    CNN_2D_best_model = load_model(checkpoint_filepath)\n",
    "    print(\"Best model loaded successfully!\")\n",
    "    \n",
    "    fl2 = fl1 + len(test)\n",
    "    pred_all_val[fl1:fl2, :] = CNN_2D_best_model.predict(X_2D_train[test])\n",
    "    y_2D_val[fl1:fl2, :] = y_2D_train[test]\n",
    "    kfold_test_len.append(fl2 - fl1)\n",
    "    fl1 = fl2\n",
    "\n",
    "    train_loss, train_accuracy = CNN_2D_best_model.evaluate(X_2D_train[train], y_2D_train[train])\n",
    "    accuracy_train.append(train_accuracy)\n",
    "    val_loss, val_accuracy = CNN_2D_best_model.evaluate(X_2D_train[test], y_2D_train[test])\n",
    "    accuracy_val.append(val_accuracy)\n",
    "    test_loss, test_accuracy = CNN_2D_best_model.evaluate(X_2D_test, y_2D_test)\n",
    "    accuracy_test.append(test_accuracy)\n",
    "    \n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the trained model by computing average accuracies across folds for training, validation, and test sets. Visualize performance with confusion matrices for train and test sets, and bar plots for fold-wise and train vs. test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_2D_train_accuracy = np.average(accuracy_train) * 100\n",
    "print(f'CNN 2D train accuracy = {CNN_2D_train_accuracy}')\n",
    "CNN_2D_val_accuracy = np.average(accuracy_val) * 100\n",
    "print(f'CNN 2D validation accuracy = {CNN_2D_val_accuracy}')\n",
    "CNN_2D_test_accuracy = np.average(accuracy_test) * 100\n",
    "print(f'CNN 2D test accuracy = {CNN_2D_test_accuracy}')\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "    y_pred = np.argmax(Model.predict(X), axis=1)\n",
    "    ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "    return ConfusionMat\n",
    "\n",
    "# Plot results\n",
    "plt.figure(5)\n",
    "plt.title('Confusion Matrix - CNN 2D Train')\n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_train, y_2D_train), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.title('Confusion Matrix - CNN 2D Test')\n",
    "sns.heatmap(ConfusionMatrix(CNN_2D_best_model, X_2D_test, y_2D_test), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7)\n",
    "plt.title('Train - Accuracy - CNN 2D')\n",
    "plt.bar(np.arange(1, kSplits + 1), [i * 100 for i in accuracy_val])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70, 100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(8)\n",
    "plt.title('Train vs Test Accuracy - CNN 2D')\n",
    "plt.bar([1, 2], [CNN_2D_train_accuracy, CNN_2D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.xticks([1, 2], ['Train', 'Test'])\n",
    "plt.ylim([70, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Running the Notebook**: Ensure the CWRU dataset files are in the 'CWRU_BearingData_Load_2HP' folder. Install required libraries (e.g., `pip install PyWavelets` for pywt).\n",
    "- **Switching Input Types**: Change `image_type` to 'spectrogram' in the main execution cell to use spectrograms instead of scalograms.\n",
    "- **Performance**: Per Verstraete et al., scalograms achieve up to 99.5% accuracy on CWRU data with 96x96 images, outperforming spectrograms (99.5%) and HHT (97.6%).\n",
    "- **Scalability**: 96x96 images increase computational load. For lower memory usage, set `image_shape = (32, 32)`, but expect reduced accuracy (e.g., 98.8% for scalograms).\n",
    "\n",
    "This notebook provides an interactive environment to experiment with time-frequency-based fault diagnosis, leveraging the strengths of CNNs for automatic feature learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
